<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="pdf2htmlEX"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="note03-Neural-Networks-and-Backpropagation.css"/>
<script>
/*
 Copyright 2012 Mozilla Foundation 
 Copyright 2013 Lu Wang <coolwanglu@gmail.com>
 Apachine License Version 2.0 
*/
(function(){function b(a,b,e,f){var c=(a.className||"").split(/\s+/g);""===c[0]&&c.shift();var d=c.indexOf(b);0>d&&e&&c.push(b);0<=d&&f&&c.splice(d,1);a.className=c.join(" ");return 0<=d}if(!("classList"in document.createElement("div"))){var e={add:function(a){b(this.element,a,!0,!1)},contains:function(a){return b(this.element,a,!1,!1)},remove:function(a){b(this.element,a,!1,!0)},toggle:function(a){b(this.element,a,!0,!0)}};Object.defineProperty(HTMLElement.prototype,"classList",{get:function(){if(this._classList)return this._classList;
var a=Object.create(e,{element:{value:this,writable:!1,enumerable:!0}});Object.defineProperty(this,"_classList",{value:a,writable:!1,enumerable:!1});return a},enumerable:!0})}})();
</script>
<script>
(function(){/*
 pdf2htmlEX.js: Core UI functions for pdf2htmlEX 
 Copyright 2012,2013 Lu Wang <coolwanglu@gmail.com> and other contributors 
 https://github.com/coolwanglu/pdf2htmlEX/blob/master/share/LICENSE 
*/
var pdf2htmlEX=window.pdf2htmlEX=window.pdf2htmlEX||{},CSS_CLASS_NAMES={page_frame:"pf",page_content_box:"pc",page_data:"pi",background_image:"bi",link:"l",input_radio:"ir",__dummy__:"no comma"},DEFAULT_CONFIG={container_id:"page-container",sidebar_id:"sidebar",outline_id:"outline",loading_indicator_cls:"loading-indicator",preload_pages:3,render_timeout:100,scale_step:0.9,key_handler:!0,hashchange_handler:!0,view_history_handler:!0,__dummy__:"no comma"},EPS=1E-6;
function invert(a){var b=a[0]*a[3]-a[1]*a[2];return[a[3]/b,-a[1]/b,-a[2]/b,a[0]/b,(a[2]*a[5]-a[3]*a[4])/b,(a[1]*a[4]-a[0]*a[5])/b]}function transform(a,b){return[a[0]*b[0]+a[2]*b[1]+a[4],a[1]*b[0]+a[3]*b[1]+a[5]]}function get_page_number(a){return parseInt(a.getAttribute("data-page-no"),16)}function disable_dragstart(a){for(var b=0,c=a.length;b<c;++b)a[b].addEventListener("dragstart",function(){return!1},!1)}
function clone_and_extend_objs(a){for(var b={},c=0,e=arguments.length;c<e;++c){var h=arguments[c],d;for(d in h)h.hasOwnProperty(d)&&(b[d]=h[d])}return b}
function Page(a){if(a){this.shown=this.loaded=!1;this.page=a;this.num=get_page_number(a);this.original_height=a.clientHeight;this.original_width=a.clientWidth;var b=a.getElementsByClassName(CSS_CLASS_NAMES.page_content_box)[0];b&&(this.content_box=b,this.original_scale=this.cur_scale=this.original_height/b.clientHeight,this.page_data=JSON.parse(a.getElementsByClassName(CSS_CLASS_NAMES.page_data)[0].getAttribute("data-data")),this.ctm=this.page_data.ctm,this.ictm=invert(this.ctm),this.loaded=!0)}}
Page.prototype={hide:function(){this.loaded&&this.shown&&(this.content_box.classList.remove("opened"),this.shown=!1)},show:function(){this.loaded&&!this.shown&&(this.content_box.classList.add("opened"),this.shown=!0)},rescale:function(a){this.cur_scale=0===a?this.original_scale:a;this.loaded&&(a=this.content_box.style,a.msTransform=a.webkitTransform=a.transform="scale("+this.cur_scale.toFixed(3)+")");a=this.page.style;a.height=this.original_height*this.cur_scale+"px";a.width=this.original_width*this.cur_scale+
"px"},view_position:function(){var a=this.page,b=a.parentNode;return[b.scrollLeft-a.offsetLeft-a.clientLeft,b.scrollTop-a.offsetTop-a.clientTop]},height:function(){return this.page.clientHeight},width:function(){return this.page.clientWidth}};function Viewer(a){this.config=clone_and_extend_objs(DEFAULT_CONFIG,0<arguments.length?a:{});this.pages_loading=[];this.init_before_loading_content();var b=this;document.addEventListener("DOMContentLoaded",function(){b.init_after_loading_content()},!1)}
Viewer.prototype={scale:1,cur_page_idx:0,first_page_idx:0,init_before_loading_content:function(){this.pre_hide_pages()},initialize_radio_button:function(){for(var a=document.getElementsByClassName(CSS_CLASS_NAMES.input_radio),b=0;b<a.length;b++)a[b].addEventListener("click",function(){this.classList.toggle("checked")})},init_after_loading_content:function(){this.sidebar=document.getElementById(this.config.sidebar_id);this.outline=document.getElementById(this.config.outline_id);this.container=document.getElementById(this.config.container_id);
this.loading_indicator=document.getElementsByClassName(this.config.loading_indicator_cls)[0];for(var a=!0,b=this.outline.childNodes,c=0,e=b.length;c<e;++c)if("ul"===b[c].nodeName.toLowerCase()){a=!1;break}a||this.sidebar.classList.add("opened");this.find_pages();if(0!=this.pages.length){disable_dragstart(document.getElementsByClassName(CSS_CLASS_NAMES.background_image));this.config.key_handler&&this.register_key_handler();var h=this;this.config.hashchange_handler&&window.addEventListener("hashchange",
function(a){h.navigate_to_dest(document.location.hash.substring(1))},!1);this.config.view_history_handler&&window.addEventListener("popstate",function(a){a.state&&h.navigate_to_dest(a.state)},!1);this.container.addEventListener("scroll",function(){h.update_page_idx();h.schedule_render(!0)},!1);[this.container,this.outline].forEach(function(a){a.addEventListener("click",h.link_handler.bind(h),!1)});this.initialize_radio_button();this.render()}},find_pages:function(){for(var a=[],b={},c=this.container.childNodes,
e=0,h=c.length;e<h;++e){var d=c[e];d.nodeType===Node.ELEMENT_NODE&&d.classList.contains(CSS_CLASS_NAMES.page_frame)&&(d=new Page(d),a.push(d),b[d.num]=a.length-1)}this.pages=a;this.page_map=b},load_page:function(a,b,c){var e=this.pages;if(!(a>=e.length||(e=e[a],e.loaded||this.pages_loading[a]))){var e=e.page,h=e.getAttribute("data-page-url");if(h){this.pages_loading[a]=!0;var d=e.getElementsByClassName(this.config.loading_indicator_cls)[0];"undefined"===typeof d&&(d=this.loading_indicator.cloneNode(!0),
d.classList.add("active"),e.appendChild(d));var f=this,g=new XMLHttpRequest;g.open("GET",h,!0);g.onload=function(){if(200===g.status||0===g.status){var b=document.createElement("div");b.innerHTML=g.responseText;for(var d=null,b=b.childNodes,e=0,h=b.length;e<h;++e){var p=b[e];if(p.nodeType===Node.ELEMENT_NODE&&p.classList.contains(CSS_CLASS_NAMES.page_frame)){d=p;break}}b=f.pages[a];f.container.replaceChild(d,b.page);b=new Page(d);f.pages[a]=b;b.hide();b.rescale(f.scale);disable_dragstart(d.getElementsByClassName(CSS_CLASS_NAMES.background_image));
f.schedule_render(!1);c&&c(b)}delete f.pages_loading[a]};g.send(null)}void 0===b&&(b=this.config.preload_pages);0<--b&&(f=this,setTimeout(function(){f.load_page(a+1,b)},0))}},pre_hide_pages:function(){var a="@media screen{."+CSS_CLASS_NAMES.page_content_box+"{display:none;}}",b=document.createElement("style");b.styleSheet?b.styleSheet.cssText=a:b.appendChild(document.createTextNode(a));document.head.appendChild(b)},render:function(){for(var a=this.container,b=a.scrollTop,c=a.clientHeight,a=b-c,b=
b+c+c,c=this.pages,e=0,h=c.length;e<h;++e){var d=c[e],f=d.page,g=f.offsetTop+f.clientTop,f=g+f.clientHeight;g<=b&&f>=a?d.loaded?d.show():this.load_page(e):d.hide()}},update_page_idx:function(){var a=this.pages,b=a.length;if(!(2>b)){for(var c=this.container,e=c.scrollTop,c=e+c.clientHeight,h=-1,d=b,f=d-h;1<f;){var g=h+Math.floor(f/2),f=a[g].page;f.offsetTop+f.clientTop+f.clientHeight>=e?d=g:h=g;f=d-h}this.first_page_idx=d;for(var g=h=this.cur_page_idx,k=0;d<b;++d){var f=a[d].page,l=f.offsetTop+f.clientTop,
f=f.clientHeight;if(l>c)break;f=(Math.min(c,l+f)-Math.max(e,l))/f;if(d===h&&Math.abs(f-1)<=EPS){g=h;break}f>k&&(k=f,g=d)}this.cur_page_idx=g}},schedule_render:function(a){if(void 0!==this.render_timer){if(!a)return;clearTimeout(this.render_timer)}var b=this;this.render_timer=setTimeout(function(){delete b.render_timer;b.render()},this.config.render_timeout)},register_key_handler:function(){var a=this;window.addEventListener("DOMMouseScroll",function(b){if(b.ctrlKey){b.preventDefault();var c=a.container,
e=c.getBoundingClientRect(),c=[b.clientX-e.left-c.clientLeft,b.clientY-e.top-c.clientTop];a.rescale(Math.pow(a.config.scale_step,b.detail),!0,c)}},!1);window.addEventListener("keydown",function(b){var c=!1,e=b.ctrlKey||b.metaKey,h=b.altKey;switch(b.keyCode){case 61:case 107:case 187:e&&(a.rescale(1/a.config.scale_step,!0),c=!0);break;case 173:case 109:case 189:e&&(a.rescale(a.config.scale_step,!0),c=!0);break;case 48:e&&(a.rescale(0,!1),c=!0);break;case 33:h?a.scroll_to(a.cur_page_idx-1):a.container.scrollTop-=
a.container.clientHeight;c=!0;break;case 34:h?a.scroll_to(a.cur_page_idx+1):a.container.scrollTop+=a.container.clientHeight;c=!0;break;case 35:a.container.scrollTop=a.container.scrollHeight;c=!0;break;case 36:a.container.scrollTop=0,c=!0}c&&b.preventDefault()},!1)},rescale:function(a,b,c){var e=this.scale;this.scale=a=0===a?1:b?e*a:a;c||(c=[0,0]);b=this.container;c[0]+=b.scrollLeft;c[1]+=b.scrollTop;for(var h=this.pages,d=h.length,f=this.first_page_idx;f<d;++f){var g=h[f].page;if(g.offsetTop+g.clientTop>=
c[1])break}g=f-1;0>g&&(g=0);var g=h[g].page,k=g.clientWidth,f=g.clientHeight,l=g.offsetLeft+g.clientLeft,m=c[0]-l;0>m?m=0:m>k&&(m=k);k=g.offsetTop+g.clientTop;c=c[1]-k;0>c?c=0:c>f&&(c=f);for(f=0;f<d;++f)h[f].rescale(a);b.scrollLeft+=m/e*a+g.offsetLeft+g.clientLeft-m-l;b.scrollTop+=c/e*a+g.offsetTop+g.clientTop-c-k;this.schedule_render(!0)},fit_width:function(){var a=this.cur_page_idx;this.rescale(this.container.clientWidth/this.pages[a].width(),!0);this.scroll_to(a)},fit_height:function(){var a=this.cur_page_idx;
this.rescale(this.container.clientHeight/this.pages[a].height(),!0);this.scroll_to(a)},get_containing_page:function(a){for(;a;){if(a.nodeType===Node.ELEMENT_NODE&&a.classList.contains(CSS_CLASS_NAMES.page_frame)){a=get_page_number(a);var b=this.page_map;return a in b?this.pages[b[a]]:null}a=a.parentNode}return null},link_handler:function(a){var b=a.target,c=b.getAttribute("data-dest-detail");if(c){if(this.config.view_history_handler)try{var e=this.get_current_view_hash();window.history.replaceState(e,
"","#"+e);window.history.pushState(c,"","#"+c)}catch(h){}this.navigate_to_dest(c,this.get_containing_page(b));a.preventDefault()}},navigate_to_dest:function(a,b){try{var c=JSON.parse(a)}catch(e){return}if(c instanceof Array){var h=c[0],d=this.page_map;if(h in d){for(var f=d[h],h=this.pages[f],d=2,g=c.length;d<g;++d){var k=c[d];if(null!==k&&"number"!==typeof k)return}for(;6>c.length;)c.push(null);var g=b||this.pages[this.cur_page_idx],d=g.view_position(),d=transform(g.ictm,[d[0],g.height()-d[1]]),
g=this.scale,l=[0,0],m=!0,k=!1,n=this.scale;switch(c[1]){case "XYZ":l=[null===c[2]?d[0]:c[2]*n,null===c[3]?d[1]:c[3]*n];g=c[4];if(null===g||0===g)g=this.scale;k=!0;break;case "Fit":case "FitB":l=[0,0];k=!0;break;case "FitH":case "FitBH":l=[0,null===c[2]?d[1]:c[2]*n];k=!0;break;case "FitV":case "FitBV":l=[null===c[2]?d[0]:c[2]*n,0];k=!0;break;case "FitR":l=[c[2]*n,c[5]*n],m=!1,k=!0}if(k){this.rescale(g,!1);var p=this,c=function(a){l=transform(a.ctm,l);m&&(l[1]=a.height()-l[1]);p.scroll_to(f,l)};h.loaded?
c(h):(this.load_page(f,void 0,c),this.scroll_to(f))}}}},scroll_to:function(a,b){var c=this.pages;if(!(0>a||a>=c.length)){c=c[a].view_position();void 0===b&&(b=[0,0]);var e=this.container;e.scrollLeft+=b[0]-c[0];e.scrollTop+=b[1]-c[1]}},get_current_view_hash:function(){var a=[],b=this.pages[this.cur_page_idx];a.push(b.num);a.push("XYZ");var c=b.view_position(),c=transform(b.ictm,[c[0],b.height()-c[1]]);a.push(c[0]/this.scale);a.push(c[1]/this.scale);a.push(this.scale);return JSON.stringify(a)}};
pdf2htmlEX.Viewer=Viewer;})();
</script>
<script>
try{
pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
<ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",63.75,805.75,null]'>1.Neural Networks: Foundations</a><ul><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",42.5,531.35,null]'>1.1 A Neuron</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",42.5,806.15,null]'>1.2 A Single Layer of Neurons</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",42.5,173.5,null]'>1.3 Feed-forward Computation</a></li><li><a class="l" href="#pf4" data-dest-detail='[4,"XYZ",42.5,592.05,null]'>1.4 Maximum Margin Objective Function</a></li><li><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",42.5,224.4,null]'>1.6 Training with Backpropagation – Vectorized</a></li></ul></li><li><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",63.75,806.15,null]'>2.Neural Networks: Tips and Tricks</a><ul><li><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",42.5,771.35,null]'>2.1 Gradient Check</a></li><li><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",42.5,334.3,null]'>2.2 Regularization</a><ul><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",42.5,431.5,null]'>下面摘录已有的三条回答</a></li></ul></li><li><a class="l" href="#pfc" data-dest-detail='[12,"XYZ",42.5,362.65,null]'>2.3 Dropout</a><ul><li><a class="l" href="#pfd" data-dest-detail='[13,"XYZ",42.5,457.15,null]'>集成学习的解释 👍</a></li><li><a class="l" href="#pfd" data-dest-detail='[13,"XYZ",42.5,332.25,null]'>贝叶斯学习的解释 👍 </a></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",42.5,805.75,null]'>RNN中的变分Dropout </a></li></ul></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",42.5,171.8,null]'>2.4 Neuron Units</a></li><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",42.5,461.5,null]'>2.5 Data Preprocessing</a><ul><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",42.5,359.55,null]'>Mean Subtraction</a></li><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",42.5,260.3,null]'>Normalization</a></li><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",42.5,123.4,null]'>Whitening</a></li></ul></li><li><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",42.5,694.1,null]'>2.6 Parameter Initialization</a></li><li><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",42.5,318.7,null]'>2.7 Learning Strategies</a></li><li><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",42.5,264.3,null]'>2.8 Momentum Updates</a></li><li><a class="l" href="#pf13" data-dest-detail='[19,"XYZ",42.5,806.15,null]'>2.9 Adaptive Optimization Methods</a></li><li><a class="l" href="#pf13" data-dest-detail='[19,"XYZ",395.3,806.15,null]'>2.10 More reference</a></li></ul></li></ul></div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg1.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h4 y4 ff2 fs2 fc0 sc0 ls0 ws0">Lecture<span class="_ _4"> </span>Notes:<span class="_ _4"> </span>Part<span class="_ _4"> </span>III</div><div class="t m0 x0 h4 y5 ff2 fs2 fc0 sc0 ls0 ws0">Neural<span class="_ _4"> </span>Networks,<span class="_ _3"> </span>Backpropagation</div><div class="t m0 x0 h5 y6 ff4 fs3 fc0 sc0 ls0 ws0">CS224n<span class="_ _5"> </span><span class="ff5">是<span class="_ _2"></span>顶<span class="_ _2"></span>级<span class="_ _6"></span>院<span class="_ _2"></span>校<span class="_ _2"></span>斯<span class="_ _6"></span>坦<span class="_ _2"></span>福<span class="_ _2"></span>出<span class="_ _6"></span>品<span class="_ _2"></span>的<span class="_ _2"></span>深<span class="_ _6"></span>度<span class="_ _2"></span>学<span class="_ _2"></span>习<span class="_ _2"></span>与<span class="_ _2"></span>自<span class="_ _6"></span>然<span class="_ _2"></span>语<span class="_ _2"></span>言<span class="_ _6"></span>处<span class="_ _2"></span>理<span class="_ _2"></span>方</span></div><div class="t m0 x0 h5 y7 ff5 fs3 fc0 sc0 ls0 ws0">向<span class="_ _7"> </span>专<span class="_ _7"> </span>业<span class="_ _7"> </span>课<span class="_ _7"> </span>程<span class="_ _7"> </span>，<span class="_ _8"> </span>核<span class="_ _7"> </span>心<span class="_ _7"> </span>内<span class="_ _7"> </span>容<span class="_ _7"> </span>覆<span class="_ _7"> </span>盖<span class="_ _9"> </span><span class="ff4">RNN<span class="_ _7"> </span></span>、<span class="_ _7"> </span><span class="ff4">LSTM<span class="_ _8"> </span></span>、<span class="_ _7"> </span><span class="ff4">CNN<span class="_ _7"> </span></span>、</div><div class="t m0 x0 h5 y8 ff4 fs3 fc0 sc0 ls0 ws0">transformer<span class="_ _2"></span><span class="ff5">、<span class="_ _2"></span></span>bert<span class="_ _2"></span><span class="ff5">、<span class="_ _2"></span>问答<span class="_ _2"></span>、<span class="_ _2"></span>摘<span class="_ _2"></span>要、<span class="_ _2"></span>文<span class="_ _2"></span>本<span class="_ _2"></span>生<span class="_ _2"></span>成、<span class="_ _2"></span>语<span class="_ _2"></span>言<span class="_ _2"></span>模型<span class="_ _2"></span>、<span class="_ _2"></span>阅<span class="_ _2"></span>读</span></div><div class="t m0 x0 h6 y9 ff5 fs3 fc0 sc0 ls0 ws0">理解等前沿内<span class="_ _2"></span>容。</div><div class="t m0 x0 h6 ya ff5 fs3 fc0 sc0 ls0 ws0">这组笔记介绍<span class="_ _2"></span>了单层和多层<span class="_ _2"></span>神经网络<span class="_ _2"></span>，以及如何将<span class="_ _2"></span>它们用于分类</div><div class="t m0 x0 h6 yb ff5 fs3 fc0 sc0 ls0 ws0">目的。然后我<span class="_ _2"></span>们讨论如何使<span class="_ _2"></span>用一种称<span class="_ _2"></span>为反向传播的<span class="_ _2"></span>分布式梯度下</div><div class="t m0 x0 h6 yc ff5 fs3 fc0 sc0 ls0 ws0">降技术来训练<span class="_ _2"></span>它们。我们将<span class="_ _2"></span>看到如何<span class="_ _2"></span>使用链式法则<span class="_ _2"></span>按顺序进行参</div><div class="t m0 x0 h6 yd ff5 fs3 fc0 sc0 ls0 ws0">数更新。在对<span class="_ _2"></span>神经网络进行<span class="_ _2"></span>严格的数<span class="_ _2"></span>学讨论之后，<span class="_ _2"></span>我们将讨论一</div><div class="t m0 x0 h5 ye ff5 fs3 fc0 sc0 ls0 ws0">些训练神经<span class="_ _2"></span>网络的实用技<span class="_ _2"></span>巧和技巧<span class="_ _2"></span>，包括<span class="ff4">:</span>神<span class="_ _2"></span>经元单元<span class="ff4">(</span>非<span class="_ _2"></span>线性<span class="ff4">)</span>、</div><div class="t m0 x0 h5 yf ff5 fs3 fc0 sc0 ls0 ws0">梯<span class="_ _2"></span>度<span class="_ _2"></span>检<span class="_ _6"></span>查<span class="_ _2"></span>、<span class="_ _2"></span><span class="ff4">Xavier<span class="_ _5"> </span></span>参<span class="_ _6"></span>数<span class="_ _2"></span>初<span class="_ _2"></span>始<span class="_ _6"></span>化<span class="_ _2"></span>、<span class="_ _2"></span>学<span class="_ _6"></span>习<span class="_ _2"></span>率<span class="_ _2"></span>、<span class="_ _6"></span><span class="ff4">Adagrad<span class="_ _5"> </span></span>等<span class="_ _6"></span>。<span class="_ _2"></span>最<span class="_ _2"></span>后<span class="_ _6"></span><span class="ff4">,</span></div><div class="t m0 x0 h6 y10 ff5 fs3 fc0 sc0 ls0 ws0">我们将鼓励使<span class="_ _2"></span>用递归神经网<span class="_ _2"></span>络作为语<span class="_ _2"></span>言模型。</div><div class="t m0 x0 h7 y11 ff6 fs2 fc0 sc0 ls0 ws0">笔记核心词<span class="_ _a"></span>：</div><div class="t m0 x0 h5 y12 ff4 fs3 fc0 sc0 ls0 ws0">Neural<span class="_ _b"> </span>networks<span class="_ _c"> </span><span class="ff5">，<span class="_ _9"> </span></span>For<span class="_ _2"></span>ward<span class="_ _b"> </span>omputation,<span class="_ _b"> </span>Backward<span class="_ _2"></span>,</div><div class="t m0 x0 h5 y13 ff4 fs3 fc0 sc0 ls0 ws0">propagation<span class="_ _2"></span>,<span class="_ _d"> </span>Neuron<span class="_ _d"> </span>Units,<span class="_ _d"> </span>Max-margin<span class="_ _d"> </span>Loss<span class="_ _2"></span>,<span class="_ _d"> </span>Gradient</div><div class="t m0 x0 h5 y14 ff4 fs3 fc0 sc0 ls0 ws0">checks,<span class="_ _e"> </span>Xavier<span class="_ _e"> </span>parameter<span class="_ _e"> </span>initialization<span class="_ _2"></span>,<span class="_ _e"> </span>Learning<span class="_ _e"> </span>rates,</div><div class="t m0 x0 h5 y15 ff4 fs3 fc0 sc0 ls0 ws0">Adagrad</div><div class="t m0 x0 h6 y16 ff5 fs3 fc0 sc0 ls0 ws0">课程</div><div class="t m0 x2 h8 y17 ff7 fs4 fc0 sc0 ls0 ws0">全部<span class="_ _2"></span>资<span class="_ _2"></span>料和<span class="_ _2"></span>信<span class="_ _2"></span>息</div><div class="t m0 x3 h6 y16 ff5 fs3 fc0 sc0 ls0 ws0">已整<span class="_ _6"></span>理<span class="_ _2"></span>发<span class="_ _2"></span>布<span class="_ _2"></span>，<span class="_ _2"></span>扫<span class="_ _2"></span>描<span class="_ _2"></span>下<span class="_ _2"></span>方</div><div class="t m0 x4 h8 y17 ff7 fs4 fc0 sc0 ls0 ws0">任意</div><div class="t m0 x5 h6 y16 ff5 fs3 fc0 sc0 ls0 ws0">二维<span class="_ _6"></span>码<span class="_ _2"></span>，<span class="_ _2"></span>均<span class="_ _2"></span>可</div><div class="t m0 x0 h6 y18 ff5 fs3 fc0 sc0 ls0 ws0">获取！！</div></div><div class="c x6 y19 w3 h9"><div class="t m0 x7 ha y1a ff6 fs3 fc0 sc0 ls0 ws0">微信公众号</div><div class="t m0 x8 hb y1b ff5 fs5 fc0 sc0 ls0 ws0">·全套资料</div><div class="t m0 x7 hc y1c ff5 fs5 fc0 sc0 ls0 ws0">回复 <span class="ff4">CS224n</span></div><div class="t m0 x7 hb y1d ff5 fs5 fc0 sc0 ls0 ws0">底部菜单栏</div></div><div class="c x9 y19 w4 h9"><div class="t m0 x7 ha y1a ff6 fs3 fc0 sc0 ls0 ws0">Bilibili</div><div class="t m0 xa hb y1b ff5 fs5 fc0 sc0 ls0 ws0">·课程视频</div><div class="t m0 x7 hb y1c ff5 fs5 fc0 sc0 ls0 ws0">视频简介</div><div class="t m0 x7 hb y1d ff5 fs5 fc0 sc0 ls0 ws0">置顶评论</div></div><div class="c xb y19 w3 h9"><div class="t m0 x7 ha y1a ff6 fs3 fc0 sc0 ls0 ws0">GitHub</div><div class="t m0 xc hb y1b ff5 fs5 fc0 sc0 ls0 ws0">·项目代码</div><div class="t m0 x7 hc y1c ff5 fs5 fc0 sc0 ls0 ws0">阅读 <span class="ff4">ReadMe</span></div><div class="t m0 x7 hb y1d ff5 fs5 fc0 sc0 ls0 ws0">点击超链接</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi x0 y0 w5 hd" alt="" src="bg2.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h10 y20 ff9 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _f"> </span>Neural<span class="_ _4"> </span>Network<span class="_ _a"></span>s:<span class="_ _4"> </span>Foundations</div><div class="t m0 x0 h6 y21 ff5 fs3 fc0 sc0 ls0 ws0">在前面的讨论<span class="_ _2"></span>中认为，因为<span class="_ _2"></span>大部分数<span class="_ _2"></span>据是线性不可<span class="_ _2"></span>分的所以需要</div><div class="t m0 x0 h6 y22 ff5 fs3 fc0 sc0 ls0 ws0">非线性分类器<span class="_ _2"></span>，不然的话线<span class="_ _2"></span>性分类器<span class="_ _2"></span>在这些数据上<span class="_ _2"></span>的表现是有限</div><div class="t m0 x0 h6 y23 ff5 fs3 fc0 sc0 ls0 ws0">的。神经网络<span class="_ _2"></span>就是如右图<span class="_ _2"></span>所示的一<span class="_ _2"></span>类具有非线性<span class="_ _2"></span>决策分界<span class="_ _2"></span>的分类</div><div class="t m0 x0 h6 y24 ff5 fs3 fc0 sc0 ls0 ws0">器。现在我们<span class="_ _2"></span>知道神经网络<span class="_ _2"></span>创建的决<span class="_ _2"></span>策边界，让我<span class="_ _2"></span>们看看这是如</div><div class="t m0 x0 h6 y25 ff5 fs3 fc0 sc0 ls0 ws0">何创建的。</div><div class="t m0 x0 h11 y26 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ffb fs1">神经<span class="_ _2"></span>网<span class="_ _2"></span>络<span class="_ _2"></span>是<span class="_ _2"></span>受<span class="_ _2"></span>生<span class="_ _2"></span>物<span class="_ _2"></span>学<span class="_ _2"></span>启<span class="_ _2"></span>发<span class="_ _2"></span>的分<span class="_ _2"></span>类<span class="_ _2"></span>器<span class="_ _2"></span>，<span class="_ _2"></span>这<span class="_ _2"></span>就<span class="_ _2"></span>是<span class="_ _2"></span>为<span class="_ _2"></span>什<span class="_ _2"></span>么<span class="_ _2"></span>它<span class="_ _2"></span>们<span class="_ _2"></span>经<span class="_ _2"></span>常<span class="_ _2"></span>被</span></div><div class="t m0 x0 h12 y27 ffb fs1 fc0 sc0 ls0 ws0">称为<span class="_ _6"></span><span class="ffc">“<span class="_ _2"></span></span>人<span class="_ _2"></span>工<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>网<span class="_ _2"></span>络<span class="_ _2"></span><span class="ffc">”<span class="_ _2"></span></span>，<span class="_ _2"></span>以<span class="_ _2"></span>区<span class="_ _2"></span>别<span class="_ _2"></span>于<span class="_ _2"></span>有<span class="_ _6"></span>机<span class="_ _2"></span>类。<span class="_ _6"></span>然<span class="_ _2"></span>而<span class="_ _2"></span>，<span class="_ _2"></span>在<span class="_ _2"></span>现<span class="_ _2"></span>实<span class="_ _2"></span>中<span class="_ _6"></span>，人<span class="_ _2"></span>类<span class="_ _2"></span>神</div><div class="t m0 x0 h13 y28 ffb fs1 fc0 sc0 ls0 ws0">经网<span class="_ _2"></span>络<span class="_ _2"></span>比人<span class="_ _2"></span>工<span class="_ _2"></span>神<span class="_ _2"></span>经网<span class="_ _2"></span>络<span class="_ _2"></span>更<span class="_ _2"></span>有能<span class="_ _2"></span>力<span class="_ _2"></span>、<span class="_ _2"></span>更复<span class="_ _2"></span>杂<span class="_ _2"></span>，<span class="_ _2"></span>因此<span class="_ _2"></span>通<span class="_ _2"></span>常<span class="_ _2"></span>最好<span class="_ _2"></span>不<span class="_ _2"></span>要在<span class="_ _2"></span>两</div><div class="t m0 x0 h13 y29 ffb fs1 fc0 sc0 ls0 ws0">者之间画太<span class="_ _2"></span>多的相似点。</div><div class="t m0 x0 h14 y2a ffd fs0 fc0 sc0 ls0 ws0">1.1<span class="_ _7"> </span>A<span class="_ _4"> </span>Neuron</div><div class="t m0 x0 h6 y2b ff5 fs3 fc0 sc0 ls0 ws0">神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>是<span class="_ _6"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>通<span class="_ _6"></span>用<span class="_ _6"></span>的<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _2"></span>单<span class="_ _6"></span>元<span class="_ _2"></span>，<span class="_ _6"></span>它<span class="_ _2"></span>接<span class="_ _6"></span>受</div><div class="t m0 x11 h15 y2c ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x12 h6 y2b ff5 fs3 fc0 sc0 ls0 ws0">个<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _2"></span>并<span class="_ _6"></span>产<span class="_ _2"></span>生<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>输</div><div class="t m0 x0 h6 y2d ff5 fs3 fc0 sc0 ls0 ws0">出。不同的神<span class="_ _2"></span>经元根据它们<span class="_ _2"></span>不同的参<span class="_ _2"></span>数（一般认为<span class="_ _2"></span>是神经元的权</div><div class="t m0 x0 h6 y2e ff5 fs3 fc0 sc0 ls0 ws0">值<span class="_ _3"> </span>）<span class="_ _3"> </span>会<span class="_ _3"> </span>有<span class="_ _4"> </span>不<span class="_ _3"> </span>同<span class="_ _3"> </span>的<span class="_ _3"> </span>输<span class="_ _3"> </span>出<span class="_ _3"> </span>。<span class="_ _3"> </span>对<span class="_ _3"> </span>神<span class="_ _4"> </span>经<span class="_ _3"> </span>元<span class="_ _3"> </span>来<span class="_ _3"> </span>说<span class="_ _3"> </span>一<span class="_ _4"> </span>个<span class="_ _3"> </span>常<span class="_ _3"> </span>见<span class="_ _3"> </span>的<span class="_ _3"> </span>选<span class="_ _3"> </span>择</div><div class="t m0 x0 h6 y2f ff5 fs3 fc0 sc0 ls0 ws0">是</div><div class="t m0 x13 h15 y30 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x14 h5 y2f ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>或<span class="_ _2"></span>者<span class="_ _6"></span>称为<span class="_ _6"></span><span class="ff4">“<span class="_ _2"></span></span>二<span class="_ _2"></span>元<span class="_ _6"></span>逻<span class="_ _2"></span>辑<span class="_ _2"></span>回<span class="_ _2"></span>归<span class="_ _2"></span><span class="ff4">”<span class="_ _6"></span></span>单<span class="_ _2"></span>元<span class="_ _2"></span>。<span class="_ _6"></span>这<span class="_ _2"></span>种<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>以</div><div class="t m0 x15 h15 y30 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h6 y31 ff5 fs3 fc0 sc0 ls0 ws0">维<span class="_ _2"></span>的<span class="_ _6"></span>向<span class="_ _2"></span>量<span class="_ _6"></span>作<span class="_ _2"></span>为<span class="_ _6"></span>输<span class="_ _2"></span>入<span class="_ _6"></span>，<span class="_ _2"></span>然<span class="_ _6"></span>后<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _6"></span>出<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _2"></span>激<span class="_ _6"></span>活<span class="_ _6"></span>标<span class="_ _2"></span>量<span class="_ _6"></span>（<span class="_ _2"></span>输<span class="_ _2"></span>出<span class="_ _6"></span>）</div><div class="t m0 x16 h15 y32 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xe h6 y31 ff5 fs3 fc0 sc0 ls0 ws0">。<span class="_ _2"></span>该</div><div class="t m0 x0 h6 y33 ff5 fs3 fc0 sc0 ls0 ws0">神经<span class="_ _6"></span>元<span class="_ _2"></span>还与<span class="_ _6"></span>一<span class="_ _2"></span>个</div><div class="t m0 x17 h15 y34 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x18 h15 y33 ff5 fs3 fc0 sc0 ls0 ws0">维的<span class="_ _6"></span>权<span class="_ _2"></span>重向<span class="_ _6"></span>量<span class="_ _7"> </span><span class="ffe"><span class="_ _7"></span></span>和一<span class="_ _2"></span>个<span class="_ _2"></span>偏<span class="_ _2"></span>置<span class="_ _2"></span>标<span class="_ _2"></span>量</div><div class="t m0 x19 h15 y34 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1a h6 y33 ff5 fs3 fc0 sc0 ls0 ws0">相关<span class="_ _6"></span>联<span class="_ _2"></span>。</div><div class="t m0 x0 h6 y35 ff5 fs3 fc0 sc0 ls0 ws0">这个神经元的<span class="_ _2"></span>输出是：</div><div class="t m0 x18 h15 y36 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>=</div><div class="t m0 x1b h15 y37 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 h15 y38 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _4"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>(</div><div class="t m0 x1c h16 y39 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x1d h15 y38 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span>+<span class="_ _3"></span>))</div><div class="t m0 x0 h6 y3a ff5 fs3 fc0 sc0 ls0 ws0">我们也可以把<span class="_ _2"></span>上面公式中的<span class="_ _2"></span>权值和偏<span class="_ _2"></span>置项结合在一<span class="_ _2"></span>起：</div><div class="t m0 x1e h15 y3b ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>=</div><div class="t m0 x1b h15 y3c ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1f h15 y3d ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _4"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>[</div><div class="t m0 x20 h16 y3e ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m1 x21 h17 y3d ffe fs8 fc0 sc0 ls0 ws0">  </div><div class="t m0 x1c h15 y3d ffe fs3 fc0 sc0 ls0 ws0">]<span class="_ _3"></span>⋅<span class="_ _3"></span>[</div><div class="t m1 x12 h17 y3d ffe fs8 fc0 sc0 ls0 ws0">  </div><div class="t m0 x22 h15 y3d ffe fs3 fc0 sc0 ls0 ws0">1])</div><div class="t m0 x0 h6 y3f ff5 fs3 fc0 sc0 ls0 ws0">这个公式可以<span class="_ _2"></span>以右图的形<span class="_ _2"></span>式可视化<span class="_ _2"></span>。</div><div class="t m0 x0 h11 y40 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ffb fs1">神经<span class="_ _2"></span>元<span class="_ _2"></span>：<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>元<span class="_ _2"></span>是<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>网<span class="_ _2"></span>络的<span class="_ _2"></span>基<span class="_ _2"></span>本<span class="_ _2"></span>组<span class="_ _2"></span>成<span class="_ _2"></span>部<span class="_ _2"></span>分<span class="_ _2"></span>。<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>将<span class="_ _2"></span>看<span class="_ _2"></span>到<span class="_ _2"></span>，<span class="_ _2"></span>神</span></div><div class="t m0 x0 h13 y41 ffb fs1 fc0 sc0 ls0 ws0">经元可以是<span class="_ _2"></span>许多允许非线<span class="_ _2"></span>性在网络中累<span class="_ _2"></span>积的函数<span class="_ _2"></span>之一。</div><div class="t m0 x0 h11 y42 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="fff">→<span class="_ _0"> </span><span class="ffb fs1">图<span class="_ _5"> </span><span class="ffc">2<span class="_ _2"></span></span>：<span class="_ _2"></span>这<span class="_ _6"></span>幅<span class="_ _2"></span>图<span class="_ _2"></span>像<span class="_ _6"></span>捕<span class="_ _2"></span>捉<span class="_ _6"></span>了<span class="_ _2"></span>在<span class="_ _6"></span>一<span class="_ _2"></span>个<span class="_ _5"> </span><span class="ffc">sigmoid </span>神<span class="_ _6"></span>经<span class="_ _2"></span>元<span class="_ _6"></span>中<span class="_ _2"></span>，<span class="_ _6"></span>输<span class="_ _2"></span>入<span class="_ _2"></span>向</span></span></div><div class="t m0 x0 h12 y43 ffb fs1 fc0 sc0 ls0 ws0">量<span class="_ _10"> </span><span class="ffc">x </span>是如<span class="_ _2"></span>何被<span class="_ _2"></span>缩<span class="_ _2"></span>放，<span class="_ _2"></span>求和<span class="_ _2"></span>，<span class="_ _2"></span>添加<span class="_ _2"></span>到一<span class="_ _2"></span>个偏<span class="_ _2"></span>置<span class="_ _2"></span>单元<span class="_ _2"></span>，然<span class="_ _2"></span>后传<span class="_ _2"></span>递<span class="_ _2"></span>给挤<span class="_ _2"></span>压</div><div class="t m0 x0 h12 y44 ffc fs1 fc0 sc0 ls0 ws0">sigmoid <span class="ffb">函数<span class="_ _2"></span>的。</span></div></div><div class="c x23 y45 w6 h18"><div class="t m0 x7 h19 y46 ff7 fs0 fc0 sc0 ls0 ws0">1<span class="_ _7"> </span>No<span class="_ _a"></span>tes<span class="_ _7"> </span>info.</div></div><div class="c x23 y47 w7 h1a"><div class="t m0 x7 hb y48 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y47 w8 h1a"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>P16</div></div><div class="c x23 y49 w7 h1a"><div class="t m0 x7 hb y4a ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y49 w8 h1a"><div class="t m0 x7 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>-,<span class="_ _3"> </span>--:--</div></div><div class="c x23 y4b w7 h1b"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y4b w8 h1b"><div class="t m0 x7 h1c y48 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y4c w7 h1a"><div class="t m0 x7 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y4c w8 h1a"><div class="t m0 x7 h1c y4a ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y4d w6 h1d"><div class="t m0 x25 h1e y4e ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA</div><div class="t m0 x26 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">I</div></div><div class="c x23 y4f w6 h18"><div class="t m0 x7 h19 y50 ff7 fs0 fc0 sc0 ls0 ws0">1.1 Notes<span class="_ _7"> </span>inf<span class="_ _a"></span>o.</div></div><div class="c x23 y51 w7 h1a"><div class="t m0 x7 hb y52 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y51 w8 h1a"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>P17</div></div><div class="c x23 y53 w7 h1a"><div class="t m0 x7 hb y54 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y53 w8 h1a"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>28:30</div></div><div class="c x23 y55 w7 h1b"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y55 w8 h1b"><div class="t m0 x7 h1c y52 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y56 w7 h1a"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y56 w8 h1a"><div class="t m0 x7 h1c y57 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y58 w6 h1d"><div class="t m0 x25 h1e y59 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA</div><div class="t m0 x26 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">I</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y5a ffa fs6 fc0 sc0 ls0 ws0">❐</div><div class="t m0 x29 h1f y5b ff10 fs1 fc0 sc0 ls0 ws0">↑</div><div class="t m0 x2a h12 y5a ffb fs1 fc0 sc0 ls0 ws0">图<span class="_ _10"> </span><span class="ffc">1<span class="_ _2"></span></span>：<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>在<span class="_ _2"></span>这<span class="_ _2"></span>里<span class="_ _2"></span>看<span class="_ _2"></span>到<span class="_ _6"></span>非<span class="_ _2"></span>线<span class="_ _2"></span>性</div><div class="t m0 x28 h13 y5c ffb fs1 fc0 sc0 ls0 ws0">决<span class="_ _6"></span>策<span class="_ _6"></span>边<span class="_ _6"></span>界<span class="_ _6"></span>如<span class="_ _12"></span>何<span class="_ _6"></span>很<span class="_ _6"></span>好<span class="_ _6"></span>地<span class="_ _6"></span>分<span class="_ _12"></span>离<span class="_ _6"></span>数<span class="_ _6"></span>据<span class="_ _6"></span>。<span class="_ _6"></span>这</div><div class="t m0 x28 h13 y5d ffb fs1 fc0 sc0 ls0 ws0">就是神经网<span class="_ _2"></span>络的威力。</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg3.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h14 y5e ffd fs0 fc0 sc0 ls0 ws0">1.2<span class="_ _7"> </span>A<span class="_ _4"> </span>Single<span class="_ _7"> </span>Layer<span class="_ _4"> </span>of<span class="_ _7"> </span>Neurons</div><div class="t m0 x0 h6 y5f ff5 fs3 fc0 sc0 ls0 ws0">我<span class="_ _2"></span>们<span class="_ _6"></span>将<span class="_ _2"></span>上<span class="_ _6"></span>述<span class="_ _6"></span>思<span class="_ _2"></span>想<span class="_ _6"></span>扩<span class="_ _2"></span>展<span class="_ _6"></span>到<span class="_ _6"></span>多<span class="_ _2"></span>个<span class="_ _6"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>，<span class="_ _6"></span>考<span class="_ _2"></span>虑<span class="_ _6"></span>输<span class="_ _2"></span>入</div><div class="t m0 x2b h15 y60 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xd h6 y5f ff5 fs3 fc0 sc0 ls0 ws0">作<span class="_ _2"></span>为<span class="_ _6"></span>多<span class="_ _2"></span>个<span class="_ _6"></span>这<span class="_ _6"></span>样</div><div class="t m0 x0 h5 y61 ff5 fs3 fc0 sc0 ls0 ws0">的神经元的输<span class="_ _2"></span>入，如右图<span class="_ _5"> </span><span class="ff4">3 </span>所示。</div><div class="t m0 x0 h15 y62 ff5 fs3 fc0 sc0 ls0 ws0">如<span class="_ _6"></span>果<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>定<span class="_ _6"></span>义<span class="_ _6"></span>不<span class="_ _6"></span>同<span class="_ _12"></span>的<span class="_ _6"></span>神<span class="_ _2"></span>经<span class="_ _12"></span>元<span class="_ _6"></span>的<span class="_ _6"></span>权<span class="_ _6"></span>值<span class="_ _6"></span>为<span class="_ _8"> </span><span class="ffe">{w</span></div><div class="t m0 x2c h16 y63 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2d h15 y62 ffe fs3 fc0 sc0 ls0 ws0">,<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _1"></span>,<span class="_ _1"></span>w</div><div class="t m0 x5 h16 y63 ffe fs7 fc0 sc0 ls0 ws0">(m)</div><div class="t m0 x19 h15 y62 ffe fs3 fc0 sc0 ls0 ws0">}<span class="_ _8"></span><span class="ff5">、<span class="_ _6"></span>偏<span class="_ _6"></span>置<span class="_ _6"></span>为</span></div><div class="t m0 x0 h15 y64 ffe fs3 fc0 sc0 ls0 ws0">{b</div><div class="t m0 x2e h16 y65 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13 h15 y64 ffe fs3 fc0 sc0 ls0 ws0">,<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _1"></span>,<span class="_ _1"></span>b</div><div class="t m0 x2f h16 y65 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x30 h15 y64 ffe fs3 fc0 sc0 ls0 ws0">}</div><div class="t m0 x31 h6 y66 ff5 fs3 fc0 sc0 ls0 ws0">和相对应的激<span class="_ _2"></span>活输出为</div><div class="t m0 x32 h15 y64 ffe fs3 fc0 sc0 ls0 ws0">{a</div><div class="t m0 x1c h16 y65 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1d h15 y64 ffe fs3 fc0 sc0 ls0 ws0">,<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _1"></span>,<span class="_ _1"></span>a</div><div class="t m0 x33 h16 y65 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x34 h15 y64 ffe fs3 fc0 sc0 ls0 ws0">}</div><div class="t m0 x35 h6 y66 ff5 fs3 fc0 sc0 ls0 ws0">：</div><div class="t m0 x36 h15 y67 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x37 h16 y68 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x38 h15 y67 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x39 h15 y69 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3a h15 y6a ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>ex<span class="_ _2"></span>p − w</div><div class="t m0 x3b h16 y6b ffe fs7 fc0 sc0 ls0 ws0">(1)T</div><div class="t m0 x3c h15 y6c ffe fs3 fc0 sc0 ls0 ws0">x<span class="_ _1"></span>+<span class="_ _3"></span>b</div><div class="t m0 x3d h15 y6d ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x1e h15 y6e ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x3e h16 y6f ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x38 h15 y6e ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x39 h15 y27 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3a h15 y70 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>ex<span class="_ _2"></span>p</div><div class="t m0 x3f h15 y71 ffe fs3 fc0 sc0 ls0 ws0">− w</div><div class="t m0 x3b h16 y72 ffe fs7 fc0 sc0 ls0 ws0">(m)T</div><div class="t m0 x40 h15 y71 ffe fs3 fc0 sc0 ls0 ws0">x<span class="_ _1"></span>+<span class="_ _3"></span>b</div><div class="t m0 x0 h6 y73 ff5 fs3 fc0 sc0 ls0 ws0">让我们定义简<span class="_ _2"></span>化公式以便于<span class="_ _2"></span>更好地表<span class="_ _2"></span>达复杂的网络<span class="_ _2"></span>：</div><div class="t m0 x3 h15 y74 ffe fs3 fc0 sc0 ls0 ws0">σ<span class="_ _13"> </span>z<span class="_ _d"> </span>=</div><div class="t m0 x32 h15 y75 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x41 h15 y76 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>e<span class="_ _2"></span>xp</div><div class="t m0 x42 h15 y77 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x3c h16 y78 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x43 h15 y79 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x32 h15 y7a ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x41 h15 y7b ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>ex<span class="_ _2"></span>p</div><div class="t m0 x1d h15 y7c ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x44 h16 y7d ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x45 h15 y7e ffe fs3 fc0 sc0 ls0 ws0">b<span class="_ _4"></span>=</div><div class="t m0 x41 h15 y7f ffe fs3 fc0 sc0 ls0 ws0">b</div><div class="t m0 x3f h16 y80 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x46 h15 y81 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x41 h15 y82 ffe fs3 fc0 sc0 ls0 ws0">b</div><div class="t m0 x3f h16 y83 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x39 h15 y7e ffe fs3 fc0 sc0 ls0 ws0">∈<span class="_ _4"></span>ℝ</div><div class="t m0 x47 h16 y84 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x38 h15 y85 ffe fs3 fc0 sc0 ls0 ws0">W<span class="_ _4"></span>=</div><div class="t m0 x48 h15 y86 ffe fs3 fc0 sc0 ls0 ws0">−w</div><div class="t m0 x49 h16 y87 ffe fs7 fc0 sc0 ls0 ws0">(1)T</div><div class="t m0 x1b h15 y86 ffe fs3 fc0 sc0 ls0 ws0">−</div><div class="t m0 x4a h15 y88 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x48 h15 y89 ffe fs3 fc0 sc0 ls0 ws0">−w</div><div class="t m0 x4b h16 y8a ffe fs7 fc0 sc0 ls0 ws0">(m)T</div><div class="t m0 x1b h15 y89 ffe fs3 fc0 sc0 ls0 ws0">−</div><div class="t m0 x1c h15 y85 ffe fs3 fc0 sc0 ls0 ws0">∈<span class="_ _4"></span>ℝ</div><div class="t m0 x11 h16 y8b ffe fs7 fc0 sc0 ls0 ws0">m×n</div><div class="t m0 x0 h6 y8c ff5 fs3 fc0 sc0 ls0 ws0">我们现在可以<span class="_ _2"></span>将缩放和偏差<span class="_ _2"></span>的输出写<span class="_ _2"></span>成：</div><div class="t m0 x4c h15 y8d ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>=<span class="_ _7"></span><span class="_ _3"></span>+<span class="_ _3"></span></div><div class="t m0 x0 h5 y8e ff5 fs3 fc0 sc0 ls0 ws0">激活函数<span class="_ _4"> </span><span class="ff4">sigmoid<span class="_ _4"> </span></span>可以变为<span class="_ _2"></span>如下形式<span class="_ _2"></span>：</div><div class="t m0 x1f h15 y8f ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x3 h16 y90 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4d h15 y91 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x4e h15 y92 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x4d h16 y93 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x45 h15 y94 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>σ<span class="_ _14"> </span>z<span class="_ _d"> </span>=<span class="_ _4"></span>σ<span class="_ _13"> </span>Wx<span class="_ _3"></span>+<span class="_ _3"></span>b</div><div class="t m0 x0 h6 y95 ff5 fs3 fc0 sc0 ls0 ws0">那么这些激活<span class="_ _2"></span>的作用是什么<span class="_ _2"></span>呢？可以<span class="_ _2"></span>把这些激活看<span class="_ _2"></span>作是一些加权</div><div class="t m0 x0 h6 y96 ff5 fs3 fc0 sc0 ls0 ws0">特征组合存在<span class="_ _2"></span>的指标。然后<span class="_ _2"></span>我们可以<span class="_ _2"></span>使用这些激活<span class="_ _2"></span>的组合来执行</div><div class="t m0 x0 h6 y97 ff5 fs3 fc0 sc0 ls0 ws0">分类任务。</div><div class="t m0 x0 h14 y98 ffd fs0 fc0 sc0 ls0 ws0">1.3<span class="_ _7"> </span>Feed<span class="_ _a"></span>-forward<span class="_ _7"> </span>Comput<span class="_ _a"></span>ation</div><div class="t m0 x0 h6 y99 ff5 fs3 fc0 sc0 ls0 ws0">到<span class="_ _11"> </span>目<span class="_ _11"> </span>前<span class="_ _11"> </span>为<span class="_ _11"> </span>止<span class="_ _11"> </span>我<span class="_ _11"> </span>们<span class="_ _11"> </span>知<span class="_ _11"> </span>道<span class="_ _11"> </span>一<span class="_ _11"> </span>个<span class="_ _11"> </span>输<span class="_ _1"> </span>入<span class="_ _11"> </span>向<span class="_ _11"> </span>量</div><div class="t m0 x11 h15 y9a ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>∈<span class="_ _7"></span>ℝ</div><div class="t m0 x35 h16 y9b ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x4f h6 y99 ff5 fs3 fc0 sc0 ls0 ws0">可<span class="_ _11"> </span>以<span class="_ _11"> </span>经<span class="_ _11"> </span>过<span class="_ _11"> </span>一<span class="_ _11"> </span>层</div><div class="t m0 x0 h15 y9c ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x50 h6 y9d ff5 fs3 fc0 sc0 ls0 ws0">单元<span class="_ _6"></span>的<span class="_ _2"></span>变换<span class="_ _2"></span>得<span class="_ _6"></span>到<span class="_ _2"></span>激活<span class="_ _6"></span>输<span class="_ _2"></span>出</div><div class="t m0 x43 h15 y9c ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>∈<span class="_ _7"></span>ℝ</div><div class="t m0 x11 h16 y9e ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x51 h6 y9d ff5 fs3 fc0 sc0 ls0 ws0">。但<span class="_ _6"></span>是<span class="_ _2"></span>这么<span class="_ _2"></span>做<span class="_ _6"></span>的<span class="_ _2"></span>直觉</div><div class="t m0 x0 h5 y9f ff5 fs3 fc0 sc0 ls0 ws0">是什么呢？让<span class="_ _2"></span>我们考虑一个<span class="_ _15"> </span><span class="ff4">NLP<span class="_ _4"> </span></span>中的命名实体<span class="_ _2"></span>识别问题为例<span class="_ _2"></span>：</div><div class="t m0 x0 h15 ya0 ffe fs3 fc0 sc0 ls0 ws0">Museums<span class="_ _3"></span>in<span class="_ _3"></span>Paris<span class="_ _3"></span>are<span class="_ _3"></span>am<span class="_ _2"></span>azing</div></div><div class="c x23 ya1 w6 h18"><div class="t m0 x7 h19 ya2 ff7 fs0 fc0 sc0 ls0 ws0">1.2 Notes<span class="_ _15"> </span>info.</div></div><div class="c x23 ya3 w7 h1a"><div class="t m0 x7 hb ya4 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 ya3 w8 h1a"><div class="t m0 x7 hb ya4 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>P18</div></div><div class="c x23 ya5 w7 h1a"><div class="t m0 x7 hb ya6 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 ya5 w8 h1a"><div class="t m0 x7 hb ya6 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>-,<span class="_ _3"> </span>--:00</div></div><div class="c x23 ya7 w7 h1b"><div class="t m0 x7 hb ya4 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 ya7 w8 h1b"><div class="t m0 x7 h1c ya8 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 ya9 w7 h1a"><div class="t m0 x7 hb ya6 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 ya9 w8 h1a"><div class="t m0 x7 h1c ya6 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 yaa w6 h1d"><div class="t m0 x25 hb yab ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA<span class="fs5">I</span></div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 yac ffa fs6 fc0 sc0 ls0 ws0">❐</div><div class="t m0 x29 h1f yad ff10 fs1 fc0 sc0 ls0 ws0">↑</div><div class="t m0 x13 h12 yac ffb fs1 fc0 sc0 ls0 ws0">图<span class="_ _16"> </span><span class="ffc">3<span class="_ _12"></span></span>：<span class="_ _17"> </span>这<span class="_ _17"></span>幅<span class="_ _6"></span>图<span class="_ _17"> </span>像<span class="_ _17"></span>捕<span class="_ _12"></span>捉<span class="_ _17"></span>了<span class="_ _12"></span>多<span class="_ _17"> </span>个</div><div class="t m0 x28 h12 yae ffc fs1 fc0 sc0 ls0 ws0">sigmoid<span class="_ _3"> </span><span class="ffb">单<span class="_ _6"></span>元<span class="_ _2"></span>如<span class="_ _6"></span>何<span class="_ _2"></span>堆<span class="_ _6"></span>叠<span class="_ _2"></span>在<span class="_ _6"></span>右<span class="_ _2"></span>侧<span class="_ _2"></span>，<span class="_ _6"></span>所<span class="_ _6"></span>有</span></div><div class="t m0 x28 h12 yaf ffb fs1 fc0 sc0 ls0 ws0">这些单元都<span class="_ _2"></span>接收相同的输<span class="_ _2"></span>入<span class="_ _10"> </span><span class="ffc">x</span>。</div></div><div class="c x23 yb0 w6 h18"><div class="t m0 x7 h19 yb1 ff7 fs0 fc0 sc0 ls0 ws0">1.3 Notes<span class="_ _15"> </span>info.</div></div><div class="c x23 yb2 w7 h1a"><div class="t m0 x7 hb yb3 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 yb2 w8 h1a"><div class="t m0 x7 hb yb3 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>P20</div></div><div class="c x23 yb4 w7 h1a"><div class="t m0 x7 hb y52 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 yb4 w8 h1a"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>33:00</div></div><div class="c x23 yb5 w7 h1b"><div class="t m0 x7 hb yb3 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 yb5 w8 h1b"><div class="t m0 x7 h1c yb6 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 yb7 w7 h1a"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 yb7 w8 h1a"><div class="t m0 x7 h1c y52 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 yb8 w6 h1d"><div class="t m0 x25 hb yb9 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA<span class="fs5">I</span></div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x0 y0 w1 hd" alt="" src="bg4.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h6 yba ff5 fs3 fc0 sc0 ls0 ws0">这<span class="_ _2"></span>里<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>想<span class="_ _6"></span>判<span class="_ _6"></span>断<span class="_ _2"></span>中<span class="_ _6"></span>心<span class="_ _6"></span>词</div><div class="t m0 x52 h15 ybb ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x46 h6 yba ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>不<span class="_ _6"></span>是<span class="_ _6"></span>以<span class="_ _6"></span>命<span class="_ _6"></span>名<span class="_ _6"></span>实<span class="_ _2"></span>体<span class="_ _6"></span>。<span class="_ _6"></span>在<span class="_ _6"></span>这<span class="_ _6"></span>种<span class="_ _2"></span>情<span class="_ _12"></span>况</div><div class="t m0 x0 h6 ybc ff5 fs3 fc0 sc0 ls0 ws0">下，我们很可<span class="_ _2"></span>能不仅想要捕<span class="_ _2"></span>捉窗口中<span class="_ _2"></span>单词的单词向<span class="_ _2"></span>量，还想要捕</div><div class="t m0 x0 h6 ybd ff5 fs3 fc0 sc0 ls0 ws0">捉<span class="_ _2"></span>单<span class="_ _6"></span>词<span class="_ _6"></span>之<span class="_ _2"></span>间<span class="_ _6"></span>的<span class="_ _6"></span>一<span class="_ _6"></span>些<span class="_ _2"></span>其<span class="_ _6"></span>他<span class="_ _6"></span>交<span class="_ _6"></span>互<span class="_ _2"></span>，<span class="_ _6"></span>以<span class="_ _6"></span>便<span class="_ _2"></span>进<span class="_ _6"></span>行<span class="_ _6"></span>分<span class="_ _6"></span>类<span class="_ _2"></span>。<span class="_ _6"></span>例<span class="_ _6"></span>如<span class="_ _2"></span>，<span class="_ _6"></span>可<span class="_ _6"></span>能<span class="_ _6"></span>只<span class="_ _2"></span>有</div><div class="t m0 x0 h15 ybe ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x53 h15 ybf ff5 fs3 fc0 sc0 ls0 ws0">是第一<span class="_ _2"></span>个<span class="_ _2"></span>单词<span class="_ _2"></span>和<span class="_ _4"> </span><span class="ffe"><span class="_ _4"></span></span>是<span class="_ _2"></span>第二<span class="_ _2"></span>个<span class="_ _2"></span>单词的<span class="_ _2"></span>时候<span class="_ _2"></span>，</div><div class="t m0 x54 h15 ybe ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xe h6 ybf ff5 fs3 fc0 sc0 ls0 ws0">才是</div><div class="t m0 x0 h5 yc0 ff5 fs3 fc0 sc0 ls0 ws0">命名<span class="_ _6"></span>实<span class="_ _2"></span>体。<span class="_ _6"></span>这<span class="_ _2"></span>样<span class="_ _2"></span>的非<span class="_ _6"></span>线<span class="_ _2"></span>性<span class="_ _2"></span>决<span class="_ _2"></span>策<span class="_ _2"></span>通<span class="_ _2"></span>常<span class="_ _2"></span>不<span class="_ _2"></span>能<span class="_ _2"></span>被<span class="_ _2"></span>直<span class="_ _2"></span>接<span class="_ _2"></span>提<span class="_ _2"></span>供<span class="_ _2"></span>给<span class="_ _5"> </span><span class="ff4">Softmax</span></div><div class="t m0 x0 h5 yc1 ff5 fs3 fc0 sc0 ls0 ws0">函<span class="_ _6"></span>数<span class="_ _12"></span>的<span class="_ _12"></span>输<span class="_ _6"></span>入<span class="_ _12"></span>捕<span class="_ _12"></span>获<span class="_ _6"></span>，<span class="_ _12"></span>而<span class="_ _12"></span>是<span class="_ _6"></span>需<span class="_ _12"></span>要<span class="_ _12"></span>第<span class="_ _16"> </span><span class="ff4">1.2<span class="_ _16"> </span></span>节<span class="_ _6"></span>中<span class="_ _12"></span>讨<span class="_ _6"></span>论<span class="_ _12"></span>的<span class="_ _12"></span>中<span class="_ _12"></span>间<span class="_ _6"></span>层<span class="_ _12"></span>进<span class="_ _6"></span>行<span class="_ _12"></span>评</div><div class="t m0 x0 h6 yc2 ff5 fs3 fc0 sc0 ls0 ws0">分。<span class="_ _2"></span>因<span class="_ _2"></span>此<span class="_ _2"></span>，我<span class="_ _2"></span>们<span class="_ _2"></span>可<span class="_ _2"></span>以<span class="_ _2"></span>使用<span class="_ _2"></span>另<span class="_ _2"></span>一<span class="_ _2"></span>个矩<span class="_ _2"></span>阵</div><div class="t m0 x47 h15 yc3 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>∈<span class="_ _15"></span>ℝ</div><div class="t m0 x55 h16 yc4 ffe fs7 fc0 sc0 ls0 ws0">×1</div><div class="t m0 x2b h6 yc2 ff5 fs3 fc0 sc0 ls0 ws0">与激<span class="_ _2"></span>活<span class="_ _2"></span>输<span class="_ _2"></span>出计<span class="_ _2"></span>算</div><div class="t m0 x0 h6 yc5 ff5 fs3 fc0 sc0 ls0 ws0">得到未归一化<span class="_ _2"></span>的得分用于分<span class="_ _2"></span>类任务：</div><div class="t m0 x4e h15 yc6 ffe fs3 fc0 sc0 ls0 ws0">s<span class="_ _4"></span>=<span class="_ _15"></span>U</div><div class="t m0 x48 h16 yc7 ffe fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x56 h15 yc6 ffe fs3 fc0 sc0 ls0 ws0">a<span class="_ _4"></span>=<span class="_ _15"></span>U</div><div class="t m0 x57 h16 yc7 ffe fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x1b h15 yc6 ffe fs3 fc0 sc0 ls0 ws0">f(Wx<span class="_ _3"></span>+<span class="_ _3"></span>b)</div><div class="t m0 x0 h15 yc8 ff5 fs3 fc0 sc0 ls0 ws0">其中<span class="_ _4"> </span><span class="ffe"><span class="_ _4"></span></span>是激活函数（例如<span class="_ _4"> </span><span class="ff4">sigmoid<span class="_ _15"> </span></span>函数）。</div><div class="t m0 x0 h14 yc9 ffd fs0 fc0 sc0 ls0 ws0">1.4<span class="_ _4"> </span>Ma<span class="_ _2"></span>ximum<span class="_ _15"> </span>Margin<span class="_ _15"> </span>Objective<span class="_ _15"> </span>Function</div><div class="t m0 x0 h6 yca ff5 fs3 fc0 sc0 ls0 ws0">类似很多的机<span class="_ _2"></span>器学习模型，<span class="_ _2"></span>神经网络<span class="_ _2"></span>需要一个优化<span class="_ _2"></span>目标函数，一</div><div class="t m0 x0 h6 ycb ff5 fs3 fc0 sc0 ls0 ws0">个我们想要最<span class="_ _2"></span>小化或最大化<span class="_ _2"></span>的误差。<span class="_ _2"></span>这里我们讨论<span class="_ _2"></span>一个常用的误</div><div class="t m0 x0 h5 ycc ff5 fs3 fc0 sc0 ls0 ws0">差度<span class="_ _2"></span>量<span class="_ _2"></span>方<span class="_ _2"></span>法<span class="_ _2"></span>：<span class="_ _2"></span><span class="ff4">maxi<span class="_ _2"></span>mum<span class="_ _15"> </span>margin<span class="_ _15"> </span>obj<span class="_ _2"></span>ective<span class="_ _4"> </span></span>最<span class="_ _2"></span>大<span class="_ _2"></span>间<span class="_ _2"></span>隔<span class="_ _2"></span>目<span class="_ _2"></span>标函<span class="_ _2"></span>数<span class="_ _6"></span>。</div><div class="t m0 x0 h5 ycd ff5 fs3 fc0 sc0 ls0 ws0">使<span class="_ _2"></span>用<span class="_ _2"></span>这<span class="_ _2"></span>个<span class="_ _2"></span>目<span class="_ _6"></span>标<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _2"></span>的<span class="_ _6"></span>背<span class="_ _2"></span>后<span class="_ _2"></span>的<span class="_ _2"></span>思<span class="_ _6"></span>想<span class="_ _2"></span>是<span class="_ _2"></span>保<span class="_ _2"></span>证<span class="_ _2"></span>对<span class="_ _6"></span><span class="ff4">“<span class="_ _2"></span></span>真<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>标<span class="_ _2"></span>签<span class="_ _6"></span>数<span class="_ _2"></span>据<span class="_ _2"></span>的<span class="_ _2"></span>计<span class="_ _6"></span>算</div><div class="t m0 x0 h5 yce ff5 fs3 fc0 sc0 ls0 ws0">得分要比<span class="ff4">“</span>假<span class="ff4">”<span class="_ _2"></span></span>标签数据<span class="_ _2"></span>的计算得分要<span class="_ _2"></span>高。</div><div class="t m0 x0 h5 ycf ff5 fs3 fc0 sc0 ls0 ws0">回<span class="_ _10"> </span>到<span class="_ _14"> </span>前<span class="_ _10"> </span>面<span class="_ _14"> </span>的<span class="_ _10"> </span>例<span class="_ _14"> </span>子 ，<span class="_ _14"> </span>如<span class="_ _14"> </span>果 我<span class="_ _14"> </span>们 令<span class="_ _13"> </span><span class="ff4">“ </span>真<span class="_ _14"> </span><span class="ff4">”<span class="_ _10"> </span></span>标<span class="_ _14"> </span>签<span class="_ _10"> </span>窗<span class="_ _14"> </span>口</div><div class="t m0 x0 h15 yd0 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _3"></span><span class="_ _2"></span><span class="_ _1"></span><span class="_ _2"></span><span class="_ _3"></span><span class="_ _3"></span><span class="_ _2"></span></div><div class="t m0 x57 h5 yd1 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _2"></span>得<span class="_ _2"></span>分<span class="_ _6"></span>为<span class="_ _7"> </span><span class="ff4">s<span class="_ _15"> </span></span>，<span class="_ _6"></span>令<span class="_ _2"></span><span class="ff4">“<span class="_ _6"></span></span>假<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>标<span class="_ _6"></span>签</div><div class="t m0 x0 h6 yd2 ff5 fs3 fc0 sc0 ls0 ws0">窗<span class="_ _2"></span>口</div><div class="t m0 x58 h5 yd3 ff4 fs3 fc0 sc0 ls0 ws0">Not<span class="_ _4"> </span>all<span class="_ _4"> </span>museums<span class="_ _4"> </span>in<span class="_ _4"> </span>Paris</div><div class="t m0 x59 h6 yd2 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _6"></span>得<span class="_ _6"></span>分<span class="_ _2"></span>为</div><div class="t m0 x5a h15 yd3 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b h16 yd4 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 xd h6 yd2 ff5 fs3 fc0 sc0 ls0 ws0">（<span class="_ _2"></span>下<span class="_ _6"></span>标</div><div class="t m0 x16 h15 yd3 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xe h6 yd2 ff5 fs3 fc0 sc0 ls0 ws0">表<span class="_ _2"></span>示</div><div class="t m0 x0 h5 yd5 ff5 fs3 fc0 sc0 ls0 ws0">这个这个窗口<span class="_ _4"> </span><span class="ff4">corrup<span class="_ _2"></span>t<span class="_ _4"> </span></span>）</div><div class="t m0 x0 h6 yd6 ff5 fs3 fc0 sc0 ls0 ws0">然后<span class="_ _2"></span>，<span class="_ _2"></span>我<span class="_ _2"></span>们对<span class="_ _2"></span>目<span class="_ _2"></span>标<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _2"></span>最<span class="_ _2"></span>大化</div><div class="t m0 x46 h15 yd7 ffe fs3 fc0 sc0 ls0 ws0">(<span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x5c h16 yd8 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x5d h15 yd7 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x44 h6 yd6 ff5 fs3 fc0 sc0 ls0 ws0">或者<span class="_ _2"></span>最<span class="_ _2"></span>小<span class="_ _2"></span>化</div><div class="t m0 x5e h15 yd7 ffe fs3 fc0 sc0 ls0 ws0">(</div><div class="t m0 x54 h16 yd8 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x1a h15 yd7 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>)</div><div class="t m0 xe h6 yd6 ff5 fs3 fc0 sc0 ls0 ws0">。然</div><div class="t m0 x0 h6 yd9 ff5 fs3 fc0 sc0 ls0 ws0">而，<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>修改<span class="_ _2"></span>目<span class="_ _2"></span>标<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _2"></span>来<span class="_ _2"></span>保<span class="_ _2"></span>证<span class="_ _2"></span>误差<span class="_ _2"></span>仅<span class="_ _2"></span>在</div><div class="t m0 x40 h15 yda ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c h16 ydb ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x5f h15 yd9 ffe fs3 fc0 sc0 ls0 ws0">&gt;<span class="_ _4"></span><span class="_ _15"></span>⇒<span class="_ _15"></span>(</div><div class="t m0 x5 h15 yda ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e h16 ydb ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x60 h15 yd9 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>)<span class="_ _4"></span>&gt;<span class="_ _15"></span>0<span class="_ _7"></span><span class="ff5">才</span></div><div class="t m0 x0 h5 ydc ff5 fs3 fc0 sc0 ls0 ws0">进<span class="_ _2"></span>行<span class="_ _2"></span>计<span class="_ _2"></span>算<span class="_ _2"></span>。<span class="_ _6"></span>这<span class="_ _2"></span>样<span class="_ _2"></span>做<span class="_ _2"></span>的<span class="_ _6"></span>直<span class="_ _2"></span>觉<span class="_ _2"></span>是<span class="_ _2"></span>，<span class="_ _6"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>只<span class="_ _2"></span>关<span class="_ _2"></span>心<span class="_ _6"></span><span class="ff4">“<span class="_ _2"></span></span>正<span class="_ _2"></span>确<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>数<span class="_ _6"></span>据<span class="_ _2"></span>点<span class="_ _2"></span>的<span class="_ _2"></span>得<span class="_ _6"></span>分</div><div class="t m0 x0 h5 ydd ff5 fs3 fc0 sc0 ls0 ws0">高于<span class="_ _6"></span><span class="ff4">“<span class="_ _2"></span></span>错<span class="_ _2"></span>误<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>数<span class="_ _2"></span>据<span class="_ _2"></span>点<span class="_ _2"></span>，<span class="_ _2"></span>其<span class="_ _2"></span>余<span class="_ _6"></span>的都<span class="_ _6"></span>不<span class="_ _2"></span>重<span class="_ _2"></span>要<span class="_ _2"></span>。<span class="_ _2"></span>因<span class="_ _2"></span>此<span class="_ _2"></span>，<span class="_ _2"></span>当</div><div class="t m0 x61 h15 yde ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x62 h16 ydf ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x19 h15 yde ffe fs3 fc0 sc0 ls0 ws0">&gt;<span class="_ _4"></span></div><div class="t m0 x63 h6 ydd ff5 fs3 fc0 sc0 ls0 ws0">则误<span class="_ _6"></span>差</div><div class="t m0 x0 h6 ye0 ff5 fs3 fc0 sc0 ls0 ws0">为</div><div class="t m0 x13 h15 ye1 ffe fs3 fc0 sc0 ls0 ws0">(</div><div class="t m0 x2 h16 ye2 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x64 h15 ye1 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>)</div><div class="t m0 x65 h5 ye0 ff5 fs3 fc0 sc0 ls0 ws0">，否则为<span class="_ _4"> </span><span class="ff4">0<span class="_ _4"> </span></span>。因此，我们<span class="_ _2"></span>的优化的<span class="_ _2"></span>目标函数现在<span class="_ _2"></span>为：</div><div class="t m0 x37 h15 ye3 ffe fs3 fc0 sc0 ls0 ws0">minimize <span class="_ _2"></span>J<span class="_ _4"></span>=<span class="_ _4"></span>m<span class="_ _2"></span>ax<span class="_ _2"></span> (s</div><div class="t m0 x1d h16 ye4 ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x3c h15 ye3 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>s,<span class="_ _11"></span>0)</div><div class="t m0 x0 h6 ye5 ff5 fs3 fc0 sc0 ls0 ws0">然而，上面的<span class="_ _2"></span>优化目标函数<span class="_ _2"></span>是有风险<span class="_ _2"></span>的，因为它不<span class="_ _2"></span>能创造一个安</div><div class="t m0 x0 h5 ye6 ff5 fs3 fc0 sc0 ls0 ws0">全的<span class="_ _2"></span>间<span class="_ _2"></span>隔<span class="_ _2"></span>。我<span class="_ _2"></span>们<span class="_ _2"></span>希<span class="_ _2"></span>望<span class="_ _2"></span><span class="ff4">“</span>真<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>数据<span class="_ _2"></span>要<span class="_ _2"></span>比<span class="_ _2"></span><span class="ff4">“</span>假<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>数<span class="_ _2"></span>据的<span class="_ _2"></span>得<span class="_ _2"></span>分<span class="_ _2"></span>大于<span class="_ _2"></span>某<span class="_ _2"></span>个<span class="_ _2"></span>正</div><div class="t m0 x0 h6 ye7 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _6"></span>间<span class="_ _6"></span>隔</div><div class="t m0 x66 h15 ye8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x30 h6 ye7 ff5 fs3 fc0 sc0 ls0 ws0">。<span class="_ _6"></span>换<span class="_ _6"></span>而<span class="_ _6"></span>言<span class="_ _6"></span>之<span class="_ _6"></span>，<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>想<span class="_ _6"></span>要<span class="_ _6"></span>误<span class="_ _6"></span>差<span class="_ _6"></span>在</div><div class="t m0 x2c h15 ye8 ffe fs3 fc0 sc0 ls0 ws0">(<span class="_ _3"></span>−<span class="_ _3"></span></div><div class="t m0 x67 h16 ye9 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x68 h15 ye8 ffe fs3 fc0 sc0 ls0 ws0">&lt;<span class="_ _4"></span>)</div><div class="t m0 x1a h6 ye7 ff5 fs3 fc0 sc0 ls0 ws0">就<span class="_ _6"></span>开<span class="_ _6"></span>始<span class="_ _6"></span>计</div><div class="t m0 x0 h15 yea ff5 fs3 fc0 sc0 ls0 ws0">算，<span class="_ _2"></span>而<span class="_ _2"></span>不<span class="_ _2"></span>是当<span class="_ _7"> </span><span class="ffe">(<span class="_ _3"></span>−</span></div><div class="t m0 x69 h15 yeb ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x4e h16 yec ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h15 yea ffe fs3 fc0 sc0 ls0 ws0">&lt;<span class="_ _4"></span>0)<span class="_ _15"></span><span class="ff5">时<span class="_ _2"></span>就<span class="_ _2"></span>计<span class="_ _2"></span>算。<span class="_ _2"></span>因<span class="_ _2"></span>此<span class="_ _2"></span>，<span class="_ _2"></span>我们<span class="_ _2"></span>修<span class="_ _2"></span>改<span class="_ _2"></span>优<span class="_ _2"></span>化目<span class="_ _2"></span>标</span></div><div class="t m0 x0 h6 yed ff5 fs3 fc0 sc0 ls0 ws0">函数为：</div><div class="t m0 x6a h15 yee ffe fs3 fc0 sc0 ls0 ws0">minimize<span class="_ _2"></span> J<span class="_ _4"></span>=<span class="_ _15"></span>max<span class="_ _2"></span> (Δ<span class="_ _3"></span>+<span class="_ _3"></span>s</div><div class="t m0 x6b h16 yef ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x2c h15 yee ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>s,<span class="_ _11"></span>0)</div><div class="t m0 x0 h6 yf0 ff5 fs3 fc0 sc0 ls0 ws0">我们可以把<span class="_ _2"></span>这个间<span class="_ _2"></span>隔缩放使得</div><div class="t m0 x4a h15 yf1 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _4"></span>=<span class="_ _15"></span>1</div><div class="t m0 x5c h6 yf0 ff5 fs3 fc0 sc0 ls0 ws0">，让其他参<span class="_ _2"></span>数在优<span class="_ _2"></span>化过程中</div><div class="t m0 x0 h6 yf2 ff5 fs3 fc0 sc0 ls0 ws0">自动进行调整<span class="_ _2"></span>，并且不会影<span class="_ _2"></span>响模型的<span class="_ _2"></span>表现。如果想<span class="_ _2"></span>更多地了解这</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 yf3 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _8"> </span><span class="ffb fs1">维度<span class="_ _2"></span>分析：</span></div><div class="t m0 x28 h12 yf4 ffb fs1 fc0 sc0 ls0 ws0">如<span class="_ _6"></span>果<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>使<span class="_ _6"></span>用<span class="_ _7"> </span><span class="ffc">4<span class="_ _4"> </span></span>维<span class="_ _6"></span>的<span class="_ _6"></span>词<span class="_ _6"></span>向<span class="_ _6"></span>量<span class="_ _6"></span>来<span class="_ _6"></span>表<span class="_ _6"></span>示</div><div class="t m0 x28 h12 yf5 ffb fs1 fc0 sc0 ls0 ws0">每<span class="_ _6"></span>个<span class="_ _6"></span>单<span class="_ _6"></span>词<span class="_ _6"></span>并<span class="_ _6"></span>使<span class="_ _6"></span>用<span class="_ _7"> </span><span class="ffc">5<span class="_ _4"> </span></span>个<span class="_ _6"></span>词<span class="_ _6"></span>的<span class="_ _6"></span>窗<span class="_ _6"></span>口<span class="_ _12"></span>，<span class="_ _2"></span>则</div><div class="t m0 x28 h13 yf6 ffb fs1 fc0 sc0 ls0 ws0">输入是</div><div class="t m0 x6c h20 yf7 ffe fs1 fc0 sc0 ls0 ws0">x<span class="_ _4"></span>∈<span class="_ _4"></span>ℝ</div><div class="t m0 x6d h21 yf8 ffe fsa fc0 sc0 ls0 ws0">20</div><div class="t m0 x6e h13 yf6 ffb fs1 fc0 sc0 ls0 ws0">。</div><div class="t m0 x28 h12 yf9 ffb fs1 fc0 sc0 ls0 ws0">如<span class="_ _2"></span>果<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _6"></span>在<span class="_ _2"></span>隐<span class="_ _6"></span>藏层<span class="_ _6"></span>使<span class="_ _2"></span>用<span class="_ _4"> </span><span class="ffc">8<span class="_ _4"> </span></span>个<span class="_ _4"> </span><span class="ffc">sigmoi<span class="_ _2"></span>d</span></div><div class="t m0 x28 h13 yfa ffb fs1 fc0 sc0 ls0 ws0">单<span class="_ _6"></span>元<span class="_ _6"></span>和<span class="_ _6"></span>从<span class="_ _6"></span>激<span class="_ _12"></span>活<span class="_ _6"></span>函<span class="_ _6"></span>数<span class="_ _6"></span>中<span class="_ _6"></span>生<span class="_ _12"></span>成<span class="_ _6"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>分<span class="_ _6"></span>数</div><div class="t m0 x28 h20 yfb ffb fs1 fc0 sc0 ls0 ws0">输<span class="_ _12"></span>出<span class="_ _17"></span>，<span class="_ _6"></span>其<span class="_ _17"></span>中<span class="_ _8"> </span><span class="ffe">W<span class="_ _15"></span>∈</span></div><div class="t m0 x6f h20 yfc ffe fs1 fc0 sc0 ls0 ws0">ℝ</div><div class="t m0 x6a h21 yfd ffe fsa fc0 sc0 ls0 ws0">8×20</div><div class="t m0 x38 h13 yfb ffb fs1 fc0 sc0 ls0 ws0">，</div><div class="t m0 x3a h20 yfc ffe fs1 fc0 sc0 ls0 ws0">b<span class="_ _4"></span>∈<span class="_ _4"></span>ℝ</div><div class="t m0 x70 h21 yfd ffe fsa fc0 sc0 ls0 ws0">8</div><div class="t m0 x4b h13 yfb ffb fs1 fc0 sc0 ls0 ws0">，</div><div class="t m0 x28 h20 yfe ffe fs1 fc0 sc0 ls0 ws0">U<span class="_ _4"></span>∈<span class="_ _15"></span>ℝ</div><div class="t m0 x13 h21 yff ffe fsa fc0 sc0 ls0 ws0">8×1</div><div class="t m0 x71 h13 y100 ffb fs1 fc0 sc0 ls0 ws0">，</div><div class="t m0 x72 h20 yfe ffe fs1 fc0 sc0 ls0 ws0">s<span class="_ _4"></span>∈<span class="_ _4"></span>ℝ</div><div class="t m0 x73 h13 y100 ffb fs1 fc0 sc0 ls0 ws0">。</div></div><div class="c x23 y101 w6 h18"><div class="t m0 x7 h19 y102 ff7 fs0 fc0 sc0 ls0 ws0">1.4 Notes<span class="_ _4"> </span>i<span class="_ _2"></span>nfo.</div></div><div class="c x23 y103 w7 h1a"><div class="t m0 x7 hb y104 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y103 w8 h1a"><div class="t m0 x7 hb y104 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>P33</div></div><div class="c x23 y105 w7 h1a"><div class="t m0 x7 hb y106 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y105 w8 h1a"><div class="t m0 x7 hb y106 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>-,<span class="_ _3"> </span>--:00</div></div><div class="c x23 y107 w7 h1b"><div class="t m0 x7 hb y104 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y107 w8 h1b"><div class="t m0 x7 h1c y108 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y109 w7 h1a"><div class="t m0 x7 hb y10a ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y109 w8 h1a"><div class="t m0 x7 h1c y10a ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y10b w6 h1d"><div class="t m0 x25 hb y10c ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA<span class="fs5">I</span></div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y10d ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ff10 fs1">↑<span class="_ _2"></span><span class="ffb">图<span class="_ _10"> </span><span class="ffc">4<span class="_ _2"></span></span>：<span class="_ _2"></span>这<span class="_ _2"></span>个<span class="_ _6"></span>图像<span class="_ _2"></span>捕<span class="_ _2"></span>捉<span class="_ _2"></span>了<span class="_ _6"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>简</span></span></div><div class="t m0 x28 h13 y10e ffb fs1 fc0 sc0 ls0 ws0">单的前馈网<span class="_ _2"></span>络如何计算它<span class="_ _2"></span>的输出。</div><div class="t m0 x28 h11 y10f ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _13"> </span><span class="ffb fs1">最<span class="_ _12"></span>大<span class="_ _6"></span>边<span class="_ _12"></span>际<span class="_ _12"></span>目<span class="_ _6"></span>标<span class="_ _12"></span>函<span class="_ _12"></span>数<span class="_ _12"></span>通<span class="_ _6"></span>常<span class="_ _12"></span>与<span class="_ _6"></span>支<span class="_ _12"></span>持</span></div><div class="t m0 x28 h12 y110 ffb fs1 fc0 sc0 ls0 ws0">向量机一起<span class="_ _2"></span>使用<span class="ffc">.</span></div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x0 y0 w5 h1" alt="" src="bg5.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">方面<span class="_ _2"></span>，<span class="_ _2"></span>可<span class="_ _2"></span>以<span class="_ _2"></span>去<span class="_ _2"></span>读<span class="_ _2"></span>一<span class="_ _2"></span>下</div><div class="t m0 x3 h15 y112 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x74 h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">中的<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _2"></span>间<span class="_ _2"></span>隔<span class="_ _2"></span>和<span class="_ _2"></span>几<span class="_ _2"></span>何<span class="_ _2"></span>间<span class="_ _2"></span>隔<span class="_ _2"></span>中<span class="_ _2"></span>的<span class="_ _2"></span>相<span class="_ _2"></span>关<span class="_ _2"></span>内</div><div class="t m0 x0 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">容。最后，我<span class="_ _2"></span>们定义在所有<span class="_ _2"></span>训练窗口<span class="_ _2"></span>上的优化目标<span class="_ _2"></span>函数为：</div><div class="t m0 x6a h15 y114 ffe fs3 fc0 sc0 ls0 ws0">minimize J<span class="_ _4"></span>=<span class="_ _15"></span>m<span class="_ _2"></span>ax <span class="_ _2"></span>(1<span class="_ _1"></span>+<span class="_ _4"></span>s</div><div class="t m0 x40 h16 y115 ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x2c h15 y114 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>s,<span class="_ _11"></span>0)</div><div class="t m0 x0 h6 y116 ff5 fs3 fc0 sc0 ls0 ws0">按照上面的公<span class="_ _2"></span>式有，</div><div class="t m0 x4e h15 y117 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h16 y63 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 h15 y117 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span></div><div class="t m0 x74 h16 y118 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x75 h15 y117 ffe fs3 fc0 sc0 ls0 ws0">(</div><div class="t m0 x1b h16 y63 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h15 y117 ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span>)</div><div class="t m0 x40 h6 y116 ff5 fs3 fc0 sc0 ls0 ws0">和</div><div class="t m0 x5f h15 y117 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _15"></span>=<span class="_ _15"></span></div><div class="t m0 x5b h16 y118 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x76 h15 y117 ffe fs3 fc0 sc0 ls0 ws0">(<span class="_ _3"></span>+<span class="_ _3"></span>)</div><div class="t m0 x77 h6 y116 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h14 y119 ffd fs0 fc0 sc0 ls0 ws0">1.5<span class="_ _4"> </span>Tra<span class="_ _2"></span>ining<span class="_ _15"> </span>with<span class="_ _15"> </span>Backpropagation<span class="_ _15"> </span>–<span class="_ _15"> </span>Elemental</div><div class="t m0 x0 h15 y11a ff5 fs3 fc0 sc0 ls0 ws0">在<span class="_ _2"></span>这<span class="_ _2"></span>部<span class="_ _2"></span>分<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _6"></span>讨<span class="_ _2"></span>论<span class="_ _2"></span>当<span class="_ _5"> </span><span class="ff4">1.4<span class="_ _5"> </span></span>节<span class="_ _2"></span>中<span class="_ _2"></span>讨<span class="_ _2"></span>论<span class="_ _2"></span>的<span class="_ _2"></span>损<span class="_ _6"></span>失<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _7"> </span><span class="ffe"><span class="_ _7"></span></span>为<span class="_ _2"></span>正<span class="_ _2"></span>时<span class="_ _2"></span>，<span class="_ _6"></span>模型</div><div class="t m0 x0 h5 y11b ff5 fs3 fc0 sc0 ls0 ws0">中<span class="_ _2"></span>不<span class="_ _6"></span>同<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _6"></span>时<span class="_ _2"></span>是<span class="_ _6"></span>如<span class="_ _6"></span>何<span class="_ _2"></span>训<span class="_ _6"></span>练<span class="_ _2"></span>的<span class="_ _2"></span>。<span class="_ _6"></span>如<span class="_ _2"></span>果<span class="_ _6"></span>损<span class="_ _6"></span>失<span class="_ _2"></span>为<span class="_ _7"> </span><span class="ff4">0<span class="_ _15"> </span></span>时<span class="_ _6"></span>，<span class="_ _6"></span>那<span class="_ _2"></span>么<span class="_ _2"></span>不<span class="_ _6"></span>需<span class="_ _2"></span>要<span class="_ _6"></span>再</div><div class="t m0 x0 h5 y11c ff5 fs3 fc0 sc0 ls0 ws0">更新<span class="_ _2"></span>参数<span class="_ _2"></span>。<span class="_ _2"></span>我们一<span class="_ _2"></span>般<span class="_ _2"></span>使用<span class="_ _2"></span>梯度<span class="_ _2"></span>下<span class="_ _2"></span>降（<span class="_ _2"></span>或者<span class="_ _2"></span>像<span class="_ _4"> </span><span class="ff4">SGD<span class="_ _15"> </span></span>这样<span class="_ _2"></span>的<span class="_ _2"></span>变体<span class="_ _2"></span>）</div><div class="t m0 x0 h6 y11d ff5 fs3 fc0 sc0 ls0 ws0">来更新参数，<span class="_ _2"></span>所以要知道在<span class="_ _2"></span>更新公式<span class="_ _2"></span>中需要的任意<span class="_ _2"></span>参数的梯度信</div><div class="t m0 x0 h6 y11e ff5 fs3 fc0 sc0 ls0 ws0">息：</div><div class="t m0 x3 h15 y11f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 h16 y120 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x70 h15 y121 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x41 h15 y11f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3f h16 y120 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x39 h15 y121 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span></div><div class="t m0 x78 h16 y122 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x40 h22 y123 ffe fsb fc0 sc0 ls0 ws0">()</div><div class="t m0 x2c h15 y11f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h6 y124 ff5 fs3 fc0 sc0 ls0 ws0">反向传播是一<span class="_ _2"></span>种利用微分链<span class="_ _2"></span>式法则来<span class="_ _2"></span>计算模型上任<span class="_ _2"></span>意参数的损失</div><div class="t m0 x0 h6 y125 ff5 fs3 fc0 sc0 ls0 ws0">梯度的方法。<span class="_ _2"></span>为了更进一步<span class="_ _2"></span>理解反向<span class="_ _2"></span>传播，我们先<span class="_ _2"></span>看右图的<span class="_ _2"></span>一个</div><div class="t m0 x0 h6 y126 ff5 fs3 fc0 sc0 ls0 ws0">简单的网络<span class="_ _2"></span>。</div><div class="t m0 x0 h6 y127 ff5 fs3 fc0 sc0 ls0 ws0">这里我们使用<span class="_ _2"></span>只有单个隐藏<span class="_ _2"></span>层和单个<span class="_ _2"></span>输出单元的神<span class="_ _2"></span>经网络。现在</div><div class="t m0 x0 h6 y128 ff5 fs3 fc0 sc0 ls0 ws0">让我们先建立<span class="_ _2"></span>一些符号定义<span class="_ _2"></span>：</div><div class="t m0 x0 h23 y129 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y12a ffe fs3 fc0 sc0 ls0 ws0">x</div><div class="t m0 x71 h16 y12b ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x79 h6 y12a ff5 fs3 fc0 sc0 ls0 ws0">是神经网络的<span class="_ _2"></span>输入</div><div class="t m0 x0 h23 y12c ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y12d ffe fs3 fc0 sc0 ls0 ws0">s</div><div class="t m0 x64 h6 y12e ff5 fs3 fc0 sc0 ls0 ws0">是神经网络的<span class="_ _2"></span>输出</div><div class="t m0 x0 h6 y12f ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">每层（包括输<span class="_ _2"></span>入和输出层）<span class="_ _2"></span>的神经元<span class="_ _2"></span>都接收一个输<span class="_ _2"></span>入和生成</span></div><div class="t m0 x2 h6 y130 ff5 fs3 fc0 sc0 ls0 ws0">一个<span class="_ _2"></span>输出<span class="_ _2"></span>。第</div><div class="t m0 x18 h15 y131 ffe fs3 fc0 sc0 ls0 ws0">k</div><div class="t m0 x1f h6 y130 ff5 fs3 fc0 sc0 ls0 ws0">层的<span class="_ _2"></span>第</div><div class="t m0 x7a h15 y131 ffe fs3 fc0 sc0 ls0 ws0">j</div><div class="t m0 x4b h6 y130 ff5 fs3 fc0 sc0 ls0 ws0">个神<span class="_ _2"></span>经元<span class="_ _2"></span>接收<span class="_ _2"></span>标量<span class="_ _2"></span>输<span class="_ _2"></span>入</div><div class="t m0 x54 h15 y131 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x7b h16 y132 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x7b h16 y133 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x63 h6 y130 ff5 fs3 fc0 sc0 ls0 ws0">和生<span class="_ _2"></span>成</div><div class="t m0 x2 h6 y134 ff5 fs3 fc0 sc0 ls0 ws0">一个标量激活<span class="_ _2"></span>输出</div><div class="t m0 x7c h15 y135 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x52 h16 y136 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x52 h16 y137 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x0 h23 y138 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y139 ff5 fs3 fc0 sc0 ls0 ws0">我们把<span class="_ _4"> </span><span class="ffe">z</span></div><div class="t m0 x7d h16 y13a ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x7d h16 y13b ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x7e h15 y139 ff5 fs3 fc0 sc0 ls0 ws0">计算出的反向<span class="_ _2"></span>传播误差定义<span class="_ _2"></span>为<span class="_ _4"> </span><span class="ffe">δ</span></div><div class="t m0 x7f h16 y13a ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x7f h16 y13b ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x0 h6 y13c ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">第</span></div><div class="t m0 x80 h15 y13d ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x6d h6 y13c ff5 fs3 fc0 sc0 ls0 ws0">层<span class="_ _2"></span>是<span class="_ _6"></span>输<span class="_ _2"></span>入<span class="_ _2"></span>层<span class="_ _6"></span>，<span class="_ _2"></span>而<span class="_ _6"></span>不<span class="_ _6"></span>是<span class="_ _2"></span>第</div><div class="t m0 x39 h15 y13d ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x21 h6 y13c ff5 fs3 fc0 sc0 ls0 ws0">个<span class="_ _2"></span>隐<span class="_ _6"></span>藏<span class="_ _2"></span>层<span class="_ _2"></span>。<span class="_ _6"></span>对<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _6"></span>层<span class="_ _2"></span>而<span class="_ _2"></span>言<span class="_ _6"></span>，</div><div class="t m0 x2 h15 y13e ffe fs3 fc0 sc0 ls0 ws0">x</div><div class="t m0 x71 h16 y13f ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x71 h16 y140 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x72 h15 y13e ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>z</div><div class="t m0 x6e h16 y13f ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x6e h16 y140 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x81 h15 y13e ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x36 h15 y141 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x37 h16 y13f ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x37 h16 y140 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x0 h23 y142 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y143 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x79 h16 y144 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x6d h5 y142 ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>将<span class="_ _6"></span>第<span class="_ _8"> </span><span class="ff4">k<span class="_ _7"> </span></span>层<span class="_ _2"></span>的<span class="_ _6"></span>输<span class="_ _6"></span>出<span class="_ _6"></span>映<span class="_ _6"></span>射<span class="_ _6"></span>到<span class="_ _6"></span>第</div><div class="t m0 x44 h15 y143 ffe fs3 fc0 sc0 ls0 ws0">k<span class="_ _1"></span>+<span class="_ _3"></span>1</div><div class="t m0 x4 h6 y142 ff5 fs3 fc0 sc0 ls0 ws0">层<span class="_ _2"></span>的<span class="_ _6"></span>输<span class="_ _6"></span>入<span class="_ _6"></span>的<span class="_ _6"></span>转<span class="_ _6"></span>移<span class="_ _2"></span>矩</div><div class="t m0 x2 h15 y145 ff5 fs3 fc0 sc0 ls0 ws0">阵<span class="_ _2"></span>，<span class="_ _2"></span>因<span class="_ _2"></span>此<span class="_ _2"></span>将<span class="_ _2"></span>这<span class="_ _6"></span>个<span class="_ _2"></span>新<span class="_ _2"></span>的<span class="_ _2"></span>符<span class="_ _6"></span>号<span class="_ _2"></span>用<span class="_ _2"></span>在<span class="_ _7"> </span><span class="ffe">Section <span class="_ _2"></span>1.3<span class="_ _15"></span></span>中<span class="_ _2"></span>的<span class="_ _2"></span>例<span class="_ _6"></span>子</div><div class="t m0 x63 h15 y146 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 xe h16 y147 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x82 h15 y145 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2 h15 y148 ffe fs3 fc0 sc0 ls0 ws0">W<span class="_ _3"></span><span class="ff5">和<span class="_ _15"> </span></span>W</div><div class="t m0 x14 h16 y149 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x83 h15 y148 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>U<span class="_ _4"></span><span class="ff5">。</span></div><div class="t m0 x0 h15 y14a ff5 fs3 fc0 sc0 ls0 ws0">现<span class="_ _2"></span>在<span class="_ _6"></span>开<span class="_ _6"></span>始<span class="_ _6"></span>反<span class="_ _6"></span>向<span class="_ _6"></span>传<span class="_ _2"></span>播<span class="_ _6"></span>：<span class="_ _6"></span>假<span class="_ _6"></span>设<span class="_ _6"></span>损<span class="_ _6"></span>失<span class="_ _6"></span>函<span class="_ _2"></span>数<span class="_ _8"> </span><span class="ffe">J<span class="_ _4"></span>=<span class="_ _15"></span>(<span class="_ _2"></span>1<span class="_ _3"></span>+</span></div><div class="t m0 x34 h15 y14b ffe fs3 fc0 sc0 ls0 ws0">s</div><div class="t m0 x84 h16 y14c ffe fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x5a h15 y14a ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>s)<span class="_ _7"></span><span class="ff5">为<span class="_ _6"></span>正<span class="_ _6"></span>值<span class="_ _6"></span>，<span class="_ _6"></span>我</span></div><div class="t m0 x0 h6 y14d ff5 fs3 fc0 sc0 ls0 ws0">们<span class="_ _2"></span>想<span class="_ _6"></span>更<span class="_ _6"></span>新<span class="_ _6"></span>参<span class="_ _2"></span>数</div><div class="t m0 x81 h15 y14e ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x17 h16 y14f ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x17 h16 y150 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x38 h6 y14d ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>看<span class="_ _6"></span>到</div><div class="t m0 x57 h15 y14e ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x20 h16 y14f ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x20 h16 y150 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x47 h15 y14d ff5 fs3 fc0 sc0 ls0 ws0">只<span class="_ _2"></span>参<span class="_ _6"></span>与<span class="_ _6"></span>了<span class="_ _8"> </span><span class="ffe">z</span></div><div class="t m0 x68 h16 y14f ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x68 h16 y150 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x85 h6 y14d ff5 fs3 fc0 sc0 ls0 ws0">和</div><div class="t m0 x86 h15 y14e ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x87 h16 y14f ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x87 h16 y150 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xe h6 y14d ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>计</div><div class="t m0 x0 h5 y151 ff5 fs3 fc0 sc0 ls0 ws0">算。这点对于<span class="_ _2"></span>理解反向传播<span class="_ _2"></span>是非常重<span class="_ _2"></span>要的<span class="ff4">——</span>反向<span class="_ _2"></span>传播的梯<span class="_ _2"></span>度只</div><div class="t m0 x0 h6 y152 ff5 fs3 fc0 sc0 ls0 ws0">受它<span class="_ _2"></span>们<span class="_ _6"></span>所贡<span class="_ _2"></span>献<span class="_ _2"></span>的<span class="_ _6"></span>值的<span class="_ _2"></span>影<span class="_ _2"></span>响<span class="_ _6"></span>。</div><div class="t m0 x88 h15 y153 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x49 h16 y154 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x49 h16 y155 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x57 h6 y152 ff5 fs3 fc0 sc0 ls0 ws0">在随<span class="_ _2"></span>后<span class="_ _6"></span>的前<span class="_ _2"></span>向<span class="_ _2"></span>计<span class="_ _6"></span>算中<span class="_ _2"></span>和</div><div class="t m0 x89 h15 y153 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x8a h16 y154 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8a h16 y155 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8b h6 y152 ff5 fs3 fc0 sc0 ls0 ws0">相</div><div class="t m0 x0 h6 y156 ff5 fs3 fc0 sc0 ls0 ws0">乘计算得分。<span class="_ _2"></span>我们可以从最<span class="_ _2"></span>大间隔损<span class="_ _2"></span>失看到：</div></div><div class="c x23 y157 w6 h18"><div class="t m0 x7 h19 y158 ff7 fs0 fc0 sc0 ls0 ws0">Notes<span class="_ _4"> </span>in<span class="_ _2"></span>fo.</div></div><div class="c x23 y159 w7 h1a"><div class="t m0 x7 hb y54 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y159 w8 h1a"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>P12</div></div><div class="c x23 y15a w7 h1a"><div class="t m0 x7 hb y15b ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y15a w8 h1a"><div class="t m0 x7 hb y15b ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>3<span class="_ _2"></span>,<span class="_ _1"> </span>57:00</div></div><div class="c x23 y15c w7 h1b"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y15c w8 h1b"><div class="t m0 x7 h1c y57 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y15d w7 h1a"><div class="t m0 x7 hb y15b ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y15d w8 h1a"><div class="t m0 x7 h1c y15b ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y15e w6 h1d"><div class="t m0 x25 hb y15f ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA<span class="fs5">I</span></div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y160 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ff10 fs1">↑<span class="ffb">图<span class="_ _19"> </span><span class="ffc">5<span class="_ _2"></span></span>：<span class="_ _2"></span>这<span class="_ _2"></span>是<span class="_ _2"></span>一<span class="_ _2"></span>个<span class="_ _10"> </span><span class="ffc">4-2-1<span class="_ _3"> </span></span>神<span class="_ _2"></span>经<span class="_ _2"></span>网</span></span></div><div class="t m0 x28 h12 y161 ffb fs1 fc0 sc0 ls0 ws0">络<span class="_ _2"></span>，<span class="_ _12"></span>其<span class="_ _6"></span>中<span class="_ _19"> </span><span class="ffc">k<span class="_ _4"> </span></span>层<span class="_ _2"></span>的<span class="_ _6"></span>神<span class="_ _6"></span>经<span class="_ _6"></span>元<span class="_ _5"> </span><span class="ffc">j<span class="_ _4"> </span></span>接<span class="_ _2"></span>收<span class="_ _6"></span>输<span class="_ _6"></span>入</div><div class="t m0 x28 h20 y162 ffe fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x8c h21 y163 ffe fsa fc0 sc0 ls0 ws0"></div><div class="t m0 x8c h21 y164 ffe fsa fc0 sc0 ls0 ws0">()</div><div class="t m0 x8d h13 y165 ffb fs1 fc0 sc0 ls0 ws0">，并产生激<span class="_ _2"></span>活输出</div><div class="t m0 x37 h20 y162 ffe fs1 fc0 sc0 ls0 ws0"></div><div class="t m0 x8e h21 y163 ffe fsa fc0 sc0 ls0 ws0"></div><div class="t m0 x8e h21 y164 ffe fsa fc0 sc0 ls0 ws0">()</div><div class="t m0 x3a h13 y165 ffb fs1 fc0 sc0 ls0 ws0">。</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><img class="bi x0 y0 w1 hd" alt="" src="bg6.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x8f h15 y166 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h15 y167 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x56 h15 y168 ffe fs3 fc0 sc0 ls0 ws0">=−</div><div class="t m0 x3f h15 y166 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x46 h15 y167 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x59 h15 y169 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x90 h16 y16a ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h15 y168 ffe fs3 fc0 sc0 ls0 ws0">=−<span class="_ _3"></span>1</div><div class="t m0 x0 h6 y16b ff5 fs3 fc0 sc0 ls0 ws0">为了简化我们<span class="_ _2"></span>只分析</div><div class="t m0 x3a h16 y16c ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x4d h16 y16d ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x26 h16 y16e ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h22 y16f ffe fsb fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h22 y170 ffe fsb fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x48 h6 y16b ff5 fs3 fc0 sc0 ls0 ws0">。所以，</div><div class="t m0 x91 h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h15 y172 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8 h16 y173 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x8 h16 y174 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x64 h15 y175 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2f h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x14 h16 y176 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6f h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x7e h16 y176 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x53 h15 y172 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x73 h16 y173 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x73 h16 y174 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x18 h15 y175 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x92 h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x52 h16 y177 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x52 h16 y178 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x74 h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x75 h16 y177 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x75 h16 y178 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x9 h15 y179 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h15 y172 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h16 y173 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 h16 y17a ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x46 h15 y175 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x90 h15 y17b ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h16 y17c ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h16 y17d ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x78 h15 y171 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c h16 y177 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c h16 y178 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x1d h15 y179 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3c h15 y172 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x2c h16 y173 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x2c h16 y17a ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x0 h15 y17e ffe fs3 fc0 sc0 ls0 ws0">⟹<span class="_ _15"></span></div><div class="t m0 x58 h16 y17f ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x58 h16 y180 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x2f h15 y181 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y26 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y6a ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x72 h15 y182 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x31 h16 y27 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x31 h16 y183 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x93 h15 y184 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x17 h15 y17e ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x18 h16 y17f ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x18 h16 y180 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3 h15 y181 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h16 y26 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h16 y6a ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3 h15 y182 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h16 y27 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f h16 y183 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x70 h15 y181 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x41 h16 y26 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x41 h16 y6a ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x56 h15 y182 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x94 h16 y27 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x94 h16 y183 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x1b h15 y184 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x21 h15 y17e ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x47 h16 y17f ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x47 h16 y180 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x11 h15 y185 ffe fs3 fc0 sc0 ls0 ws0"> </div><div class="t m0 x22 h16 y186 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x22 h16 y187 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x95 h15 y182 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x22 h16 y27 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x22 h16 y183 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x68 h15 y181 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e h16 y26 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e h16 y6a ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x5b h15 y182 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x96 h16 y27 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x96 h16 y183 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x0 h15 y188 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2e h15 y189 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y18a ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y18b ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x79 h15 y188 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x97 h16 y71 ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x30 h15 y188 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y18a ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y18b ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x98 h15 y18c ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3e h16 y18d ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x3e h16 y18e ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x81 h15 y18f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6a h15 y190 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y191 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y192 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x0 h15 y193 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2e h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y195 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x79 h15 y193 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x97 h16 y197 ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x30 h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y198 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x36 h15 y199 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x81 h15 y19a ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y19b ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y19c ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x3a h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h16 y198 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x99 h15 y194 ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span></div><div class="t m0 x41 h16 y195 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x41 h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x59 h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9a h16 y195 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9a h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x1c h15 y194 ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span></div><div class="t m0 x11 h16 y195 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x11 h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x12 h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h16 y195 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x4 h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2b h15 y194 ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span></div><div class="t m0 x62 h16 y195 ffe fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x62 h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x9b h15 y194 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9c h16 y195 ffe fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x9c h16 y196 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x0 h15 y19d ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _1"></span></div><div class="t m0 x8 h16 y19e ffe fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x8 h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x71 h15 y19d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x66 h16 y19e ffe fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x66 h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x14 h15 y19f ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x6f h15 y19d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1e h16 y1a0 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x1e h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x18 h15 y19d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9d h16 y1a1 ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x26 h15 y19d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h16 y1a0 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4b h15 y1a2 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x56 h15 y1a3 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x7a h15 y1a4 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x94 h16 y1a5 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x94 h16 y1a6 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x20 h15 y19d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h16 y1a0 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x78 h15 y19d ffe fs3 fc0 sc0 ls0 ws0">+</div><div class="t m0 x95 h16 y1a7 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x22 h15 y1a8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xb h16 y19e ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 xb h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2b h15 y1a8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5 h16 y19e ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x5 h16 y78 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x11 h24 y19f ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h15 y1a9 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2e h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y1ab ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c h16 y1ac ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x79 h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x97 h16 y1ad ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x30 h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y1ab ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h16 y1ac ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x81 h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6a h16 y1ab ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x6a h16 y1ac ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x69 h15 y1a9 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x4d h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 h16 y1ab ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 h16 y1ac ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x9e h15 y1aa ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x99 h16 y1ab ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x99 h16 y1ac ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x0 h6 y1ae ff5 fs3 fc0 sc0 ls0 ws0">其<span class="_ _2"></span>中<span class="_ _6"></span>，</div><div class="t m0 x80 h15 y1af ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x50 h16 yce ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x6e h6 y1ae ff5 fs3 fc0 sc0 ls0 ws0">指<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _2"></span>层<span class="_ _6"></span>的<span class="_ _6"></span>输<span class="_ _2"></span>入<span class="_ _6"></span>。<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _2"></span>可<span class="_ _6"></span>以<span class="_ _6"></span>看<span class="_ _2"></span>到<span class="_ _6"></span>梯<span class="_ _2"></span>度<span class="_ _6"></span>计<span class="_ _6"></span>算<span class="_ _2"></span>最<span class="_ _6"></span>后<span class="_ _6"></span>可<span class="_ _2"></span>以</div><div class="t m0 x0 h15 y1b0 ff5 fs3 fc0 sc0 ls0 ws0">简<span class="_ _2"></span>化<span class="_ _2"></span>为<span class="_ _7"> </span><span class="ffe">δ</span></div><div class="t m0 x50 h16 y1b1 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x50 h16 y1b2 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x31 h15 y1b0 ffe fs3 fc0 sc0 ls0 ws0">⋅</div><div class="t m0 x7d h15 y1b3 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x73 h16 y1b1 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x73 h16 y1b2 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x17 h15 y1b0 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>其<span class="_ _2"></span>中<span class="_ _7"> </span><span class="ffe">δ</span></div><div class="t m0 x48 h16 y1b1 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x48 h16 y1b2 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x9f h6 y1b0 ff5 fs3 fc0 sc0 ls0 ws0">本<span class="_ _2"></span>质<span class="_ _2"></span>上<span class="_ _6"></span>是<span class="_ _2"></span>第</div><div class="t m0 x4c h15 y1b3 ffe fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x33 h15 y1b0 ff5 fs3 fc0 sc0 ls0 ws0">层<span class="_ _2"></span>中<span class="_ _2"></span>第<span class="_ _7"> </span><span class="ffe">i<span class="_ _7"></span></span>个<span class="_ _6"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>元<span class="_ _6"></span>反</div><div class="t m0 x0 h6 y1b4 ff5 fs3 fc0 sc0 ls0 ws0">向传<span class="_ _2"></span>播的<span class="_ _2"></span>误<span class="_ _2"></span>差。</div><div class="t m0 x1e h15 y1b5 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x3e h16 y1b6 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x3e h16 y1b7 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x1f h6 y1b4 ff5 fs3 fc0 sc0 ls0 ws0">与</div><div class="t m0 xa0 h15 y1b5 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 xa1 h16 y1b8 ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa2 h6 y1b4 ff5 fs3 fc0 sc0 ls0 ws0">相乘<span class="_ _2"></span>的结<span class="_ _2"></span>果<span class="_ _2"></span>，输<span class="_ _2"></span>入第</div><div class="t m0 xa3 h15 y1b5 ffe fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x61 h15 y1b4 ff5 fs3 fc0 sc0 ls0 ws0">层中<span class="_ _2"></span>第<span class="_ _4"> </span><span class="ffe">i<span class="_ _15"></span></span>个神</div><div class="t m0 x0 h6 y1b9 ff5 fs3 fc0 sc0 ls0 ws0">经元中。</div><div class="t m0 x0 h5 y1ba ff5 fs3 fc0 sc0 ls0 ws0">我们<span class="_ _2"></span>以右<span class="_ _2"></span>图<span class="_ _2"></span>为例<span class="_ _2"></span>，让<span class="_ _2"></span>我<span class="_ _2"></span>们从<span class="_ _2"></span><span class="ff4">“</span>误<span class="_ _2"></span>差共<span class="_ _2"></span>享<span class="_ _2"></span><span class="ff4">/</span>分<span class="_ _2"></span>配<span class="_ _2"></span><span class="ff4">”</span>的来<span class="_ _2"></span>阐<span class="_ _2"></span>释<span class="_ _2"></span>一下反<span class="_ _2"></span>向</div><div class="t m0 x0 h6 y1bb ff5 fs3 fc0 sc0 ls0 ws0">传播，现在我<span class="_ _2"></span>们要更新</div><div class="t m0 x7c h15 y1bc ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 xa4 h16 y1bd ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 xa4 h16 y1be ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x7a h6 y1bb ff5 fs3 fc0 sc0 ls0 ws0">：</div><div class="t m0 x0 h5 y1bf ff4 fs3 fc0 sc0 ls0 ws0">1.<span class="_ _1a"> </span><span class="ff5">我们从</span></div><div class="t m0 xa5 h15 y1c0 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x73 h16 y1c1 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x73 h16 y1c2 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x17 h5 y1bf ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _4"> </span><span class="ff4">1<span class="_ _4"> </span></span>的误差信号开始反<span class="_ _2"></span>向传播。</div><div class="t m0 x0 h5 y1c3 ff4 fs3 fc0 sc0 ls0 ws0">2.<span class="_ _1a"> </span><span class="ff5">然<span class="_ _2"></span>后<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>把<span class="_ _2"></span>误<span class="_ _6"></span>差<span class="_ _2"></span>与<span class="_ _2"></span>将</span></div><div class="t m0 x74 h15 y1c4 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x75 h16 y3a ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x75 h16 y1c5 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x46 h6 y1c3 ff5 fs3 fc0 sc0 ls0 ws0">映<span class="_ _2"></span>射<span class="_ _2"></span>到</div><div class="t m0 x78 h15 y1c4 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x40 h16 y3a ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x40 h16 y1c5 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x12 h6 y1c3 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>元<span class="_ _2"></span>的<span class="_ _2"></span>局<span class="_ _6"></span>部<span class="_ _2"></span>梯<span class="_ _2"></span>度</div><div class="t m0 x58 h5 y1c6 ff5 fs3 fc0 sc0 ls0 ws0">相乘<span class="_ _6"></span>。<span class="_ _2"></span>在这<span class="_ _2"></span>个<span class="_ _6"></span>例<span class="_ _2"></span>子中<span class="_ _6"></span>梯<span class="_ _2"></span>度<span class="_ _2"></span>正<span class="_ _2"></span>好<span class="_ _2"></span>等<span class="_ _2"></span>于<span class="_ _15"> </span><span class="ff4">1<span class="_ _15"> </span></span>，<span class="_ _2"></span>则<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _2"></span>仍<span class="_ _2"></span>然<span class="_ _2"></span>为<span class="_ _15"> </span><span class="ff4">1<span class="_ _15"> </span></span>。</div><div class="t m0 x58 h15 y1c7 ff5 fs3 fc0 sc0 ls0 ws0">所以有<span class="_ _4"> </span><span class="ffe"></span></div><div class="t m0 x73 h16 y92 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x73 h16 y1c8 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x17 h15 y1c7 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>1<span class="_ _4"></span><span class="ff5">。</span></div><div class="t m0 x0 h5 y1c9 ff4 fs3 fc0 sc0 ls0 ws0">3.<span class="_ _1a"> </span><span class="ff5">这<span class="_ _2"></span>里<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _2"></span>信<span class="_ _6"></span>号<span class="_ _15"> </span></span>1<span class="_ _15"> </span><span class="ff5">已<span class="_ _2"></span>经<span class="_ _2"></span>到<span class="_ _6"></span>达</span></div><div class="t m0 xa6 h15 y1ca ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xa7 h16 y1cb ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa7 h16 y1cc ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 xa8 h6 y1c9 ff5 fs3 fc0 sc0 ls0 ws0">。<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>现<span class="_ _2"></span>在<span class="_ _2"></span>需<span class="_ _6"></span>要<span class="_ _2"></span>分<span class="_ _2"></span>配<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _2"></span>信</div><div class="t m0 x58 h5 y1cd ff5 fs3 fc0 sc0 ls0 ws0">号使得误差的<span class="_ _2"></span><span class="ff4">“</span>公平共享<span class="_ _2"></span><span class="ff4">”</span>到达</div><div class="t m0 xa8 h15 y1ce ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5d h16 y1cf ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5d h16 y1d0 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6b h6 y1cd ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h5 y1d1 ff4 fs3 fc0 sc0 ls0 ws0">4.<span class="_ _1a"> </span><span class="ff5">现在<span class="_ _2"></span>在</span></div><div class="t m0 xa5 h15 y1d2 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x73 h16 y1d3 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x73 h16 y1d4 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x17 h6 y1d1 ff5 fs3 fc0 sc0 ls0 ws0">的误<span class="_ _2"></span>差为</div><div class="t m0 x74 h15 y1d2 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x75 h16 y1d3 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x75 h16 y1d4 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x46 h15 y1d2 ffe fs3 fc0 sc0 ls0 ws0">×<span class="_ _3"></span></div><div class="t m0 x32 h16 y1d3 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x32 h16 y1d4 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x1d h15 y1d2 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span></div><div class="t m0 x5f h16 y1d3 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5f h16 y1d4 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xb h6 y1d1 ff5 fs3 fc0 sc0 ls0 ws0">（在</div><div class="t m0 xa9 h15 y1d2 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x96 h16 y1d3 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x96 h16 y1d4 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x1a h6 y1d1 ff5 fs3 fc0 sc0 ls0 ws0">的误<span class="_ _2"></span>差信</div><div class="t m0 x58 h15 y1d5 ff5 fs3 fc0 sc0 ls0 ws0">号为<span class="_ _4"> </span><span class="ffe"></span></div><div class="t m0 x31 h16 y1d6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x31 h16 y1d7 ffe fs7 fc0 sc0 ls0 ws0">(3)</div><div class="t m0 x6f h6 y1d5 ff5 fs3 fc0 sc0 ls0 ws0">）。因此在</div><div class="t m0 x99 h15 y1d8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x70 h16 y1d6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x70 h16 y1d7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x94 h6 y1d5 ff5 fs3 fc0 sc0 ls0 ws0">的误差为</div><div class="t m0 x6b h15 y1d8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5f h16 y1d6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5f h16 y1d7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xaa h6 y1d5 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h5 y1d9 ff4 fs3 fc0 sc0 ls0 ws0">5.<span class="_ _1a"> </span><span class="ff5">与第<span class="_ _7"> </span></span>2<span class="_ _4"> </span><span class="ff5">步<span class="_ _2"></span>的<span class="_ _2"></span>做<span class="_ _2"></span>法<span class="_ _2"></span>相<span class="_ _2"></span>同<span class="_ _2"></span>，<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>在<span class="_ _2"></span>将</span></div><div class="t m0 x78 h15 y1da ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x40 h16 y1db ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x40 h16 y1dc ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x12 h6 y1d9 ff5 fs3 fc0 sc0 ls0 ws0">映射<span class="_ _6"></span>到</div><div class="t m0 x61 h15 y1da ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x96 h16 y1db ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x96 h16 y1dc ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x1a h6 y1d9 ff5 fs3 fc0 sc0 ls0 ws0">的神<span class="_ _6"></span>经<span class="_ _2"></span>元</div><div class="t m0 x58 h6 y1dd ff5 fs3 fc0 sc0 ls0 ws0">上<span class="_ _2"></span>移<span class="_ _2"></span>动<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _6"></span>，<span class="_ _2"></span>将</div><div class="t m0 x3a h15 y1de ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h16 y1df ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x7c h16 y1e0 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x99 h6 y1dd ff5 fs3 fc0 sc0 ls0 ws0">与<span class="_ _2"></span>局<span class="_ _2"></span>部<span class="_ _2"></span>梯<span class="_ _2"></span>度<span class="_ _6"></span>相<span class="_ _2"></span>乘<span class="_ _2"></span>，<span class="_ _2"></span>这<span class="_ _6"></span>里<span class="_ _2"></span>的<span class="_ _2"></span>局<span class="_ _2"></span>部<span class="_ _6"></span>梯度<span class="_ _6"></span>为</div><div class="t m0 x58 h15 y1e1 ffe fs3 fc0 sc0 ls0 ws0">&apos;(</div><div class="t m0 x50 h16 y1e2 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x50 h16 y1e3 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x31 h15 y1e1 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x7d h6 y1e4 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h15 y1e5 ff4 fs3 fc0 sc0 ls0 ws0">6.<span class="_ _1b"> </span><span class="ff5">因此在<span class="_ _4"> </span><span class="ffe"></span></span></div><div class="t m0 xab h16 y1e6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab h16 y1e7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x1e h15 y1e5 ff5 fs3 fc0 sc0 ls0 ws0">的误差是<span class="_ _4"> </span><span class="ffe">&apos;(</span></div><div class="t m0 x4a h16 y1e6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4a h16 y1e7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x57 h15 y1e5 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x1b h15 y1e8 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h16 y1e6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x21 h16 y1e7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xac h15 y1e5 ff5 fs3 fc0 sc0 ls0 ws0">，我们将其定<span class="_ _2"></span>义为<span class="_ _4"> </span><span class="ffe"></span></div><div class="t m0 x8a h16 y1e6 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8a h16 y1e7 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8b h6 y1e5 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h5 y1e9 ff4 fs3 fc0 sc0 ls0 ws0">7.<span class="_ _1a"> </span><span class="ff5">最<span class="_ _6"></span>后<span class="_ _12"></span>，<span class="_ _12"></span>我<span class="_ _12"></span>们<span class="_ _12"></span>通<span class="_ _12"></span>过<span class="_ _6"></span>将<span class="_ _12"></span>上<span class="_ _12"></span>面<span class="_ _12"></span>的<span class="_ _12"></span>误<span class="_ _12"></span>差<span class="_ _12"></span>与<span class="_ _12"></span>参<span class="_ _6"></span>与<span class="_ _12"></span>前<span class="_ _12"></span>向<span class="_ _12"></span>计<span class="_ _12"></span>算<span class="_ _12"></span>的</span></div><div class="t m0 x63 h15 y1ea ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xad h16 y1eb ffe fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 xad h16 y1ec ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x8b h6 y1e9 ff5 fs3 fc0 sc0 ls0 ws0">相</div><div class="t m0 x58 h5 y1ed ff5 fs3 fc0 sc0 ls0 ws0">乘，把误差的<span class="_ _2"></span><span class="ff4">“</span>误差共享<span class="_ _2"></span><span class="ff4">”</span>分配到</div><div class="t m0 x42 h15 y1ee ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x11 h16 y1ef ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x11 h16 y1f0 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x33 h6 y1ed ff5 fs3 fc0 sc0 ls0 ws0">。</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y1f1 ffa fs6 fc0 sc0 ls0 ws0">❐</div><div class="t m0 x29 h1f y1f2 ff10 fs1 fc0 sc0 ls0 ws0">↑</div><div class="t m0 x2a h12 y1f1 ffb fs1 fc0 sc0 ls0 ws0">图<span class="_ _10"> </span><span class="ffc">6<span class="_ _6"></span></span>：<span class="_ _2"></span>此<span class="_ _2"></span>子<span class="_ _2"></span>网<span class="_ _6"></span>显<span class="_ _2"></span>示<span class="_ _6"></span>了<span class="_ _2"></span>更<span class="_ _2"></span>新</div><div class="t m0 xa2 h20 y1f3 ffe fs1 fc0 sc0 ls0 ws0">W</div><div class="t m0 x4b h21 y1f4 ffe fsa fc0 sc0 ls0 ws0">ij</div><div class="t m0 x4b h21 y1f5 ffe fsa fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x28 h13 y1f6 ffb fs1 fc0 sc0 ls0 ws0">所需的网络<span class="_ _2"></span>的相关部分。</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg7.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h15 y111 ff4 fs3 fc0 sc0 ls0 ws0">8.<span class="_ _1a"> </span><span class="ff5">所以，对于<span class="_ _4"> </span><span class="ffe"></span></span></div><div class="t m0 x69 h16 y1f7 ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x69 h16 y1f8 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x3a h15 y111 ff5 fs3 fc0 sc0 ls0 ws0">的梯度损失可<span class="_ _2"></span>以计算为<span class="_ _4"> </span><span class="ffe"></span></div><div class="t m0 x5a h16 yf3 ffe fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x5a h16 y1f8 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x76 h15 y111 ffe fs3 fc0 sc0 ls0 ws0">&apos;(</div><div class="t m0 x54 h16 y1f7 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x54 h16 y1f8 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xae h15 y111 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 xad h16 y1f7 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad h16 y1f8 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8b h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h6 y1f9 ff5 fs3 fc0 sc0 ls0 ws0">注意我们使用<span class="_ _2"></span>这个方法得到<span class="_ _2"></span>的结果是<span class="_ _2"></span>和之前微分的<span class="_ _2"></span>方法的结果是</div><div class="t m0 x0 h6 y1fa ff5 fs3 fc0 sc0 ls0 ws0">完全一样的。<span class="_ _2"></span>因此，计算网<span class="_ _2"></span>络中的相<span class="_ _2"></span>应参数的梯度<span class="_ _2"></span>误差既可以使</div><div class="t m0 x0 h5 y1fb ff5 fs3 fc0 sc0 ls0 ws0">用链式法则也<span class="_ _2"></span>可以使用误差<span class="_ _2"></span>共享和分<span class="_ _2"></span>配的方法<span class="ff4">——<span class="_ _2"></span></span>这两个方<span class="_ _2"></span>法能</div><div class="t m0 x0 h6 y1fc ff5 fs3 fc0 sc0 ls0 ws0">得到相同结果<span class="_ _2"></span>，但是多种方<span class="_ _2"></span>式考虑它<span class="_ _2"></span>们可能是有帮<span class="_ _2"></span>助的。</div><div class="t m0 x0 h6 y1fd ff5 fs3 fc0 sc0 ls0 ws0">偏<span class="_ _2"></span>置<span class="_ _6"></span>更<span class="_ _2"></span>新<span class="_ _6"></span>：<span class="_ _6"></span>偏<span class="_ _2"></span>置<span class="_ _6"></span>项<span class="_ _2"></span>（<span class="_ _6"></span>例<span class="_ _2"></span>如</div><div class="t m0 x74 h15 y1fe ffe fs3 fc0 sc0 ls0 ws0">b</div><div class="t m0 x75 h16 y1ff ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x75 h16 y200 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x46 h6 y1fd ff5 fs3 fc0 sc0 ls0 ws0">）<span class="_ _2"></span>和<span class="_ _6"></span>其<span class="_ _2"></span>他<span class="_ _6"></span>权<span class="_ _6"></span>值<span class="_ _2"></span>在<span class="_ _6"></span>数<span class="_ _2"></span>学<span class="_ _6"></span>形<span class="_ _2"></span>式<span class="_ _6"></span>是<span class="_ _2"></span>等<span class="_ _6"></span>价</div><div class="t m0 x0 h15 y201 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>，<span class="_ _6"></span>只<span class="_ _2"></span>是<span class="_ _6"></span>在<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _2"></span>下<span class="_ _6"></span>一<span class="_ _2"></span>层<span class="_ _6"></span>神<span class="_ _2"></span>经<span class="_ _8"> </span><span class="ffe">z</span></div><div class="t m0 x41 h16 y202 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x41 h16 y203 ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xa7 h5 y201 ff5 fs3 fc0 sc0 ls0 ws0">元<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _2"></span>时<span class="_ _6"></span>相<span class="_ _2"></span>乘<span class="_ _6"></span>的<span class="_ _2"></span>值<span class="_ _6"></span>是<span class="_ _2"></span>常<span class="_ _6"></span>量<span class="_ _7"> </span><span class="ff4">1<span class="_ _15"> </span></span>。</div><div class="t m0 x0 h15 y204 ff5 fs3 fc0 sc0 ls0 ws0">因此<span class="_ _2"></span>在第<span class="_ _15"> </span><span class="ff4">k<span class="_ _4"> </span></span>层的<span class="_ _2"></span>第<span class="_ _4"> </span><span class="ff4">i<span class="_ _4"> </span></span>个<span class="_ _2"></span>神<span class="_ _2"></span>经元<span class="_ _2"></span>的偏<span class="_ _2"></span>置的<span class="_ _2"></span>梯度<span class="_ _2"></span>时<span class="_ _15"> </span><span class="ffe">δ</span></div><div class="t m0 x5a h16 y205 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5a h16 y206 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x5 h6 y204 ff5 fs3 fc0 sc0 ls0 ws0">。例<span class="_ _2"></span>如在<span class="_ _2"></span>上面</div><div class="t m0 x0 h15 y207 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _6"></span>例<span class="_ _6"></span>子<span class="_ _12"></span>中<span class="_ _6"></span>，<span class="_ _12"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>更<span class="_ _12"></span>新<span class="_ _6"></span>的<span class="_ _6"></span>是<span class="_ _0"> </span><span class="ffe">b</span></div><div class="t m0 x7a h16 y208 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x7a h16 y209 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x3d h15 y207 ff5 fs3 fc0 sc0 ls0 ws0">而<span class="_ _6"></span>不<span class="_ _6"></span>是<span class="_ _0"> </span><span class="ffe">W</span></div><div class="t m0 x2c h16 y208 ffe fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x2c h16 y209 ffe fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x34 h6 y207 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _6"></span>那<span class="_ _6"></span>么<span class="_ _12"></span>这<span class="_ _6"></span>个<span class="_ _12"></span>梯<span class="_ _6"></span>度<span class="_ _6"></span>为</div><div class="t m0 x0 h15 y20a ffe fs3 fc0 sc0 ls0 ws0">f&apos;(z</div><div class="t m0 x8 h16 y20b ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 h16 y20c ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x58 h15 y20a ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 xaf h15 y20d ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x72 h16 y20b ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x72 h16 y20c ffe fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x31 h6 y20a ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h15 y11e ff5 fs3 fc0 sc0 ls0 ws0">从<span class="_ _3"> </span><span class="ffe">δ</span></div><div class="t m0 xb0 h16 y20e ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x79 h15 y11e ff5 fs3 fc0 sc0 ls0 ws0">到<span class="_ _3"> </span><span class="ffe">δ</span></div><div class="t m0 x65 h16 y20e ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x7e h6 y11e ff5 fs3 fc0 sc0 ls0 ws0">反向传播的一<span class="_ _2"></span>般步骤：</div><div class="t m0 x0 h6 y1f3 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">我们有从</span></div><div class="t m0 x73 h15 y20f ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x83 h16 y210 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x83 h16 y120 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x3e h6 y1f3 ff5 fs3 fc0 sc0 ls0 ws0">向后传播的误<span class="_ _2"></span>差</div><div class="t m0 x20 h15 y20f ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x21 h16 y210 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x21 h16 y120 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 xac h15 y1f3 ff5 fs3 fc0 sc0 ls0 ws0">，如图 <span class="ffe">7<span class="_ _7"></span></span>所示</div><div class="t m0 x0 h15 y211 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">我<span class="_ _2"></span>们<span class="_ _2"></span>通<span class="_ _6"></span>过<span class="_ _2"></span>把<span class="_ _15"> </span><span class="ffe">δ</span></span></div><div class="t m0 x37 h16 y212 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x37 h16 y213 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x92 h6 y211 ff5 fs3 fc0 sc0 ls0 ws0">与<span class="_ _2"></span>路<span class="_ _2"></span>径<span class="_ _6"></span>上<span class="_ _2"></span>的<span class="_ _2"></span>权<span class="_ _6"></span>值</div><div class="t m0 x1d h15 y214 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x40 h16 y212 ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x40 h16 y213 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x4 h6 y211 ff5 fs3 fc0 sc0 ls0 ws0">相<span class="_ _2"></span>乘<span class="_ _2"></span>，<span class="_ _6"></span>将<span class="_ _2"></span>这<span class="_ _2"></span>个<span class="_ _6"></span>误<span class="_ _2"></span>差</div><div class="t m0 x2 h6 y215 ff5 fs3 fc0 sc0 ls0 ws0">反向传播到</div><div class="t m0 x1e h15 y216 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 xb1 h16 y217 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb1 h16 y218 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 xb2 h6 y215 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h6 y219 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">因此在</span></div><div class="t m0 x6e h15 y21a ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x7d h16 y21b ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x7d h16 y21c ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x3e h6 y219 ff5 fs3 fc0 sc0 ls0 ws0">接收的误差是</div><div class="t m0 x59 h15 y21a ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x90 h16 y21b ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x90 h16 y21c ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x21 h15 y21a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x47 h16 y21b ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x47 h16 y21c ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x5f h6 y219 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h23 y21d ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h6 y21e ff5 fs3 fc0 sc0 ls0 ws0">然而，</div><div class="t m0 x6e h15 y21f ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x7d h16 y220 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x7d h16 y221 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x3e h6 y21e ff5 fs3 fc0 sc0 ls0 ws0">在前向<span class="_ _2"></span>计算<span class="_ _2"></span>可能出<span class="_ _2"></span>右图<span class="_ _2"></span>的情<span class="_ _2"></span>况，会<span class="_ _2"></span>参与<span class="_ _2"></span>下一<span class="_ _2"></span>层</div><div class="t m0 x2 h15 y222 ff5 fs3 fc0 sc0 ls0 ws0">中<span class="_ _2"></span>的<span class="_ _2"></span>多<span class="_ _6"></span>个<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>的<span class="_ _2"></span>计<span class="_ _6"></span>算<span class="_ _2"></span>。<span class="_ _2"></span>那<span class="_ _6"></span>么<span class="_ _2"></span>第<span class="_ _15"> </span><span class="ffe">k<span class="_ _4"></span></span>层<span class="_ _2"></span>的<span class="_ _2"></span>第</div><div class="t m0 x7f h15 y223 ffe fs3 fc0 sc0 ls0 ws0">m</div><div class="t m0 x5 h6 y222 ff5 fs3 fc0 sc0 ls0 ws0">个<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>的<span class="_ _2"></span>误</div><div class="t m0 x2 h6 y224 ff5 fs3 fc0 sc0 ls0 ws0">差也要使用上<span class="_ _2"></span>一步方法将误<span class="_ _2"></span>差反向传<span class="_ _2"></span>播到</div><div class="t m0 x35 h15 y225 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x5a h16 y226 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x5a h16 y227 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x85 h6 y224 ff5 fs3 fc0 sc0 ls0 ws0">上。</div><div class="t m0 x0 h23 y228 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h6 y229 ff5 fs3 fc0 sc0 ls0 ws0">因此现在在</div><div class="t m0 x1e h15 y22a ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 xb1 h16 y22b ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb1 h16 y22c ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 xb2 h15 y229 ff5 fs3 fc0 sc0 ls0 ws0">接收的误差是<span class="_ _3"> </span><span class="ffe">δ</span></div><div class="t m0 x47 h16 y22b ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x47 h16 y22c ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x6b h15 y22a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 xb3 h16 y22b ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xb3 h16 y22c ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x5a h15 y229 ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _1"></span>δ</div><div class="t m0 x61 h16 y22d ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x61 h16 y22c ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x19 h15 y22a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x86 h16 y22b ffe fs7 fc0 sc0 ls0 ws0">mj</div><div class="t m0 x86 h16 y22c ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x77 h6 y229 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h6 y22e ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">实际上，我们<span class="_ _2"></span>可以把上面误<span class="_ _2"></span>差和简化<span class="_ _2"></span>为</span></div><div class="t m0 xaa h16 y22f ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xaa h15 y230 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b h15 y231 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x76 h16 y232 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x76 h16 y233 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x2d h24 y22e ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x85 h15 y231 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x7b h16 y232 ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x7b h16 y233 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 xb4 h6 y22e ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h6 y234 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">现<span class="_ _17"></span>在<span class="_ _6"></span>我<span class="_ _17"></span>们<span class="_ _12"></span>有<span class="_ _17"></span>在</span></div><div class="t m0 x9d h15 y235 ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x4d h16 y236 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x4d h16 y237 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x74 h6 y234 ff5 fs3 fc0 sc0 ls0 ws0">正<span class="_ _17"></span>确<span class="_ _6"></span>的<span class="_ _17"></span>误<span class="_ _12"></span>差<span class="_ _17"></span>，<span class="_ _12"></span>然<span class="_ _17"></span>后<span class="_ _12"></span>将<span class="_ _17"></span>其<span class="_ _12"></span>与<span class="_ _12"></span>局<span class="_ _17"> </span>部<span class="_ _12"></span>梯<span class="_ _17"></span>度</div><div class="t m0 x2 h15 y238 ffe fs3 fc0 sc0 ls0 ws0">f&apos;(z</div><div class="t m0 x80 h16 y239 ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x80 h16 y23a ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x14 h15 y238 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 xab h6 y23b ff5 fs3 fc0 sc0 ls0 ws0">相<span class="_ _2"></span>乘<span class="_ _2"></span>，<span class="_ _2"></span>把<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _6"></span>信<span class="_ _2"></span>息<span class="_ _2"></span>反<span class="_ _2"></span>向<span class="_ _6"></span>传到<span class="_ _6"></span>第</div><div class="t m0 x34 h15 y238 ffe fs3 fc0 sc0 ls0 ws0">k<span class="_ _3"></span>−<span class="_ _3"></span>1</div><div class="t m0 x61 h6 y23b ff5 fs3 fc0 sc0 ls0 ws0">层<span class="_ _2"></span>的<span class="_ _2"></span>第</div><div class="t m0 xb5 h15 y238 ffe fs3 fc0 sc0 ls0 ws0">j</div><div class="t m0 xe h6 y23b ff5 fs3 fc0 sc0 ls0 ws0">个<span class="_ _2"></span>神</div><div class="t m0 x2 h6 y23c ff5 fs3 fc0 sc0 ls0 ws0">经元上。</div><div class="t m0 x0 h23 y23d ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y23e ff5 fs3 fc0 sc0 ls0 ws0">因此到达<span class="_ _3"> </span><span class="ffe">z</span></div><div class="t m0 x83 h16 y23f ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x83 h16 y240 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x9d h15 y23e ff5 fs3 fc0 sc0 ls0 ws0">的误差为<span class="_ _3"> </span><span class="ffe">f&apos;(z</span></div><div class="t m0 xa7 h16 y23f ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xa7 h16 y241 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x5d h15 y23e ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x6b h16 y242 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6b h15 y243 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x12 h15 y23e ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x22 h16 y23f ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x22 h16 y241 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 xac h24 y23e ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 xb6 h15 y244 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x68 h16 y23f ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x68 h16 y241 ffe fs7 fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x9b h6 y23e ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h14 y245 ffd fs0 fc0 sc0 ls0 ws0">1.6<span class="_ _15"> </span>Training<span class="_ _15"> </span>with<span class="_ _15"> </span>Backpropagation<span class="_ _15"> </span>–<span class="_ _15"> </span>Vectorized</div><div class="t m0 x0 h6 y246 ff5 fs3 fc0 sc0 ls0 ws0">到目前为止，<span class="_ _2"></span>我们讨论了对<span class="_ _2"></span>模型中的<span class="_ _2"></span>给定参数计算<span class="_ _2"></span>梯度的方法。</div><div class="t m0 x0 h6 y247 ff5 fs3 fc0 sc0 ls0 ws0">这里会一般泛<span class="_ _2"></span>化上面的方法<span class="_ _2"></span>，让我们<span class="_ _2"></span>可以直接一次<span class="_ _2"></span>过更新权值矩</div><div class="t m0 x0 h6 y248 ff5 fs3 fc0 sc0 ls0 ws0">阵和偏置向量<span class="_ _2"></span>。注意这只是<span class="_ _2"></span>对上面模<span class="_ _2"></span>型的简单地扩<span class="_ _2"></span>展，这将有助</div><div class="t m0 x0 h5 y249 ff5 fs3 fc0 sc0 ls0 ws0">于更好理解在<span class="_ _2"></span>矩阵<span class="ff4">-</span>向量级别<span class="_ _2"></span>上进行误差反<span class="_ _2"></span>向传播的<span class="_ _2"></span>方法。</div><div class="t m0 x0 h6 y24a ff5 fs3 fc0 sc0 ls0 ws0">对<span class="_ _2"></span>更<span class="_ _6"></span>定<span class="_ _6"></span>的<span class="_ _6"></span>参<span class="_ _2"></span>数</div><div class="t m0 x81 h15 y24b ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x17 h16 y24c ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x17 h16 y24d ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x38 h6 y24a ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>知<span class="_ _6"></span>道<span class="_ _2"></span>它<span class="_ _6"></span>的<span class="_ _6"></span>误<span class="_ _2"></span>差<span class="_ _6"></span>梯<span class="_ _6"></span>度<span class="_ _6"></span>是</div><div class="t m0 x68 h25 y24b fff fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x62 h16 y24c ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x62 h16 y24d ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 x87 h15 y24b ffe fs3 fc0 sc0 ls0 ws0">⋅<span class="_ _3"></span>a</div><div class="t m0 xad h16 y24c ffe fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xad h16 y24d ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x8b h6 y24a ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h6 y24e ff5 fs3 fc0 sc0 ls0 ws0">其<span class="_ _2"></span>中</div><div class="t m0 x58 h15 y24f ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x80 h16 y250 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x53 h6 y24e ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>将</div><div class="t m0 x98 h15 y24f ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x17 h16 y250 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x8e h15 y24e ff5 fs3 fc0 sc0 ls0 ws0">映<span class="_ _2"></span>射<span class="_ _2"></span>到<span class="_ _7"> </span><span class="ffe">z</span></div><div class="t m0 x7a h16 y250 ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 x1b h6 y24e ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>矩<span class="_ _2"></span>阵<span class="_ _2"></span>。<span class="_ _2"></span>因<span class="_ _6"></span>此<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>可<span class="_ _6"></span>以<span class="_ _2"></span>确<span class="_ _2"></span>定<span class="_ _2"></span>整</div><div class="t m0 x0 h6 y251 ff5 fs3 fc0 sc0 ls0 ws0">个矩阵</div><div class="t m0 x80 h15 y252 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x6d h16 y253 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 xb7 h6 y251 ff5 fs3 fc0 sc0 ls0 ws0">的梯度误差为<span class="_ _2"></span>：</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y254 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ff10 fs1">↑<span class="_ _6"></span><span class="ffb">图<span class="_ _19"> </span><span class="ffc">7<span class="_ _2"></span></span>：<span class="_ _6"></span>从</span></span></div><div class="t m0 xb7 h20 y255 ffe fs1 fc0 sc0 ls0 ws0">δ</div><div class="t m0 xab h21 y196 ffe fsa fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x6a h13 y254 ffb fs1 fc0 sc0 ls0 ws0">到</div><div class="t m0 x18 h20 y255 ffe fs1 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x9d h21 y196 ffe fsa fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x45 h13 y254 ffb fs1 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>传<span class="_ _6"></span>播</div><div class="t m0 x28 h13 y9 ffb fs1 fc0 sc0 ls0 ws0">误差</div><div class="t m0 x28 h11 y256 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ff10 fs1">↑<span class="_ _6"></span><span class="ffb">图<span class="_ _19"> </span><span class="ffc">8<span class="_ _2"></span></span>：<span class="_ _6"></span>从</span></span></div><div class="t m0 xb7 h20 y257 ffe fs1 fc0 sc0 ls0 ws0">δ</div><div class="t m0 xab h21 y258 ffe fsa fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x6a h13 y256 ffb fs1 fc0 sc0 ls0 ws0">到</div><div class="t m0 x18 h20 y257 ffe fs1 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x9d h21 y258 ffe fsa fc0 sc0 ls0 ws0">(k−1)</div><div class="t m0 x45 h13 y256 ffb fs1 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>传<span class="_ _6"></span>播</div><div class="t m0 x28 h13 y259 ffb fs1 fc0 sc0 ls0 ws0">误差</div></div><div class="c x23 y25a w6 h18"><div class="t m0 x7 h19 y46 ff7 fs0 fc0 sc0 ls0 ws0">1.6 Notes<span class="_ _4"> </span>info.</div></div><div class="c x23 y25b w7 h1a"><div class="t m0 x7 hb y48 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y25b w8 h1a"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>-,<span class="_ _3"> </span>P-</div></div><div class="c x23 y25c w7 h1a"><div class="t m0 x7 hb y4a ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y25c w8 h1a"><div class="t m0 x7 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">Lecture3,<span class="_ _1"> </span>64:00</div></div><div class="c x23 y25d w7 h1b"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y25d w8 h1b"><div class="t m0 x7 h1c y48 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y25e w7 h1a"><div class="t m0 x7 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y25e w8 h1a"><div class="t m0 x7 h1c y4a ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y25f w6 h1d"><div class="t m0 x25 h1e y260 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA</div><div class="t m0 x26 hb y4a ff7 fs5 fc0 sc0 ls0 ws0">I</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi x0 y0 w1 hd" alt="" src="bg8.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x72 h15 y261 ffe fs3 fc0 sc0 ls0 ws0">∇</div><div class="t m0 x30 h16 y262 ffe fs7 fc0 sc0 ls0 ws0">W</div><div class="t m0 x31 h22 y263 ffe fsb fc0 sc0 ls0 ws0"></div><div class="t m0 x7d h15 y261 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x6a h15 yba ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x36 h16 y264 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x36 h16 y265 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x3 h15 yba ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xb8 h16 y264 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb8 h16 y265 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x6a h15 y266 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x36 h16 y267 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x36 h16 y268 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x3 h15 y266 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xb8 h16 y267 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb8 h16 y268 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x4e h15 y269 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x70 h15 yba ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9f h16 y264 ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9f h16 y265 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x90 h15 yba ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h16 y264 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x20 h16 y265 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x70 h15 y266 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9f h16 y267 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9f h16 y268 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x90 h15 y266 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h16 y267 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x20 h16 y268 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 xa6 h15 y269 ffe fs3 fc0 sc0 ls0 ws0">⋮</div><div class="t m0 x44 h15 y111 ffe fs3 fc0 sc0 ls0 ws0">⋯</div><div class="t m0 x44 h15 y26a ffe fs3 fc0 sc0 ls0 ws0">⋯</div><div class="t m0 x3c h15 y26b ffe fs3 fc0 sc0 ls0 ws0">⋱</div><div class="t m0 x12 h15 y261 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span></div><div class="t m0 x35 h16 y26c ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 xa9 h15 y26d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x85 h16 y26e ffe fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x85 h16 y26f ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x0 h6 y270 ff5 fs3 fc0 sc0 ls0 ws0">因此我们可以<span class="_ _2"></span>将整个矩阵形<span class="_ _2"></span>式的梯度<span class="_ _2"></span>写为在矩阵中<span class="_ _2"></span>的反向传播的</div><div class="t m0 x0 h6 y271 ff5 fs3 fc0 sc0 ls0 ws0">误差向量和前<span class="_ _2"></span>向激活输出的<span class="_ _2"></span>外积。</div><div class="t m0 xb1 h15 y272 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x18 h16 y273 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x18 h16 y274 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x3 h15 y272 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>f&apos;(<span class="_ _2"></span>z</div><div class="t m0 xa2 h16 y275 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x49 h15 y272 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _3"></span>∘</div><div class="t m0 x39 h15 y276 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x21 h16 y275 ffe fs7 fc0 sc0 ls0 ws0">(k)T</div><div class="t m0 x78 h15 y272 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x6b h16 y275 ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 x0 h15 y277 ff5 fs3 fc0 sc0 ls0 ws0">当<span class="_ _2"></span>然<span class="_ _2"></span>，<span class="_ _6"></span>这是<span class="_ _6"></span>假<span class="_ _2"></span>设<span class="_ _2"></span>在<span class="_ _6"></span>正<span class="_ _2"></span>向<span class="_ _2"></span>传<span class="_ _2"></span>播<span class="_ _6"></span>中<span class="_ _2"></span>，<span class="_ _2"></span>信<span class="_ _2"></span>号<span class="_ _6"></span><span class="ffe">z</span></div><div class="t m0 xac h16 y278 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x2c h15 y277 ff5 fs3 fc0 sc0 ls0 ws0">首<span class="_ _2"></span>先<span class="_ _2"></span>经<span class="_ _6"></span>过激<span class="_ _6"></span>活<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _7"> </span><span class="ffe">f</span></div><div class="t m0 x0 h6 y279 ff5 fs3 fc0 sc0 ls0 ws0">产生激活</div><div class="t m0 x6d h15 y27a ffe fs3 fc0 sc0 ls0 ws0">a</div><div class="t m0 x65 h16 y27b ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x7d h6 y279 ff5 fs3 fc0 sc0 ls0 ws0">，然后通过传<span class="_ _2"></span>递矩阵</div><div class="t m0 x9a h15 y27a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x3b h16 y27b ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x78 h15 y279 ff5 fs3 fc0 sc0 ls0 ws0">线性组合产生<span class="_ _4"> </span><span class="ffe">z</span></div><div class="t m0 x7b h16 y27b ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 xb4 h6 y279 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h15 y27c ff5 fs3 fc0 sc0 ls0 ws0">现在我们来<span class="_ _2"></span>看看如何能<span class="_ _2"></span>够计算误<span class="_ _2"></span>差向量<span class="_ _4"> </span><span class="ffe"></span></div><div class="t m0 x11 h16 y27d ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 xb h6 y27c ff5 fs3 fc0 sc0 ls0 ws0">。我们从上<span class="_ _2"></span>面的例</div><div class="t m0 x0 h6 y27e ff5 fs3 fc0 sc0 ls0 ws0">子<span class="_ _6"></span>中<span class="_ _6"></span>有<span class="_ _12"></span>，</div><div class="t m0 x53 h15 y27f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x31 h16 y280 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x31 h16 y281 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x6f h15 y27e ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>&apos;(</div><div class="t m0 x8e h15 y27f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h16 y280 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h16 y281 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x9 h15 y27e ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 xa1 h16 y282 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m1 xa1 h17 y283 ffe fs8 fc0 sc0 ls0 ws0"></div><div class="t m0 x88 h15 y27f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x41 h16 y280 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x41 h16 y281 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x8f h24 y27e ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h15 y27f ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x1c h16 y280 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x1c h16 y281 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x40 h6 y27e ff5 fs3 fc0 sc0 ls0 ws0">。<span class="_ _6"></span>可<span class="_ _6"></span>以<span class="_ _12"></span>简<span class="_ _6"></span>单<span class="_ _6"></span>地<span class="_ _6"></span>改<span class="_ _12"></span>写<span class="_ _6"></span>为<span class="_ _6"></span>矩</div><div class="t m0 x0 h6 y284 ff5 fs3 fc0 sc0 ls0 ws0">阵的形式：</div><div class="t m0 x36 h15 y285 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y286 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y287 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x4d h15 y285 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _15"></span>&apos;(</div><div class="t m0 xa2 h16 y288 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x41 h15 y285 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _3"></span>∘</div><div class="t m0 x39 h15 y289 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 xa8 h16 y288 ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x3c h15 y289 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x11 h16 y288 ffe fs7 fc0 sc0 ls0 ws0">(+1)</div><div class="t m0 x0 h6 y28a ff5 fs3 fc0 sc0 ls0 ws0">在<span class="_ _17"> </span>上<span class="_ _17"> </span>面<span class="_ _17"></span>的<span class="_ _17"></span>公<span class="_ _17"></span>式<span class="_ _17"></span>中</div><div class="t m0 x18 h15 y28b ffe fs3 fc0 sc0 ls0 ws0">∘</div><div class="t m0 x1f h6 y28a ff5 fs3 fc0 sc0 ls0 ws0">运<span class="_ _17"> </span>算<span class="_ _17"> </span>符<span class="_ _17"></span>是<span class="_ _17"></span>表<span class="_ _17"></span>示<span class="_ _17"></span>向<span class="_ _17"> </span>量<span class="_ _17"></span>之<span class="_ _17"></span>间<span class="_ _17"></span>对<span class="_ _17"></span>应<span class="_ _17"></span>元<span class="_ _17"></span>素<span class="_ _17"></span>的<span class="_ _17"></span>相<span class="_ _17"></span>乘</div><div class="t m0 x0 h6 y28c ff5 fs3 fc0 sc0 ls0 ws0">（</div><div class="t m0 x13 h15 y80 ffe fs3 fc0 sc0 ls0 ws0">ℝ</div><div class="t m0 x2 h16 y28d ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x64 h15 y28e ffe fs3 fc0 sc0 ls0 ws0">×</div><div class="t m0 x72 h15 y80 ffe fs3 fc0 sc0 ls0 ws0">ℝ</div><div class="t m0 x30 h16 y28d ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x14 h15 y28e ffe fs3 fc0 sc0 ls0 ws0">→</div><div class="t m0 x93 h15 y80 ffe fs3 fc0 sc0 ls0 ws0">ℝ</div><div class="t m0 x6a h16 y28d ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h6 y28c ff5 fs3 fc0 sc0 ls0 ws0">）。</div><div class="t m0 x0 h5 y28f ff5 fs3 fc0 sc0 ls0 ws0">计<span class="_ _6"></span>算<span class="_ _6"></span>效<span class="_ _12"></span>率<span class="_ _6"></span>：<span class="_ _12"></span>在<span class="_ _6"></span>探<span class="_ _6"></span>索<span class="_ _12"></span>了<span class="_ _8"> </span><span class="ff4">el<span class="_ _2"></span>ement-wise<span class="_ _8"> </span></span>的<span class="_ _2"></span>更<span class="_ _12"></span>新<span class="_ _6"></span>和<span class="_ _0"> </span><span class="ff4">vector-wis<span class="_ _2"></span>e<span class="_ _7"> </span></span>的</div><div class="t m0 x0 h5 y290 ff5 fs3 fc0 sc0 ls0 ws0">更<span class="_ _17"></span>新<span class="_ _12"></span>之<span class="_ _17"></span>后<span class="_ _12"></span>，<span class="_ _17"></span>必<span class="_ _12"></span>须<span class="_ _17"> </span>认<span class="_ _12"></span>识<span class="_ _17"> </span>到<span class="_ _17"></span>在<span class="_ _12"></span>科<span class="_ _17"></span>学<span class="_ _12"></span>计<span class="_ _17"></span>算<span class="_ _12"></span>环<span class="_ _17"> </span>境<span class="_ _17"></span>中<span class="_ _12"></span>，<span class="_ _17"></span>如<span class="_ _13"> </span><span class="ff4">MATLAB<span class="_ _0"> </span></span>或</div><div class="t m0 x0 h5 y291 ff4 fs3 fc0 sc0 ls0 ws0">Python<span class="_ _2"></span><span class="ff5">（<span class="_ _6"></span>使用<span class="_ _7"> </span></span>Nump<span class="_ _2"></span>y<span class="_ _15"> </span>/<span class="_ _4"> </span>Sci<span class="_ _2"></span>py<span class="_ _15"> </span><span class="ff5">库<span class="_ _2"></span>）<span class="_ _2"></span>，<span class="_ _2"></span>向<span class="_ _2"></span>量<span class="_ _2"></span>化<span class="_ _6"></span>运<span class="_ _2"></span>算<span class="_ _2"></span>的<span class="_ _2"></span>计<span class="_ _2"></span>算<span class="_ _2"></span>效<span class="_ _6"></span>率<span class="_ _2"></span>是</span></div><div class="t m0 x0 h6 y292 ff5 fs3 fc0 sc0 ls0 ws0">非常高的。<span class="_ _2"></span>因此在实际中<span class="_ _2"></span>应该使用<span class="_ _2"></span>向量化运算。</div><div class="t m0 x0 h5 y293 ff5 fs3 fc0 sc0 ls0 ws0">此外，我们也<span class="_ _2"></span>要减少反向传<span class="_ _2"></span>播中的多<span class="_ _2"></span>余的计算<span class="ff4">——<span class="_ _2"></span></span>例如，注<span class="_ _2"></span>意到</div><div class="t m0 x0 h15 y294 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x8d h16 y295 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x6c h6 y296 ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _6"></span>直<span class="_ _6"></span>接<span class="_ _6"></span>依<span class="_ _6"></span>赖<span class="_ _12"></span>在</div><div class="t m0 x69 h15 y294 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x4e h16 y295 ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 xa1 h6 y296 ff5 fs3 fc0 sc0 ls0 ws0">上<span class="_ _6"></span>。<span class="_ _6"></span>所<span class="_ _6"></span>以<span class="_ _6"></span>我<span class="_ _12"></span>们<span class="_ _6"></span>要<span class="_ _6"></span>保<span class="_ _6"></span>证<span class="_ _6"></span>使<span class="_ _6"></span>用</div><div class="t m0 x19 h15 y294 ffe fs3 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x7b h16 y295 ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 xb4 h6 y296 ff5 fs3 fc0 sc0 ls0 ws0">更<span class="_ _6"></span>新</div><div class="t m0 x0 h15 y297 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x2e h16 y1c3 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x58 h15 y298 ff5 fs3 fc0 sc0 ls0 ws0">时<span class="_ _12"></span>，<span class="_ _12"></span>要<span class="_ _17"></span>保<span class="_ _6"></span>存<span class="_ _14"> </span><span class="ffe">δ</span></div><div class="t m0 x8e h16 y1c3 ffe fs7 fc0 sc0 ls0 ws0">(k+1)</div><div class="t m0 x9e h15 y298 ff5 fs3 fc0 sc0 ls0 ws0">用<span class="_ _12"></span>于<span class="_ _12"></span>后<span class="_ _17"></span>面<span class="_ _13"> </span><span class="ffe">δ</span></div><div class="t m0 x1c h16 y1c3 ffe fs7 fc0 sc0 ls0 ws0">(k)</div><div class="t m0 x40 h15 y298 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _12"></span>计<span class="_ _12"></span>算<span class="_ _17"></span><span class="ff4">-<span class="_ _6"></span></span>然<span class="_ _17"></span>后<span class="_ _6"></span>计<span class="_ _17"></span>算<span class="_ _0"> </span><span class="ffe">(k<span class="_ _3"></span>−</span></div><div class="t m0 x0 h15 y299 ffe fs3 fc0 sc0 ls0 ws0">1).<span class="_ _11"></span>.<span class="_ _11"></span>.<span class="_ _1"></span>(1)</div><div class="t m0 x72 h6 y29a ff5 fs3 fc0 sc0 ls0 ws0">层的<span class="_ _2"></span>时候<span class="_ _2"></span>重<span class="_ _2"></span>复上<span class="_ _2"></span>述<span class="_ _2"></span>的步<span class="_ _2"></span>骤。<span class="_ _2"></span>这<span class="_ _2"></span>样的<span class="_ _2"></span>递归<span class="_ _2"></span>过<span class="_ _2"></span>程<span class="_ _2"></span>是使<span class="_ _2"></span>得反<span class="_ _2"></span>向</div><div class="t m0 x0 h6 y29b ff5 fs3 fc0 sc0 ls0 ws0">传播成为计算<span class="_ _2"></span>上可负担的过<span class="_ _2"></span>程。</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 yf3 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ffb fs1">误差<span class="_ _2"></span>按<span class="_ _2"></span>以<span class="_ _2"></span>下<span class="_ _2"></span>方<span class="_ _2"></span>式<span class="_ _2"></span>从<span class="_ _2"></span><span class="fff">（<span class="_ _2"></span><span class="ffc">k+<span class="_ _2"></span>1</span>）<span class="_ _2"></span></span>层<span class="_ _2"></span>传</span></div><div class="t m0 x28 h12 y29c ffb fs1 fc0 sc0 ls0 ws0">播到<span class="fff">（<span class="ffc">k</span>）</span>层：</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg9.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h10 y29d ff9 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _9"> </span>Neural<span class="_ _3"> </span>Networks:<span class="_ _4"> </span>Tips<span class="_ _4"> </span>and<span class="_ _4"> </span>Tricks</div><div class="t m0 x0 h14 y29e ffd fs0 fc0 sc0 ls0 ws0">2.1<span class="_ _15"> </span>Gradient<span class="_ _15"> </span>Check</div><div class="t m0 x0 h6 y29f ff5 fs3 fc0 sc0 ls0 ws0">在上一部分中<span class="_ _2"></span>，我们详细地<span class="_ _2"></span>讨论了如<span class="_ _2"></span>何用基于微积<span class="_ _2"></span>分的方法计算</div><div class="t m0 x0 h6 y2a0 ff5 fs3 fc0 sc0 ls0 ws0">神经网络中的<span class="_ _2"></span>参数的误差梯<span class="_ _2"></span>度<span class="fff">／</span>更新<span class="_ _2"></span>。这里我们介<span class="_ _2"></span>绍一种用<span class="_ _2"></span>数值</div><div class="t m0 x0 h5 y2a1 ff5 fs3 fc0 sc0 ls0 ws0">近似这些梯度<span class="_ _2"></span>的方法<span class="ff4">——<span class="_ _2"></span></span>虽然在计<span class="_ _2"></span>算上的低效不<span class="_ _2"></span>能直接用<span class="_ _2"></span>于训练</div><div class="t m0 x0 h6 y2a2 ff5 fs3 fc0 sc0 ls0 ws0">神<span class="_ _2"></span>经<span class="_ _6"></span>网<span class="_ _6"></span>络<span class="_ _2"></span>，<span class="_ _6"></span>这<span class="_ _6"></span>种<span class="_ _6"></span>方<span class="_ _2"></span>法<span class="_ _6"></span>可<span class="_ _6"></span>以<span class="_ _6"></span>非<span class="_ _2"></span>常<span class="_ _6"></span>准<span class="_ _6"></span>确<span class="_ _2"></span>地<span class="_ _6"></span>估<span class="_ _6"></span>计<span class="_ _6"></span>任<span class="_ _2"></span>何<span class="_ _6"></span>参<span class="_ _6"></span>数<span class="_ _2"></span>的<span class="_ _6"></span>导<span class="_ _6"></span>数<span class="_ _6"></span>；<span class="_ _2"></span>因</div><div class="t m0 x0 h6 y2a3 ff5 fs3 fc0 sc0 ls0 ws0">此，它可以作<span class="_ _2"></span>为对导数的正<span class="_ _2"></span>确性的有<span class="_ _2"></span>用的检查。给<span class="_ _2"></span>定一个模型的</div><div class="t m0 x0 h6 y2a4 ff5 fs3 fc0 sc0 ls0 ws0">参<span class="_ _17"> </span>数<span class="_ _17"> </span>向<span class="_ _17"> </span>量</div><div class="t m0 x65 h15 y2a5 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 xb9 h6 y2a4 ff5 fs3 fc0 sc0 ls0 ws0">和<span class="_ _17"> </span>损<span class="_ _17"> </span>失<span class="_ _17"> </span>函<span class="_ _17"> </span>数</div><div class="t m0 x56 h15 y2a5 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x9f h6 y2a4 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _17"> </span>围<span class="_ _17"> </span>绕</div><div class="t m0 x5d h15 y2a5 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 xac h16 y2a6 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6b h5 y2a4 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _17"> </span>数<span class="_ _17"> </span>值<span class="_ _17"> </span>梯<span class="_ _17"> </span>度<span class="_ _17"> </span>由 <span class="ff4">central</span></div><div class="t m0 x0 h5 y2a7 ff4 fs3 fc0 sc0 ls0 ws0">difference<span class="_ _4"> </span>formul<span class="_ _2"></span>a<span class="_ _4"> </span><span class="ff5">得出：</span></div><div class="t m0 x69 h15 y2a8 ffe fs3 fc0 sc0 ls0 ws0">&apos;()<span class="_ _15"></span>≈</div><div class="t m0 xa2 h15 y2a9 ffe fs3 fc0 sc0 ls0 ws0">(</div><div class="t m0 x4a h16 y2aa ffe fs7 fc0 sc0 ls0 ws0">(+)</div><div class="t m0 x1b h15 y2a9 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _3"></span>−<span class="_ _3"></span>(</div><div class="t m0 x6b h16 y2aa ffe fs7 fc0 sc0 ls0 ws0">(−)</div><div class="t m0 x55 h15 y2a9 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x20 h15 y2ab ffe fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x0 h6 y2ac ff5 fs3 fc0 sc0 ls0 ws0">其<span class="_ _2"></span>中</div><div class="t m0 x58 h15 y2ad ffe fs3 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 xba h15 y2ac ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>一<span class="_ _2"></span>个<span class="_ _6"></span>很<span class="_ _2"></span>小<span class="_ _2"></span>的<span class="_ _6"></span>值<span class="_ _2"></span>（<span class="_ _2"></span>一<span class="_ _6"></span>般<span class="_ _2"></span>约<span class="_ _2"></span>为<span class="_ _7"> </span><span class="ffe">1</span></div><div class="t m0 x1c h15 y2ad ffe fs3 fc0 sc0 ls0 ws0">e</div><div class="t m0 x1d h16 y2ae ffe fs7 fc0 sc0 ls0 ws0">−5</div><div class="t m0 x4c h6 y2ac ff5 fs3 fc0 sc0 ls0 ws0">）<span class="_ _2"></span>。<span class="_ _2"></span>当<span class="_ _6"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>使<span class="_ _6"></span>用</div><div class="t m0 xb5 h15 y2ad ffe fs3 fc0 sc0 ls0 ws0">+ϵ</div><div class="t m0 x8b h6 y2ac ff5 fs3 fc0 sc0 ls0 ws0">扰</div><div class="t m0 x0 h6 y2af ff5 fs3 fc0 sc0 ls0 ws0">动<span class="_ _17"></span>参<span class="_ _17"></span>数</div><div class="t m0 x72 h15 y2b0 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x65 h6 y2af ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _17"></span>第</div><div class="t m0 x1e h15 y2b0 ffe fs3 fc0 sc0 ls0 ws0">i</div><div class="t m0 x37 h6 y2af ff5 fs3 fc0 sc0 ls0 ws0">个<span class="_ _17"></span>元<span class="_ _17"></span>素<span class="_ _17"></span>时<span class="_ _17"></span>，<span class="_ _12"></span>就<span class="_ _17"> </span>可<span class="_ _17"> </span>以<span class="_ _17"> </span>在<span class="_ _17"> </span>前<span class="_ _17"> </span>向<span class="_ _17"></span>传<span class="_ _17"></span>播<span class="_ _17"></span>上<span class="_ _17"></span>计<span class="_ _12"></span>算<span class="_ _11"> </span>误<span class="_ _17"></span>差</div><div class="t m0 x0 h15 y2b1 ffe fs3 fc0 sc0 ls0 ws0">J(</div><div class="t m0 x29 h15 y2b2 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x13 h16 y2b3 ffe fs7 fc0 sc0 ls0 ws0">(i+)</div><div class="t m0 x64 h15 y2b1 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _4"></span><span class="ff5">。相似<span class="_ _2"></span>地，<span class="_ _2"></span>当<span class="_ _2"></span>我们使<span class="_ _2"></span>用</span></div><div class="t m0 x3f h15 y2b2 ffe fs3 fc0 sc0 ls0 ws0">−ϵ</div><div class="t m0 x9a h6 y2b1 ff5 fs3 fc0 sc0 ls0 ws0">扰动参<span class="_ _2"></span>数</div><div class="t m0 x22 h15 y2b2 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x84 h15 y2b1 ff5 fs3 fc0 sc0 ls0 ws0">的第<span class="_ _4"> </span><span class="ffe">i<span class="_ _4"></span></span>个<span class="_ _2"></span>元素时<span class="_ _2"></span>，</div><div class="t m0 x0 h15 y2b4 ff5 fs3 fc0 sc0 ls0 ws0">就可<span class="_ _2"></span>以<span class="_ _2"></span>在<span class="_ _2"></span>前<span class="_ _2"></span>向<span class="_ _2"></span>传<span class="_ _2"></span>播<span class="_ _2"></span>上<span class="_ _2"></span>计<span class="_ _2"></span>算<span class="_ _2"></span>误<span class="_ _2"></span>差<span class="_ _15"> </span><span class="ffe">J(θ</span></div><div class="t m0 x39 h16 y2b5 ffe fs7 fc0 sc0 ls0 ws0">(i−)</div><div class="t m0 x1c h15 y2b4 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _15"></span><span class="ff5">。因<span class="_ _2"></span>此<span class="_ _2"></span>，<span class="_ _2"></span>计<span class="_ _2"></span>算<span class="_ _2"></span>两<span class="_ _2"></span>次<span class="_ _2"></span>前<span class="_ _2"></span>向<span class="_ _2"></span>传</span></div><div class="t m0 x0 h6 y2b6 ff5 fs3 fc0 sc0 ls0 ws0">播，我们可以<span class="_ _2"></span>估计在模型中<span class="_ _2"></span>任意给定<span class="_ _2"></span>参数的梯度。<span class="_ _2"></span>我们注意到数</div><div class="t m0 x0 h6 y2b7 ff5 fs3 fc0 sc0 ls0 ws0">值梯度的定义<span class="_ _2"></span>和导数的定义<span class="_ _2"></span>很相似，<span class="_ _2"></span>其中，在标量<span class="_ _2"></span>的情况下：</div><div class="t m0 x4e h15 y2b8 ffe fs3 fc0 sc0 ls0 ws0">&apos;()<span class="_ _4"></span>≈</div><div class="t m0 x7a h15 y2b9 ffe fs3 fc0 sc0 ls0 ws0"><span class="_ _13"> </span><span class="_ _3"></span>+<span class="_ _3"></span> −<span class="_ _1"></span><span class="_ _13"> </span></div><div class="t m0 x43 h15 y2ba ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h5 y2bb ff5 fs3 fc0 sc0 ls0 ws0">当然，还是<span class="_ _2"></span>有一点<span class="_ _2"></span>不同<span class="ff4">——</span>上<span class="_ _2"></span>面的定义仅仅<span class="_ _2"></span>在正向<span class="_ _2"></span>扰动</div><div class="t m0 xae h15 y2bc ffe fs3 fc0 sc0 ls0 ws0">x</div><div class="t m0 x63 h6 y2bb ff5 fs3 fc0 sc0 ls0 ws0">计算梯</div><div class="t m0 x0 h6 y2bd ff5 fs3 fc0 sc0 ls0 ws0">度<span class="_ _12"></span>。<span class="_ _12"></span>虽<span class="_ _12"></span>然<span class="_ _17"></span>是<span class="_ _6"></span>可<span class="_ _17"></span>以<span class="_ _6"></span>用<span class="_ _12"></span>这<span class="_ _12"></span>种<span class="_ _17"></span>方<span class="_ _6"></span>式<span class="_ _17"></span>定<span class="_ _6"></span>义<span class="_ _17"></span>数<span class="_ _6"></span>值<span class="_ _12"></span>梯<span class="_ _17"></span>度<span class="_ _6"></span>，<span class="_ _12"></span>但<span class="_ _17"></span>在<span class="_ _6"></span>实<span class="_ _17"></span>际<span class="_ _6"></span>中<span class="_ _17"></span>使<span class="_ _6"></span>用</div><div class="t m0 x0 h5 y2be ff4 fs3 fc0 sc0 ls0 ws0">central<span class="_ _15"> </span>differen<span class="_ _2"></span>ce<span class="_ _15"> </span>formula<span class="_ _15"> </span><span class="ff5">常<span class="_ _6"></span>常<span class="_ _2"></span>可<span class="_ _6"></span>以<span class="_ _2"></span>更<span class="_ _2"></span>准<span class="_ _6"></span>确<span class="_ _2"></span>和<span class="_ _2"></span>更<span class="_ _6"></span>稳<span class="_ _2"></span>定<span class="_ _6"></span>，<span class="_ _2"></span>因<span class="_ _2"></span>为<span class="_ _6"></span>我</span></div><div class="t m0 x0 h6 y2bf ff5 fs3 fc0 sc0 ls0 ws0">们在两个方向<span class="_ _2"></span>都对参数扰动<span class="_ _2"></span>。为了更<span class="_ _2"></span>好地逼近一个<span class="_ _2"></span>点附近的导数</div><div class="t m0 x0 h15 y2c0 ff4 fs3 fc0 sc0 ls0 ws0">/<span class="_ _2"></span><span class="ff5">斜率<span class="_ _2"></span>，<span class="_ _6"></span>我们<span class="_ _2"></span>需<span class="_ _2"></span>要<span class="_ _2"></span>在<span class="_ _2"></span>该<span class="_ _2"></span>点<span class="_ _2"></span>的<span class="_ _2"></span>左<span class="_ _2"></span>边<span class="_ _2"></span>和<span class="_ _2"></span>右<span class="_ _2"></span>边<span class="_ _2"></span>检<span class="_ _2"></span>查<span class="_ _2"></span>函<span class="_ _2"></span>数<span class="_ _15"> </span><span class="ffe">f&apos;<span class="_ _15"></span></span>的<span class="_ _2"></span>行<span class="_ _2"></span>为<span class="_ _2"></span>。<span class="_ _2"></span>也<span class="_ _2"></span>可</span></div><div class="t m0 x0 h5 y2c1 ff5 fs3 fc0 sc0 ls0 ws0">以<span class="_ _6"></span>使<span class="_ _6"></span>用<span class="_ _6"></span>泰<span class="_ _6"></span>勒<span class="_ _6"></span>定<span class="_ _6"></span>理<span class="_ _6"></span>来<span class="_ _6"></span>表<span class="_ _6"></span>示<span class="_ _8"> </span><span class="ff4">cent<span class="_ _2"></span>ral<span class="_ _15"> </span>differe<span class="_ _2"></span>nce<span class="_ _7"> </span>formula<span class="_ _7"> </span></span>有</div><div class="t m0 x89 h15 y2c2 ffe fs3 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 xbb h16 y2c3 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe h6 y2c1 ff5 fs3 fc0 sc0 ls0 ws0">比<span class="_ _6"></span>例</div><div class="t m0 x0 h6 y2c4 ff5 fs3 fc0 sc0 ls0 ws0">误差，这相当<span class="_ _2"></span>小，而导数定<span class="_ _2"></span>义更容易<span class="_ _2"></span>出错。</div><div class="t m0 x0 h6 y2c5 ff5 fs3 fc0 sc0 ls0 ws0">现在你可能会<span class="_ _2"></span>产生疑问，如<span class="_ _2"></span>果这个方<span class="_ _2"></span>法这么准确，<span class="_ _2"></span>为什么我们不</div><div class="t m0 x0 h6 y2c6 ff5 fs3 fc0 sc0 ls0 ws0">用它而不是用<span class="_ _2"></span>反向传播来计<span class="_ _2"></span>算神经网<span class="_ _2"></span>络的梯度？</div><div class="t m0 x0 h5 y2c7 ff5 fs3 fc0 sc0 ls0 ws0">这是因为效率<span class="_ _2"></span>的问题<span class="ff4">——<span class="_ _2"></span></span>每当我们<span class="_ _2"></span>想计算一个元<span class="_ _2"></span>素的梯度<span class="_ _2"></span>，需要</div><div class="t m0 x0 h6 y2c8 ff5 fs3 fc0 sc0 ls0 ws0">在网络中做两<span class="_ _2"></span>次前向传播，<span class="_ _2"></span>这样是很<span class="_ _2"></span>耗费计算资源<span class="_ _2"></span>的。再者，很</div><div class="t m0 x0 h6 y2c9 ff5 fs3 fc0 sc0 ls0 ws0">多大规模的神<span class="_ _2"></span>经网络含有几<span class="_ _2"></span>百万的参<span class="_ _2"></span>数，对每个参<span class="_ _2"></span>数都计算两次</div><div class="t m0 x0 h5 y2ca ff5 fs3 fc0 sc0 ls0 ws0">明显<span class="_ _2"></span>不是<span class="_ _2"></span>一<span class="_ _2"></span>个好的<span class="_ _2"></span>选<span class="_ _2"></span>择。<span class="_ _2"></span>同时<span class="_ _2"></span>在<span class="_ _2"></span>例如<span class="_ _15"> </span><span class="ff4">SGD<span class="_ _4"> </span></span>这<span class="_ _2"></span>样<span class="_ _2"></span>的优化<span class="_ _2"></span>技<span class="_ _2"></span>术中<span class="_ _2"></span>，</div><div class="t m0 x0 h6 y2cb ff5 fs3 fc0 sc0 ls0 ws0">我们需要通过<span class="_ _2"></span>数千次的迭代<span class="_ _2"></span>来计算梯<span class="_ _2"></span>度，使用这样<span class="_ _2"></span>的方法很快会</div><div class="t m0 x0 h6 y2cc ff5 fs3 fc0 sc0 ls0 ws0">变得难以应付<span class="_ _2"></span>。这种低效性<span class="_ _2"></span>是我们只<span class="_ _2"></span>使用梯度检验<span class="_ _2"></span>来验证我们的</div><div class="t m0 x0 h6 y2cd ff5 fs3 fc0 sc0 ls0 ws0">分析梯度的正<span class="_ _2"></span>确性的原因。<span class="_ _2"></span>梯度检验<span class="_ _2"></span>的实现如下所<span class="_ _2"></span>示：</div></div><div class="c x23 y2ce w6 h18"><div class="t m0 x7 h19 y2cf ff7 fs0 fc0 sc0 ls0 ws0">2.1 Notes<span class="_ _15"> </span>info.</div></div><div class="c x23 y2d0 w7 h1a"><div class="t m0 x7 hb y15b ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y2d0 w8 h1a"><div class="t m0 x7 hb y15b ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>P47</div></div><div class="c x23 y2d1 w7 h1a"><div class="t m0 x7 hb y2d2 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y2d1 w8 h1a"><div class="t m0 x7 hb y2d2 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>57:30</div></div><div class="c x23 y2d3 w7 h1b"><div class="t m0 x7 hb y15b ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y2d3 w8 h1b"><div class="t m0 x7 h1c y15b ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y2d4 w7 h1a"><div class="t m0 x7 hb y2d2 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y2d4 w8 h1a"><div class="t m0 x7 h1c y2d2 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y2d5 w6 h1d"><div class="t m0 x25 h1e y2d6 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA</div><div class="t m0 x26 hb y2d2 ff7 fs5 fc0 sc0 ls0 ws0">I</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y2d7 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _13"> </span><span class="ffb fs1">梯<span class="_ _12"></span>度<span class="_ _6"></span>检<span class="_ _12"></span>查<span class="_ _12"></span>是<span class="_ _6"></span>比<span class="_ _12"></span>较<span class="_ _12"></span>分<span class="_ _12"></span>析<span class="_ _6"></span>梯<span class="_ _12"></span>度<span class="_ _12"></span>和<span class="_ _6"></span>数</span></div><div class="t m0 x28 h13 y2d8 ffb fs1 fc0 sc0 ls0 ws0">值<span class="_ _17"> </span>梯<span class="_ _17"> </span>度<span class="_ _11"> </span>的<span class="_ _17"> </span>好<span class="_ _17"> </span>方<span class="_ _17"> </span>法<span class="_ _11"> </span>。<span class="_ _17"> </span>分<span class="_ _17"> </span>析<span class="_ _11"> </span>梯<span class="_ _17"> </span>度<span class="_ _17"> </span>应<span class="_ _17"> </span>接</div><div class="t m0 x28 h13 y2d9 ffb fs1 fc0 sc0 ls0 ws0">近<span class="_ _17"> </span>，<span class="_ _17"> </span>数<span class="_ _11"> </span>值<span class="_ _17"> </span>梯<span class="_ _17"> </span>度<span class="_ _17"> </span>可<span class="_ _11"> </span>使<span class="_ _17"> </span>用<span class="_ _17"> </span>以<span class="_ _11"> </span>下<span class="_ _17"> </span>公<span class="_ _17"> </span>式<span class="_ _17"> </span>计</div><div class="t m0 x28 h13 y2da ffb fs1 fc0 sc0 ls0 ws0">算：</div><div class="t m0 x13 h20 y2db ffe fs1 fc0 sc0 ls0 ws0">f&apos;(θ)<span class="_ _4"></span>≈</div><div class="t m0 x30 h20 y2dc ffe fs1 fc0 sc0 ls0 ws0">J(θ</div><div class="t m0 xa5 h21 y2dd ffe fsa fc0 sc0 ls0 ws0">(i+)</div><div class="t m0 x7e h20 y2dc ffe fs1 fc0 sc0 ls0 ws0">)<span class="_ _1"></span>−<span class="_ _3"></span>J(θ</div><div class="t m0 x26 h21 y2dd ffe fsa fc0 sc0 ls0 ws0">(i−)</div><div class="t m0 x45 h20 y2dc ffe fs1 fc0 sc0 ls0 ws0">)</div><div class="t m0 x17 h20 y2de ffe fs1 fc0 sc0 ls0 ws0">2ϵ</div><div class="t m0 x28 h20 y2df ffe fs1 fc0 sc0 ls0 ws0">J(</div><div class="t m0 x6 h20 y2e0 ffe fs1 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x0 h21 y2e1 ffe fsa fc0 sc0 ls0 ws0">(i+)</div><div class="t m0 x13 h20 y2df ffe fs1 fc0 sc0 ls0 ws0">)<span class="ffb">和<span class="_ _19"> </span></span>J(</div><div class="t m0 x2f h20 y2e0 ffe fs1 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x30 h21 y2e1 ffe fsa fc0 sc0 ls0 ws0">(i−)</div><div class="t m0 x7d h20 y2df ffe fs1 fc0 sc0 ls0 ws0">)<span class="_ _2"></span><span class="ffb">可<span class="_ _2"></span>以<span class="_ _2"></span>使<span class="_ _2"></span>用<span class="_ _2"></span>两<span class="_ _2"></span>个<span class="_ _2"></span>正<span class="_ _2"></span>向</span></div><div class="t m0 x28 h13 y2e2 ffb fs1 fc0 sc0 ls0 ws0">过程进行评<span class="_ _2"></span>估。</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi xa y0 wa hd" alt="" src="bga.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x0 y2e3 wb h26"><div class="t m0 x7 h27 y2e4 ff11 fs5 fc0 sc0 ls0 ws0">def <span class="ff12">eval_numerical_gradient(f, x):</span></div><div class="t m0 xbc h28 y2e5 ff13 fs5 fc0 sc0 ls0 ws0">&quot;&quot;&quot;</div><div class="t m0 xbc h28 y2e6 ff13 fs5 fc0 sc0 ls0 ws0">a naive implementation of numerical gradient of f at x</div><div class="t m0 xbc h28 y2e7 ff13 fs5 fc0 sc0 ls0 ws0">- f should be a function that takes a single argument</div><div class="t m0 xbc h28 y2e8 ff13 fs5 fc0 sc0 ls0 ws0">- x is the point (numpy array) to evaluate the gradient at</div><div class="t m0 xbc h28 y2e9 ff13 fs5 fc0 sc0 ls0 ws0">&quot;&quot;&quot;</div><div class="t m0 xbc h28 y2ea ff12 fs5 fc0 sc0 ls0 ws0">f(x) = f(x) <span class="ff13"># evaluate function value at original point</span></div><div class="t m0 xbc h29 y2eb ff12 fs5 fc0 sc0 ls0 ws0">grad = np.zeros(x.shape)</div><div class="t m0 xbc h29 y2ec ff12 fs5 fc0 sc0 ls0 ws0">h = 0.00001</div><div class="t m0 xbc h28 y2ed ff13 fs5 fc0 sc0 ls0 ws0"># iterate over all indexes in x</div><div class="t m0 xbc h29 y2ee ff12 fs5 fc0 sc0 ls0 ws0">it = np.nditer(x, flags=[&apos;</div><div class="t m0 x52 h2a y2ef ff12 fsd fc0 sc0 ls0 ws0">multi_index</div><div class="t m0 x39 h29 y2ee ff12 fs5 fc0 sc0 ls0 ws0">&apos;,op_flags=[&apos;</div><div class="t m0 x68 h2b y2ef ff12 fs7 fc0 sc0 ls0 ws0">readwrite</div><div class="t m0 xbb h29 y2ee ff12 fs5 fc0 sc0 ls0 ws0">&apos;])</div><div class="t m0 xbc h27 y2f0 ff11 fs5 fc0 sc0 ls0 ws0">while not <span class="ff12">it.finished:</span></div><div class="t m0 xbd h28 y2f1 ff13 fs5 fc0 sc0 ls0 ws0"># evaluate function at x+h</div><div class="t m0 xbd h29 y2f2 ff12 fs5 fc0 sc0 ls0 ws0">ix = it.multi_index</div><div class="t m0 xbd h29 y2f3 ff12 fs5 fc0 sc0 ls0 ws0">old_value = x[ix]</div><div class="t m0 xbd h28 y2f4 ff12 fs5 fc0 sc0 ls0 ws0">x[ix] = old_value + h <span class="ff13"># increment by h</span></div><div class="t m0 xbd h28 y2f5 ff12 fs5 fc0 sc0 ls0 ws0">fxh_left = f(x) <span class="ff13"># evaluate f(x + h)</span></div><div class="t m0 xbd h28 y2f6 ff12 fs5 fc0 sc0 ls0 ws0">x[ix] = old_value - h <span class="ff13"># decrement by h</span></div><div class="t m0 xbd h28 y2f7 ff12 fs5 fc0 sc0 ls0 ws0">fxh_right = f(x) <span class="ff13"># evaluate f(x - h)</span></div><div class="t m0 xbd h28 y2f8 ff13 fs5 fc0 sc0 ls0 ws0"># restore to previous value (very important!)</div><div class="t m0 xbd h29 y2f9 ff12 fs5 fc0 sc0 ls0 ws0">x[ix] = old_value</div><div class="t m0 xbd h28 y2fa ff13 fs5 fc0 sc0 ls0 ws0"># compute the partial derivative</div><div class="t m0 xbd h28 y2fb ff13 fs5 fc0 sc0 ls0 ws0"># the slope</div><div class="t m0 xbd h29 y2fc ff12 fs5 fc0 sc0 ls0 ws0">grad[ix] = (fxh_left - fxh_right) / (2 * h)</div><div class="t m0 xbd h28 y2fd ff12 fs5 fc0 sc0 ls0 ws0">it.iternext() <span class="ff13"># step to next dimension</span></div><div class="t m0 xbc h27 y2fe ff11 fs5 fc0 sc0 ls0 ws0">return <span class="ff12">grad</span></div></div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h14 y2ff ffd fs0 fc0 sc0 ls0 ws0">2.2<span class="_ _15"> </span>Regularization</div><div class="t m0 x0 h6 y300 ff5 fs3 fc0 sc0 ls0 ws0">和很多机器学<span class="_ _2"></span>习的模型一样<span class="_ _2"></span>，神经网<span class="_ _2"></span>络很容易过拟<span class="_ _2"></span>合，这令到模</div><div class="t m0 x0 h6 y301 ff5 fs3 fc0 sc0 ls0 ws0">型在训练集上<span class="_ _2"></span>能获得近乎完<span class="_ _2"></span>美的表现<span class="_ _2"></span>，但是却不能<span class="_ _2"></span>泛化到测试集</div><div class="t m0 x0 h5 y5a ff5 fs3 fc0 sc0 ls0 ws0">上<span class="_ _2"></span>。<span class="_ _2"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>常<span class="_ _6"></span>见<span class="_ _2"></span>的<span class="_ _2"></span>用<span class="_ _2"></span>于<span class="_ _6"></span>解<span class="_ _2"></span>决<span class="_ _2"></span>过<span class="_ _2"></span>拟<span class="_ _6"></span>合<span class="_ _2"></span>（<span class="_ _2"></span><span class="ff4">“<span class="_ _2"></span></span>高<span class="_ _6"></span>方<span class="_ _2"></span>差<span class="_ _2"></span>问<span class="_ _2"></span>题<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>）<span class="_ _6"></span>的<span class="_ _2"></span>方<span class="_ _2"></span>法<span class="_ _2"></span>是<span class="_ _6"></span>使</div><div class="t m0 x0 h6 y302 ff5 fs3 fc0 sc0 ls0 ws0">用</div><div class="t m0 x13 h15 y303 ffe fs3 fc0 sc0 ls0 ws0">L2</div><div class="t m0 x64 h6 y302 ff5 fs3 fc0 sc0 ls0 ws0">正则<span class="_ _6"></span>化<span class="_ _2"></span>。我<span class="_ _6"></span>们<span class="_ _2"></span>只<span class="_ _2"></span>需要<span class="_ _6"></span>在<span class="_ _2"></span>损<span class="_ _2"></span>失<span class="_ _2"></span>函<span class="_ _2"></span>数</div><div class="t m0 x3c h15 y303 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x11 h6 y302 ff5 fs3 fc0 sc0 ls0 ws0">上增<span class="_ _6"></span>加<span class="_ _2"></span>一个<span class="_ _6"></span>正<span class="_ _2"></span>则<span class="_ _2"></span>项，<span class="_ _6"></span>现</div><div class="t m0 x0 h6 y304 ff5 fs3 fc0 sc0 ls0 ws0">在的损失函数<span class="_ _2"></span>如下：</div><div class="t m0 x9d h15 y305 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x1f h16 ye7 ffe fs7 fc0 sc0 ls0 ws0">R</div><div class="t m0 xb2 h15 y305 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>J<span class="_ _3"></span>+<span class="_ _3"></span>λ</div><div class="t m0 xa7 h16 y306 ffe fs7 fc0 sc0 ls0 ws0">i=1</div><div class="t m0 xa7 h16 y307 ffe fs7 fc0 sc0 ls0 ws0">L</div><div class="t m0 xa8 h15 y308 ffe fs3 fc0 sc0 ls0 ws0">||W</div><div class="t m0 x3c h16 y309 ffe fs7 fc0 sc0 ls0 ws0">(i)</div><div class="t m0 x4c h15 y308 ffe fs3 fc0 sc0 ls0 ws0">||</div><div class="t m0 x5f h16 ye7 ffe fs7 fc0 sc0 ls0 ws0">F</div><div class="t m0 x41 h24 y305 ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h15 y1da ff5 fs3 fc0 sc0 ls0 ws0">在上面的<span class="_ _2"></span>公式中<span class="_ _2"></span>，<span class="_ _4"> </span><span class="ffe">||</span></div><div class="t m0 x9d h15 y30a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x3a h16 y30b ffe fs7 fc0 sc0 ls0 ws0">(i)</div><div class="t m0 x8f h15 y1da ffe fs3 fc0 sc0 ls0 ws0">||</div><div class="t m0 xa1 h16 y30c ffe fs7 fc0 sc0 ls0 ws0">F</div><div class="t m0 xa2 h6 y1da ff5 fs3 fc0 sc0 ls0 ws0">是矩阵</div><div class="t m0 x20 h15 y30a ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x1c h16 y30b ffe fs7 fc0 sc0 ls0 ws0">(i)</div><div class="t m0 x44 h15 y1da ff5 fs3 fc0 sc0 ls0 ws0">（在神经<span class="_ _2"></span>网络中<span class="_ _2"></span>的第<span class="_ _4"> </span><span class="ffe">i<span class="_ _4"></span></span>个</div><div class="t m0 x0 h6 y1de ff5 fs3 fc0 sc0 ls0 ws0">权<span class="_ _2"></span>值<span class="_ _6"></span>矩<span class="_ _2"></span>阵<span class="_ _6"></span>）<span class="_ _6"></span>的</div><div class="t m0 x93 h15 y30d ffe fs3 fc0 sc0 ls0 ws0">Frobenius</div><div class="t m0 xa4 h5 y1de ff5 fs3 fc0 sc0 ls0 ws0">范<span class="_ _2"></span>数<span class="_ _6"></span><span class="ff4">,</span></div><div class="t m0 x3d h15 y30d ffe fs3 fc0 sc0 ls0 ws0">λ</div><div class="t m0 x90 h6 y1de ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>超<span class="_ _6"></span>参<span class="_ _2"></span>数<span class="_ _6"></span>控<span class="_ _6"></span>制<span class="_ _2"></span>损<span class="_ _6"></span>失<span class="_ _2"></span>函<span class="_ _6"></span>数<span class="_ _6"></span>中<span class="_ _2"></span>的<span class="_ _6"></span>权</div><div class="t m0 x0 h6 y30e ff5 fs3 fc0 sc0 ls0 ws0">值的大小。</div><div class="t m0 x3a h20 y30f ffe fs1 fc0 sc0 ls0 ws0">||U||</div><div class="t m0 xbe h21 y310 ffe fsa fc0 sc0 ls0 ws0">F</div><div class="t m0 x75 h20 y30f ffe fs1 fc0 sc0 ls0 ws0">=</div><div class="t m0 x32 h21 y311 ffe fsa fc0 sc0 ls0 ws0">i</div><div class="t m0 x42 h21 y312 ffe fsa fc0 sc0 ls0 ws0">l</div><div class="t m0 x44 h20 y313 ffe fs1 fc0 sc0 ls0 ws0">U</div><div class="t m0 x11 h21 y314 ffe fsa fc0 sc0 ls0 ws0">il</div><div class="t m0 x11 h21 y315 ffe fsa fc0 sc0 ls0 ws0">2</div><div class="t m0 x21 h2c y30f ffe fse fc0 sc0 ls0 ws0"><span class="_ _1c"></span></div></div><div class="c x23 y316 w6 h18"><div class="t m0 x7 h19 y317 ff7 fs0 fc0 sc0 ls0 ws0">Notes<span class="_ _4"> </span>in<span class="_ _2"></span>fo.</div></div><div class="c x23 y318 w7 h1a"><div class="t m0 x7 hb y319 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y318 w8 h1a"><div class="t m0 x7 hb y319 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>P50</div></div><div class="c x23 y31a w7 h1a"><div class="t m0 x7 hb y48 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y31a w8 h1a"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>61:30</div></div><div class="c x23 y31b w7 h1b"><div class="t m0 x7 hb y31c ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y31b w8 h1b"><div class="t m0 x7 h1c y31d ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y31e w7 h1a"><div class="t m0 x7 hb y48 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y31e w8 h1a"><div class="t m0 x7 h1c y48 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y31f w6 h1d"><div class="t m0 x25 hb y320 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA<span class="fs5">I</span></div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y321 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _8"> </span><span class="ffb fs1">矩阵</span></div><div class="t m0 x64 h20 y322 ffe fs1 fc0 sc0 ls0 ws0">U</div><div class="t m0 x97 h13 y321 ffb fs1 fc0 sc0 ls0 ws0">的</div><div class="t m0 xbf h20 y322 ffe fs1 fc0 sc0 ls0 ws0">Frobenius</div><div class="t m0 x4e h13 y321 ffb fs1 fc0 sc0 ls0 ws0">范数的定义</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfb" class="pf w0 h0" data-page-no="b"><div class="pc pcb w0 h0"><img class="bi x0 y0 w5 h1" alt="" src="bgb.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">当<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>尝<span class="_ _2"></span>试<span class="_ _6"></span>去<span class="_ _2"></span>最<span class="_ _2"></span>小<span class="_ _2"></span>化</div><div class="t m0 x3 h15 y112 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x3a h16 y323 ffe fs7 fc0 sc0 ls0 ws0">R</div><div class="t m0 x8f h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>正<span class="_ _2"></span>则<span class="_ _2"></span>化<span class="_ _2"></span>本<span class="_ _6"></span>质<span class="_ _2"></span>上<span class="_ _2"></span>就<span class="_ _2"></span>是<span class="_ _6"></span>当<span class="_ _2"></span>优<span class="_ _2"></span>化<span class="_ _2"></span>损<span class="_ _6"></span>失函<span class="_ _6"></span>数<span class="_ _2"></span>的</div><div class="t m0 x0 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">时候，惩罚数<span class="_ _2"></span>值太大的权值<span class="_ _2"></span>（让权值<span class="_ _2"></span>的数值分配更<span class="_ _2"></span>加均衡，防止</div><div class="t m0 x0 h6 y324 ff5 fs3 fc0 sc0 ls0 ws0">出现部<span class="_ _2"></span>分权<span class="_ _2"></span>值<span class="_ _2"></span>特别大<span class="_ _2"></span>的情<span class="_ _2"></span>况）。<span class="_ _2"></span>由于</div><div class="t m0 x5d h15 y325 ffe fs3 fc0 sc0 ls0 ws0">Frobenius</div><div class="t m0 x2b h6 y324 ff5 fs3 fc0 sc0 ls0 ws0">范数的<span class="_ _2"></span>二次<span class="_ _2"></span>的<span class="_ _2"></span>性</div><div class="t m0 x0 h6 y5 ff5 fs3 fc0 sc0 ls0 ws0">质（<span class="_ _2"></span>计<span class="_ _2"></span>算<span class="_ _2"></span>矩阵<span class="_ _2"></span>的<span class="_ _2"></span>元<span class="_ _2"></span>素<span class="_ _2"></span>的平<span class="_ _2"></span>方<span class="_ _2"></span>和<span class="_ _2"></span>），</div><div class="t m0 x43 h15 y326 ffe fs3 fc0 sc0 ls0 ws0">L2</div><div class="t m0 x42 h6 y5 ff5 fs3 fc0 sc0 ls0 ws0">正则<span class="_ _2"></span>项<span class="_ _2"></span>有<span class="_ _2"></span>效地<span class="_ _2"></span>降<span class="_ _2"></span>低<span class="_ _2"></span>了<span class="_ _2"></span>模型</div><div class="t m0 x0 h6 y327 ff5 fs3 fc0 sc0 ls0 ws0">的灵活性和因<span class="_ _2"></span>此减少出现过<span class="_ _2"></span>拟合的可<span class="_ _2"></span>能性。增加这<span class="_ _2"></span>样一个约束可</div><div class="t m0 x0 h6 y328 ff5 fs3 fc0 sc0 ls0 ws0">以使用贝叶斯<span class="_ _2"></span>派的思想解释<span class="_ _2"></span>，这个正<span class="_ _2"></span>则项是对模型<span class="_ _2"></span>的参数加上一</div><div class="t m0 x0 h15 y329 ff5 fs3 fc0 sc0 ls0 ws0">个先验<span class="_ _2"></span>分布<span class="_ _2"></span>，优化<span class="_ _2"></span>权值<span class="_ _2"></span>使其<span class="_ _2"></span>接近于<span class="_ _15"> </span><span class="ff4">0——</span>有<span class="_ _2"></span>多接<span class="_ _2"></span>近是<span class="_ _2"></span>取决于<span class="_ _4"> </span><span class="ffe">λ<span class="_ _4"></span></span>的</div><div class="t m0 x0 h15 y32a ff5 fs3 fc0 sc0 ls0 ws0">值。选择一<span class="_ _2"></span>个合适的<span class="_ _4"> </span><span class="ffe">λ<span class="_ _4"></span></span>值是很重要<span class="_ _2"></span>的，并且<span class="_ _2"></span>需要通过超<span class="_ _2"></span>参数调整</div><div class="t m0 x0 h6 y32b ff5 fs3 fc0 sc0 ls0 ws0">来<span class="_ _2"></span>选<span class="_ _2"></span>择<span class="_ _6"></span>。</div><div class="t m0 x30 h15 y206 ffe fs3 fc0 sc0 ls0 ws0">λ</div><div class="t m0 x6e h5 y32b ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>值<span class="_ _2"></span>太<span class="_ _6"></span>大<span class="_ _2"></span>会<span class="_ _6"></span>令<span class="_ _2"></span>很<span class="_ _6"></span>多<span class="_ _2"></span>权<span class="_ _2"></span>值<span class="_ _6"></span>都<span class="_ _6"></span>接<span class="_ _2"></span>近<span class="_ _2"></span>于<span class="_ _8"> </span><span class="ff4">0<span class="_ _4"> </span></span>，<span class="_ _6"></span>则<span class="_ _2"></span>模<span class="_ _6"></span>型<span class="_ _2"></span>就<span class="_ _2"></span>不<span class="_ _6"></span>能</div><div class="t m0 x0 h6 y209 ff5 fs3 fc0 sc0 ls0 ws0">在训练集上学<span class="_ _2"></span>习到有意义的<span class="_ _2"></span>东西，经<span class="_ _2"></span>常在训练、验<span class="_ _2"></span>证和测试集上</div><div class="t m0 x0 h15 y32c ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>表<span class="_ _6"></span>现<span class="_ _2"></span>都<span class="_ _6"></span>非<span class="_ _6"></span>常<span class="_ _2"></span>差<span class="_ _6"></span>。<span class="_ _8"> </span><span class="ffe">λ<span class="_ _7"></span></span>的<span class="_ _6"></span>值<span class="_ _2"></span>太<span class="_ _6"></span>小<span class="_ _6"></span>，<span class="_ _2"></span>会<span class="_ _6"></span>让<span class="_ _6"></span>模<span class="_ _2"></span>型<span class="_ _6"></span>仍<span class="_ _2"></span>旧<span class="_ _6"></span>出<span class="_ _6"></span>现<span class="_ _2"></span>过<span class="_ _6"></span>拟<span class="_ _2"></span>合<span class="_ _6"></span>的<span class="_ _6"></span>现</div><div class="t m0 x0 h6 y32d ff5 fs3 fc0 sc0 ls0 ws0">象<span class="_ _2"></span>。<span class="_ _6"></span>需<span class="_ _6"></span>要<span class="_ _2"></span>注<span class="_ _6"></span>意<span class="_ _6"></span>的<span class="_ _6"></span>是<span class="_ _2"></span>，<span class="_ _6"></span>偏<span class="_ _6"></span>置<span class="_ _6"></span>项<span class="_ _2"></span>不<span class="_ _6"></span>会<span class="_ _6"></span>被<span class="_ _2"></span>正<span class="_ _6"></span>则<span class="_ _6"></span>化<span class="_ _6"></span>，<span class="_ _2"></span>不<span class="_ _6"></span>会<span class="_ _6"></span>计<span class="_ _2"></span>算<span class="_ _6"></span>入<span class="_ _6"></span>损<span class="_ _6"></span>失<span class="_ _2"></span>项</div><div class="t m0 x0 h5 y32e ff5 fs3 fc0 sc0 ls0 ws0">中<span class="ff4">——</span>尝试<span class="_ _2"></span>去思考一下为<span class="_ _2"></span>什么。</div><div class="t m0 x0 h6 y32f ff5 fs3 fc0 sc0 ls0 ws0">实际<span class="_ _2"></span>上<span class="_ _2"></span>，<span class="_ _2"></span>有时<span class="_ _2"></span>也<span class="_ _2"></span>会使<span class="_ _2"></span>用<span class="_ _2"></span>其他<span class="_ _2"></span>类<span class="_ _2"></span>型<span class="_ _2"></span>的正<span class="_ _2"></span>则<span class="_ _2"></span>化<span class="_ _2"></span>，例<span class="_ _2"></span>如</div><div class="t m0 x68 h15 y330 ffe fs3 fc0 sc0 ls0 ws0">L1</div><div class="t m0 x60 h6 y32f ff5 fs3 fc0 sc0 ls0 ws0">正则<span class="_ _2"></span>化<span class="_ _2"></span>，<span class="_ _2"></span>它</div><div class="t m0 x0 h6 y331 ff5 fs3 fc0 sc0 ls0 ws0">对参数元素的<span class="_ _2"></span>绝对值（而不<span class="_ _2"></span>是平方）<span class="_ _2"></span>求和。然而<span class="_ _2"></span>，这在实<span class="_ _2"></span>践中不</div><div class="t m0 x0 h6 y332 ff5 fs3 fc0 sc0 ls0 ws0">太常用，因为<span class="_ _2"></span>它会导致参数<span class="_ _2"></span>权重稀疏<span class="_ _2"></span>。在下一节中<span class="_ _2"></span>，我们将讨<span class="_ _2"></span>论</div><div class="t m0 x0 h5 y333 ff4 fs3 fc0 sc0 ls0 ws0">dropout<span class="_ _2"></span><span class="ff5">，它<span class="_ _2"></span>有效<span class="_ _2"></span>地<span class="_ _2"></span>作为<span class="_ _2"></span>另一<span class="_ _2"></span>种<span class="_ _2"></span>正则<span class="_ _2"></span>化形<span class="_ _2"></span>式<span class="_ _2"></span>，通<span class="_ _2"></span>过在<span class="_ _2"></span>前<span class="_ _2"></span>向传<span class="_ _2"></span>递中</span></div><div class="t m0 x0 h6 y334 ff5 fs3 fc0 sc0 ls0 ws0">随机丢弃（即<span class="_ _2"></span>设置为零）神<span class="_ _2"></span>经元。</div><div class="t m0 x0 h2d y335 ffd fs3 fc0 sc0 ls0 ws0">下面摘录已有<span class="_ _2"></span>的三条回答</div><div class="t m0 x0 h6 y336 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">首先正则化主<span class="_ _2"></span>要是为了防止<span class="_ _2"></span>过拟合，<span class="_ _2"></span>而过拟合一般<span class="_ _2"></span>表现为模</span></div><div class="t m0 x2 h6 y337 ff5 fs3 fc0 sc0 ls0 ws0">型对于输入的<span class="_ _2"></span>微小改变产生<span class="_ _2"></span>了输出的<span class="_ _2"></span>较大差异，这<span class="_ _2"></span>主要是由</div><div class="t m0 x2 h15 y338 ff5 fs3 fc0 sc0 ls0 ws0">于<span class="_ _2"></span>有<span class="_ _2"></span>些<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _5"> </span><span class="ff4">w<span class="_ _5"> </span></span>过<span class="_ _2"></span>大<span class="_ _2"></span>的<span class="_ _2"></span>关<span class="_ _6"></span>系，<span class="_ _6"></span>通<span class="_ _2"></span>过<span class="_ _2"></span>对<span class="_ _7"> </span><span class="ffe">||W||<span class="_ _7"></span></span>进<span class="_ _2"></span>行<span class="_ _2"></span>惩<span class="_ _2"></span>罚<span class="_ _6"></span>，<span class="_ _2"></span>可<span class="_ _2"></span>以</div><div class="t m0 x2 h5 y12e ff5 fs3 fc0 sc0 ls0 ws0">缓<span class="_ _12"></span>解<span class="_ _6"></span>这<span class="_ _12"></span>种<span class="_ _12"></span>问<span class="_ _12"></span>题<span class="_ _12"></span>。<span class="_ _12"></span>而<span class="_ _12"></span>如<span class="_ _6"></span>果<span class="_ _17"></span>对<span class="_ _6"></span><span class="ff4">||b||<span class="_ _12"></span></span>进<span class="_ _12"></span>行<span class="_ _6"></span>惩<span class="_ _12"></span>罚<span class="_ _12"></span>，<span class="_ _12"></span>其<span class="_ _12"></span>实<span class="_ _12"></span>是<span class="_ _12"></span>没<span class="_ _12"></span>有<span class="_ _12"></span>作<span class="_ _12"></span>用</div><div class="t m0 x2 h5 y339 ff5 fs3 fc0 sc0 ls0 ws0">的，<span class="_ _2"></span>因<span class="_ _2"></span>为<span class="_ _2"></span>在<span class="_ _2"></span>对<span class="_ _2"></span>输<span class="_ _2"></span>出<span class="_ _2"></span>结果<span class="_ _2"></span>的<span class="_ _2"></span>贡<span class="_ _2"></span>献<span class="_ _2"></span>中，<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _5"> </span><span class="ff4">b </span>对<span class="_ _2"></span>于<span class="_ _2"></span>输<span class="_ _2"></span>入<span class="_ _2"></span>的<span class="_ _2"></span>改<span class="_ _2"></span>变</div><div class="t m0 x2 h5 y33a ff5 fs3 fc0 sc0 ls0 ws0">是不<span class="_ _2"></span>敏<span class="_ _2"></span>感<span class="_ _2"></span>的<span class="_ _2"></span>，<span class="_ _2"></span>不<span class="_ _2"></span>管<span class="_ _2"></span>输入<span class="_ _2"></span>改<span class="_ _2"></span>变<span class="_ _2"></span>是<span class="_ _2"></span>大还<span class="_ _2"></span>是<span class="_ _2"></span>小<span class="_ _2"></span>，<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _5"> </span><span class="ff4">b </span>的<span class="_ _2"></span>贡<span class="_ _2"></span>献<span class="_ _2"></span>就</div><div class="t m0 x2 h6 y33b ff5 fs3 fc0 sc0 ls0 ws0">只是加个偏置<span class="_ _2"></span>而已。</div><div class="t m0 x2 h5 y3c ff5 fs3 fc0 sc0 ls0 ws0">举个例<span class="_ _2"></span>子，<span class="_ _2"></span>如<span class="_ _2"></span>果你在<span class="_ _2"></span>训练<span class="_ _2"></span>集中，<span class="_ _2"></span><span class="ff4">w </span>和<span class="_ _5"> </span><span class="ff4">b </span>都表现<span class="_ _2"></span>得很<span class="_ _2"></span>好<span class="_ _2"></span>，但</div><div class="t m0 x2 h5 y33c ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _2"></span>在<span class="_ _6"></span>测<span class="_ _2"></span>试<span class="_ _6"></span>集<span class="_ _6"></span>上<span class="_ _6"></span>发<span class="_ _2"></span>生<span class="_ _6"></span>了<span class="_ _6"></span>过<span class="_ _2"></span>拟<span class="_ _6"></span>合<span class="_ _6"></span>，<span class="_ _2"></span><span class="ff4">b<span class="_ _5"> </span></span>是<span class="_ _6"></span>不<span class="_ _6"></span>背<span class="_ _2"></span>这<span class="_ _6"></span>个<span class="_ _6"></span>锅<span class="_ _6"></span>的<span class="_ _2"></span>，<span class="_ _6"></span>因<span class="_ _6"></span>为<span class="_ _2"></span>它</div><div class="t m0 x2 h6 y33d ff5 fs3 fc0 sc0 ls0 ws0">对<span class="_ _12"></span>于<span class="_ _17"></span>所<span class="_ _6"></span>有<span class="_ _17"></span>的<span class="_ _12"></span>数<span class="_ _17"></span>据<span class="_ _6"></span>都<span class="_ _17"></span>是<span class="_ _12"></span>一<span class="_ _12"></span>视<span class="_ _17"></span>同<span class="_ _6"></span>仁<span class="_ _17"></span>的<span class="_ _12"></span>（<span class="_ _17"></span>都<span class="_ _6"></span>只<span class="_ _17"></span>是<span class="_ _12"></span>给<span class="_ _12"></span>它<span class="_ _17"></span>们<span class="_ _6"></span>加<span class="_ _17"></span>个<span class="_ _12"></span>偏</div><div class="t m0 x2 h5 y33e ff5 fs3 fc0 sc0 ls0 ws0">置<span class="_ _2"></span>）<span class="_ _6"></span>，<span class="_ _2"></span>要<span class="_ _2"></span>背<span class="_ _6"></span>锅<span class="_ _2"></span>的<span class="_ _6"></span>是<span class="_ _5"> </span><span class="ff4">w<span class="_ _2"></span></span>，<span class="_ _2"></span>因<span class="_ _6"></span>为<span class="_ _6"></span>它<span class="_ _2"></span>会<span class="_ _2"></span>对<span class="_ _6"></span>不<span class="_ _2"></span>同<span class="_ _6"></span>的<span class="_ _2"></span>数<span class="_ _6"></span>据<span class="_ _2"></span>产<span class="_ _6"></span>生<span class="_ _2"></span>不<span class="_ _6"></span>一<span class="_ _2"></span>样</div><div class="t m0 x2 h6 y33f ff5 fs3 fc0 sc0 ls0 ws0">的加权。或者<span class="_ _2"></span>说，模型对于<span class="_ _2"></span>输入的微<span class="_ _2"></span>小改变产生了<span class="_ _2"></span>输出的较</div><div class="t m0 x2 h5 y340 ff5 fs3 fc0 sc0 ls0 ws0">大<span class="_ _2"></span>差<span class="_ _2"></span>异<span class="_ _6"></span>，<span class="_ _2"></span>这<span class="_ _2"></span>是<span class="_ _6"></span>因<span class="_ _2"></span>为<span class="_ _2"></span>模<span class="_ _6"></span>型的<span class="_ _6"></span><span class="ff4">“<span class="_ _2"></span></span>曲<span class="_ _6"></span>率<span class="ff4">”<span class="_ _6"></span></span>太<span class="_ _2"></span>大<span class="_ _6"></span>，<span class="_ _2"></span>而<span class="_ _2"></span>模<span class="_ _6"></span>型<span class="_ _2"></span>的<span class="_ _2"></span>曲<span class="_ _6"></span>率<span class="_ _2"></span>是<span class="_ _2"></span>由</div><div class="t m0 x2 h5 y341 ff4 fs3 fc0 sc0 ls0 ws0">w <span class="ff5">决<span class="_ _6"></span>定<span class="_ _2"></span>的<span class="_ _2"></span>，<span class="_ _2"></span></span>b<span class="_ _19"> </span><span class="ff5">不<span class="_ _6"></span>贡<span class="_ _2"></span>献<span class="_ _2"></span>曲<span class="_ _2"></span>率<span class="_ _2"></span>（<span class="_ _2"></span>对<span class="_ _2"></span>输<span class="_ _2"></span>入<span class="_ _6"></span>进<span class="_ _2"></span>行<span class="_ _2"></span>求<span class="_ _2"></span>导<span class="_ _2"></span>，<span class="_ _2"></span></span>b<span class="_ _5"> </span><span class="ff5">是<span class="_ _2"></span>直<span class="_ _2"></span>接<span class="_ _2"></span>约</span></div><div class="t m0 x2 h6 y342 ff5 fs3 fc0 sc0 ls0 ws0">掉的）。</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y343 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _10"> </span><span class="ffb fs1">为<span class="_ _11"> </span>何<span class="_ _11"> </span>在<span class="_ _11"> </span>损<span class="_ _11"> </span>失<span class="_ _11"> </span>项<span class="_ _17"> </span>中<span class="_ _11"> </span>不<span class="_ _11"> </span>计<span class="_ _11"> </span>算<span class="_ _11"> </span>偏<span class="_ _11"> </span>置</span></div><div class="t m0 x28 h13 y344 ffb fs1 fc0 sc0 ls0 ws0">项？</div><div class="t m0 x28 h13 y345 ffb fs1 fc0 sc0 ls0 ws0">偏<span class="_ _17"> </span>置<span class="_ _17"> </span>项<span class="_ _11"> </span>在<span class="_ _17"> </span>模<span class="_ _17"> </span>型<span class="_ _17"> </span>中<span class="_ _11"> </span>仅<span class="_ _17"> </span>仅<span class="_ _17"> </span>是<span class="_ _11"> </span>偏<span class="_ _17"> </span>移<span class="_ _17"> </span>的<span class="_ _17"> </span>关</div><div class="t m0 x28 h13 y346 ffb fs1 fc0 sc0 ls0 ws0">系<span class="_ _6"></span>，<span class="_ _6"></span>使<span class="_ _6"></span>用<span class="_ _6"></span>少<span class="_ _12"></span>量<span class="_ _6"></span>的<span class="_ _6"></span>数<span class="_ _6"></span>据<span class="_ _6"></span>就<span class="_ _12"></span>能<span class="_ _6"></span>拟<span class="_ _6"></span>合<span class="_ _6"></span>到<span class="_ _6"></span>这</div><div class="t m0 x28 h13 y347 ffb fs1 fc0 sc0 ls0 ws0">项<span class="_ _6"></span>，<span class="_ _6"></span>而<span class="_ _6"></span>且<span class="_ _6"></span>从<span class="_ _12"></span>经<span class="_ _6"></span>验<span class="_ _6"></span>上<span class="_ _6"></span>来<span class="_ _6"></span>说<span class="_ _12"></span>，<span class="_ _6"></span>偏<span class="_ _6"></span>置<span class="_ _6"></span>值<span class="_ _6"></span>的</div><div class="t m0 x28 h13 y348 ffb fs1 fc0 sc0 ls0 ws0">大<span class="_ _17"> </span>小<span class="_ _17"> </span>对<span class="_ _11"> </span>模<span class="_ _17"> </span>型<span class="_ _17"> </span>表<span class="_ _17"> </span>现<span class="_ _11"> </span>没<span class="_ _17"> </span>有<span class="_ _17"> </span>很<span class="_ _11"> </span>显<span class="_ _17"> </span>著<span class="_ _17"> </span>的<span class="_ _17"> </span>影</div><div class="t m0 x28 h13 y349 ffb fs1 fc0 sc0 ls0 ws0">响，因此不<span class="_ _2"></span>需要正则化偏<span class="_ _2"></span>置项。</div><div class="t m0 x28 h12 y34a ffc fs1 fc0 sc0 ls0 ws0">[<span class="_ _2"></span><span class="ffb">深<span class="_ _2"></span>度<span class="_ _2"></span>学<span class="_ _6"></span>习<span class="_ _2"></span>里<span class="_ _2"></span>面<span class="_ _2"></span>的<span class="_ _6"></span>偏<span class="_ _2"></span>置<span class="_ _2"></span>为<span class="_ _2"></span>什<span class="_ _6"></span>么<span class="_ _2"></span>不<span class="_ _6"></span>加<span class="_ _2"></span>正</span></div><div class="t m0 x28 h12 y34b ffb fs1 fc0 sc0 ls0 ws0">则？<span class="ffc">]</span></div><div class="t m0 x28 h12 y334 ffc fs1 fc0 sc0 ls0 ws0">(https:<span class="_ _2"></span>//www.zhihu.c<span class="_ _2"></span>om/ques<span class="_ _2"></span>tion/6</div><div class="t m0 x28 h12 y34c ffc fs1 fc0 sc0 ls0 ws0">68940<span class="_ _2"></span>61)</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfc" class="pf w0 h0" data-page-no="c"><div class="pc pcc w0 h0"><img class="bi x0 y0 w5 hd" alt="" src="bgc.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h23 y34d ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h6 yba ff5 fs3 fc0 sc0 ls0 ws0">从<span class="_ _2"></span>贝<span class="_ _6"></span>叶<span class="_ _6"></span>斯<span class="_ _6"></span>的<span class="_ _6"></span>角<span class="_ _6"></span>度<span class="_ _2"></span>来<span class="_ _6"></span>讲<span class="_ _6"></span>，<span class="_ _6"></span>正<span class="_ _6"></span>则<span class="_ _6"></span>化<span class="_ _6"></span>项<span class="_ _2"></span>通<span class="_ _6"></span>常<span class="_ _6"></span>都<span class="_ _6"></span>包<span class="_ _6"></span>含<span class="_ _6"></span>一<span class="_ _6"></span>定<span class="_ _2"></span>的<span class="_ _6"></span>先<span class="_ _6"></span>验<span class="_ _6"></span>信</div><div class="t m0 x2 h6 ybc ff5 fs3 fc0 sc0 ls0 ws0">息，神经网络<span class="_ _2"></span>倾向于较小的<span class="_ _2"></span>权重以便<span class="_ _2"></span>更好地泛化，<span class="_ _2"></span>但是对偏</div><div class="t m0 x2 h6 ybd ff5 fs3 fc0 sc0 ls0 ws0">置就没有这样<span class="_ _2"></span>一致的先验知<span class="_ _2"></span>识。另外<span class="_ _2"></span>，很多神经网<span class="_ _2"></span>络更倾向</div><div class="t m0 x2 h6 ybf ff5 fs3 fc0 sc0 ls0 ws0">于区分方向信<span class="_ _2"></span>息（对应于权<span class="_ _2"></span>重），而<span class="_ _2"></span>不是位置信息<span class="_ _2"></span>（对应于</div><div class="t m0 x2 h6 yc0 ff5 fs3 fc0 sc0 ls0 ws0">偏置），所以<span class="_ _2"></span>对偏置加正则<span class="_ _2"></span>化项对控<span class="_ _2"></span>制过拟合的作<span class="_ _2"></span>用是有限</div><div class="t m0 x2 h6 yc1 ff5 fs3 fc0 sc0 ls0 ws0">的，相反很可<span class="_ _2"></span>能会因为不恰<span class="_ _2"></span>当的正则<span class="_ _2"></span>强度影响神经<span class="_ _2"></span>网络找到</div><div class="t m0 x2 h6 yc2 ff5 fs3 fc0 sc0 ls0 ws0">最优点。</div><div class="t m0 x0 h6 y34e ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">过拟合会使得<span class="_ _2"></span>模型对异常点<span class="_ _2"></span>很敏感，<span class="_ _2"></span>即准确插入异<span class="_ _2"></span>常点，导</span></div><div class="t m0 x2 h6 y34f ff5 fs3 fc0 sc0 ls0 ws0">致<span class="_ _12"></span>拟<span class="_ _17"></span>合<span class="_ _6"></span>函<span class="_ _17"></span>数<span class="_ _12"></span>中<span class="_ _17"></span>的<span class="_ _6"></span>曲<span class="_ _17"></span>率<span class="_ _12"></span>很<span class="_ _12"></span>大<span class="_ _17"></span>（<span class="_ _6"></span>即<span class="_ _17"></span>函<span class="_ _12"></span>数<span class="_ _17"></span>曲<span class="_ _6"></span>线<span class="_ _17"></span>的<span class="_ _12"></span>切<span class="_ _12"></span>线<span class="_ _17"></span>斜<span class="_ _6"></span>率<span class="_ _17"></span>非<span class="_ _12"></span>常</div><div class="t m0 x2 h6 y350 ff5 fs3 fc0 sc0 ls0 ws0">高），而偏置<span class="_ _2"></span>对模型的曲率<span class="_ _2"></span>没有贡献<span class="_ _2"></span>（对多项式模<span class="_ _2"></span>型进行求</div><div class="t m0 x2 h5 y351 ff5 fs3 fc0 sc0 ls0 ws0">导<span class="_ _6"></span>，<span class="_ _6"></span>为<span class="_ _5"> </span><span class="ff4">W<span class="_ _16"> </span></span>的<span class="_ _6"></span>线<span class="_ _6"></span>性<span class="_ _6"></span>加<span class="_ _6"></span>和<span class="_ _6"></span>）<span class="_ _6"></span>，<span class="_ _6"></span>所<span class="_ _6"></span>以<span class="_ _12"></span>正<span class="_ _6"></span>则<span class="_ _2"></span>化<span class="_ _12"></span>他<span class="_ _6"></span>们<span class="_ _6"></span>也<span class="_ _6"></span>没<span class="_ _6"></span>有<span class="_ _6"></span>什<span class="_ _12"></span>么<span class="_ _2"></span>意</div><div class="t m0 x2 h6 y352 ff5 fs3 fc0 sc0 ls0 ws0">义。</div><div class="t m0 x0 h6 y353 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">有时<span class="_ _2"></span>候<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>会用<span class="_ _2"></span>到<span class="_ _2"></span>其<span class="_ _2"></span>他<span class="_ _2"></span>类<span class="_ _2"></span>型<span class="_ _2"></span>的<span class="_ _2"></span>正则<span class="_ _2"></span>项<span class="_ _2"></span>，<span class="_ _2"></span>例如</span></div><div class="t m0 x76 h15 y354 ffe fs3 fc0 sc0 ls0 ws0">L1</div><div class="t m0 x60 h6 y353 ff5 fs3 fc0 sc0 ls0 ws0">正则<span class="_ _2"></span>项<span class="_ _2"></span>，<span class="_ _2"></span>它</div><div class="t m0 x2 h5 y1a7 ff5 fs3 fc0 sc0 ls0 ws0">将参数<span class="_ _2"></span>元<span class="_ _2"></span>素的<span class="_ _2"></span>绝对值<span class="_ _2"></span>全部<span class="_ _2"></span>加起<span class="_ _2"></span>来<span class="ff4">-<span class="_ _2"></span></span>然而<span class="_ _2"></span>，在<span class="_ _2"></span>实际<span class="_ _2"></span>中很<span class="_ _2"></span>少会用</div><div class="t m0 x2 h15 y355 ffe fs3 fc0 sc0 ls0 ws0">L1</div><div class="t m0 x80 h6 y356 ff5 fs3 fc0 sc0 ls0 ws0">正<span class="_ _2"></span>则<span class="_ _2"></span>项<span class="_ _2"></span>，<span class="_ _2"></span>因<span class="_ _6"></span>为<span class="_ _2"></span>会<span class="_ _2"></span>令<span class="_ _6"></span>权<span class="_ _2"></span>值<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _6"></span>变<span class="_ _2"></span>得<span class="_ _2"></span>稀<span class="_ _2"></span>疏<span class="_ _6"></span>。<span class="_ _2"></span>在<span class="_ _2"></span>下<span class="_ _6"></span>一<span class="_ _2"></span>部<span class="_ _2"></span>分<span class="_ _2"></span>，<span class="_ _2"></span>我</div><div class="t m0 x2 h5 y357 ff5 fs3 fc0 sc0 ls0 ws0">们<span class="_ _2"></span>讨<span class="_ _2"></span>论<span class="_ _7"> </span><span class="ff4">dr<span class="_ _2"></span>o<span class="_ _2"></span>p<span class="_ _6"></span>o<span class="_ _2"></span>u<span class="_ _2"></span>t<span class="_ _8"> </span></span>，<span class="_ _2"></span>这<span class="_ _2"></span>是<span class="_ _2"></span>另<span class="_ _2"></span>外<span class="_ _6"></span>一<span class="_ _2"></span>种<span class="_ _2"></span>有<span class="_ _2"></span>效<span class="_ _2"></span>的<span class="_ _6"></span>正<span class="_ _2"></span>则<span class="_ _2"></span>化<span class="_ _2"></span>方<span class="_ _6"></span>法<span class="_ _2"></span>，<span class="_ _2"></span>通<span class="_ _2"></span>过</div><div class="t m0 x2 h5 y358 ff5 fs3 fc0 sc0 ls0 ws0">在前向传播过<span class="_ _2"></span>程随机将神经<span class="_ _2"></span>元设为<span class="_ _4"> </span><span class="ff4">0</span></div><div class="t m0 x0 h5 y2e1 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff4">Dr<span class="_ _2"></span>o<span class="_ _6"></span>p<span class="_ _2"></span>o<span class="_ _6"></span>u<span class="_ _2"></span>t<span class="_ _8"> </span><span class="ff5">实<span class="_ _2"></span>际<span class="_ _2"></span>上<span class="_ _6"></span>是<span class="_ _2"></span>通<span class="_ _2"></span>过<span class="_ _6"></span>在<span class="_ _6"></span>每<span class="_ _2"></span>次<span class="_ _2"></span>迭<span class="_ _6"></span>代<span class="_ _2"></span>中<span class="_ _6"></span>忽<span class="_ _2"></span>略<span class="_ _2"></span>它<span class="_ _6"></span>们<span class="_ _2"></span>的<span class="_ _6"></span>权<span class="_ _2"></span>值<span class="_ _2"></span>来<span class="_ _6"></span>实</span></span></div><div class="t m0 x2 h5 yf ff5 fs3 fc0 sc0 ls0 ws0">现<span class="ff4">“</span>冻<span class="_ _2"></span>结<span class="ff4">”</span>部分<span class="_ _4"> </span><span class="ff4">un<span class="_ _2"></span>it<span class="_ _4"> </span></span>。<span class="_ _2"></span>这些<span class="ff4">“<span class="_ _2"></span></span>冻结<span class="ff4">”</span>的<span class="_ _15"> </span><span class="ff4">uni<span class="_ _2"></span>t<span class="_ _4"> </span></span>不是<span class="_ _2"></span>把它们设<span class="_ _2"></span>为<span class="_ _4"> </span><span class="ff4">0</span></div><div class="t m0 xc0 h5 y359 ff5 fs3 fc0 sc0 ls0 ws0">，而是<span class="_ _2"></span>对于<span class="_ _2"></span>该迭代，<span class="_ _2"></span>网络<span class="_ _2"></span>假定<span class="_ _2"></span>它们为<span class="_ _4"> </span><span class="ff4">0<span class="_ _15"> </span></span>。<span class="ff4">“</span>冻<span class="_ _2"></span>结<span class="ff4">”</span>的<span class="_ _4"> </span><span class="ff4">uni<span class="_ _2"></span>t<span class="_ _4"> </span></span>不</div><div class="t m0 x2 h6 y35a ff5 fs3 fc0 sc0 ls0 ws0">会为此次迭代<span class="_ _2"></span>更新。</div><div class="t m0 x0 h14 y35b ffd fs0 fc0 sc0 ls0 ws0">2.3<span class="_ _15"> </span>Dropout</div><div class="t m0 x0 h5 y35c ffd fs3 fc0 sc0 ls0 ws0">Dropout<span class="_ _4"> </span><span class="ff5">是<span class="_ _2"></span>一个<span class="_ _2"></span>非常<span class="_ _2"></span>强大<span class="_ _2"></span>的<span class="_ _2"></span>正则化<span class="_ _2"></span>技术<span class="_ _2"></span>，<span class="_ _2"></span>是<span class="_ _4"> </span><span class="ff4">Srivas<span class="_ _2"></span>tava<span class="_ _4"> </span></span>在论<span class="_ _2"></span>文</span></div><div class="t m0 x0 h5 y35d ff5 fs3 fc0 sc0 ls0 ws0">《<span class="_ _6"></span><span class="ff4">Dropout:<span class="_ _7"> </span>A<span class="_ _7"> </span>Simple<span class="_ _7"> </span>Way<span class="_ _7"> </span>to<span class="_ _15"> </span>P<span class="_ _2"></span>revent<span class="_ _7"> </span>Neural<span class="_ _7"> </span>Netwo<span class="_ _2"></span>rks<span class="_ _15"> </span>fro<span class="_ _2"></span>m</span></div><div class="t m0 x0 h5 y35e ff4 fs3 fc0 sc0 ls0 ws0">Over<span class="ff14">ﬁ</span>tting<span class="_ _6"></span><span class="ff5">》<span class="_ _6"></span>中<span class="_ _6"></span>首<span class="_ _2"></span>次<span class="_ _6"></span>提<span class="_ _6"></span>出<span class="_ _6"></span>，<span class="_ _6"></span>右<span class="_ _6"></span>图<span class="_ _6"></span>展<span class="_ _2"></span>示<span class="_ _6"></span>了<span class="_ _8"> </span></span>dropou<span class="_ _2"></span>t<span class="_ _15"> </span><span class="ff5">如<span class="_ _6"></span>何<span class="_ _6"></span>应<span class="_ _6"></span>用<span class="_ _2"></span>在<span class="_ _12"></span>神</span></div><div class="t m0 x0 h6 y35f ff5 fs3 fc0 sc0 ls0 ws0">经网络上。</div><div class="t m0 x0 h5 y360 ff5 fs3 fc0 sc0 ls0 ws0">这个想法是简<span class="_ _2"></span>单而有效的<span class="_ _2"></span><span class="ff4">——</span>训练<span class="_ _2"></span>过程中，在每<span class="_ _2"></span>次的前向<span class="_ _2"></span><span class="fff">／</span>反向</div><div class="t m0 x0 h6 y361 ff5 fs3 fc0 sc0 ls0 ws0">传播<span class="_ _2"></span>中<span class="_ _2"></span>我<span class="_ _2"></span>们按<span class="_ _2"></span>照<span class="_ _2"></span>一<span class="_ _2"></span>定<span class="_ _2"></span>概率</div><div class="t m0 x48 h15 y362 ffe fs3 fc0 sc0 ls0 ws0">(1<span class="_ _3"></span>−<span class="_ _3"></span>)</div><div class="t m0 x39 h5 y361 ff5 fs3 fc0 sc0 ls0 ws0">随机<span class="_ _2"></span>地<span class="_ _2"></span><span class="ff4">“<span class="_ _4"> </span>d<span class="_ _2"></span>rop<span class="_ _4"> </span>”<span class="_ _2"></span></span>一<span class="_ _2"></span>些<span class="_ _2"></span>神经<span class="_ _2"></span>元<span class="_ _2"></span>子</div><div class="t m0 x0 h6 y363 ff5 fs3 fc0 sc0 ls0 ws0">集<span class="_ _2"></span>（<span class="_ _6"></span>或<span class="_ _2"></span>者<span class="_ _6"></span>等<span class="_ _2"></span>价<span class="_ _6"></span>的<span class="_ _2"></span>，<span class="_ _6"></span>我<span class="_ _2"></span>们<span class="_ _6"></span>保<span class="_ _2"></span>持<span class="_ _6"></span>一<span class="_ _6"></span>定<span class="_ _2"></span>概<span class="_ _6"></span>率</div><div class="t m0 x42 h15 y364 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x6b h6 y363 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>神<span class="_ _6"></span>经<span class="_ _2"></span>元<span class="_ _6"></span>是<span class="_ _2"></span>激<span class="_ _6"></span>活<span class="_ _2"></span>的<span class="_ _6"></span>）<span class="_ _2"></span>。</div><div class="t m0 x0 h6 y365 ff5 fs3 fc0 sc0 ls0 ws0">然后，在测试<span class="_ _2"></span>阶段，我们将<span class="_ _2"></span>使用全部<span class="_ _2"></span>的神经元来进<span class="_ _2"></span>行预测。使用</div><div class="t m0 x0 h5 y1dc ff4 fs3 fc0 sc0 ls0 ws0">Dropout<span class="_ _15"> </span><span class="ff5">神<span class="_ _6"></span>经<span class="_ _6"></span>网<span class="_ _2"></span>络<span class="_ _6"></span>一<span class="_ _6"></span>般<span class="_ _6"></span>能<span class="_ _2"></span>从<span class="_ _6"></span>数<span class="_ _6"></span>据<span class="_ _2"></span>中<span class="_ _6"></span>学<span class="_ _6"></span>到<span class="_ _6"></span>更<span class="_ _2"></span>多<span class="_ _6"></span>有<span class="_ _6"></span>意<span class="_ _2"></span>义<span class="_ _6"></span>的<span class="_ _2"></span>信<span class="_ _6"></span>息<span class="_ _6"></span>，<span class="_ _6"></span>更</span></div><div class="t m0 x0 h6 y366 ff5 fs3 fc0 sc0 ls0 ws0">少出现过拟合<span class="_ _2"></span>和通常在现今<span class="_ _2"></span>的任务上<span class="_ _2"></span>获得更高的整<span class="_ _2"></span>体表现。这种</div><div class="t m0 x0 h5 y367 ff5 fs3 fc0 sc0 ls0 ws0">技<span class="_ _2"></span>术<span class="_ _2"></span>应<span class="_ _6"></span>该<span class="_ _2"></span>如<span class="_ _6"></span>此<span class="_ _2"></span>有<span class="_ _6"></span>效<span class="_ _2"></span>的<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>直<span class="_ _2"></span>观<span class="_ _2"></span>原<span class="_ _6"></span>因<span class="_ _2"></span>是<span class="_ _6"></span>，<span class="_ _7"> </span><span class="ff4">dropou<span class="_ _2"></span>t<span class="_ _15"> </span></span>本<span class="_ _2"></span>质<span class="_ _2"></span>上<span class="_ _6"></span>作<span class="_ _6"></span>的<span class="_ _2"></span>是</div><div class="t m0 x0 h6 y368 ff5 fs3 fc0 sc0 ls0 ws0">一次以指数形<span class="_ _2"></span>式训练许多较<span class="_ _2"></span>小的网络<span class="_ _2"></span>，并对其预测<span class="_ _2"></span>进行平均。</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y369 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _0"> </span><span class="ff10 fs1">↑<span class="_ _6"></span><span class="ffc">D<span class="_ _2"></span>ropout<span class="_ _4"> </span>applied<span class="_ _4"> </span>to<span class="_ _3"> </span>an<span class="_ _4"> </span>artif<span class="_ _2"></span>icial</span></span></div><div class="t m0 x28 h12 y36 ffc fs1 fc0 sc0 ls0 ws0">neural<span class="_ _9"> </span>network.<span class="_ _9"> </span>Image<span class="_ _9"> </span>credits<span class="_ _9"> </span>to</div><div class="t m0 x28 h12 y36a ffc fs1 fc0 sc0 ls0 ws0">Srivastava<span class="_ _8"> </span>et<span class="_ _7"> </span>al.<span class="_ _17"></span><span class="ffb">【<span class="_ _17"> </span></span>Dropo<span class="_ _2"></span>ut<span class="_ _7"> </span><span class="ffb">应<span class="_ _17"> </span>用<span class="_ _17"> </span>于</span></div><div class="t m0 x28 h13 y36b ffb fs1 fc0 sc0 ls0 ws0">人<span class="_ _8"> </span>工<span class="_ _7"> </span>神<span class="_ _8"> </span>经<span class="_ _7"> </span>网<span class="_ _8"> </span>络<span class="_ _7"> </span>。<span class="_ _8"> </span>图<span class="_ _8"> </span>像<span class="_ _8"> </span>来<span class="_ _7"> </span>源<span class="_ _8"> </span>于</div><div class="t m0 x28 h12 y36c ffc fs1 fc0 sc0 ls0 ws0">Srivastava <span class="ffb">等人<span class="_ _2"></span>。】</span></div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfd" class="pf w0 h0" data-page-no="d"><div class="pc pcd w0 h0"><img class="bi x0 y0 w5 h1" alt="" src="bgd.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h5 y111 ff5 fs3 fc0 sc0 ls0 ws0">实<span class="_ _2"></span>际<span class="_ _2"></span>上<span class="_ _6"></span>，<span class="_ _2"></span>我<span class="_ _6"></span>们<span class="_ _2"></span>使<span class="_ _6"></span>用<span class="_ _7"> </span><span class="ff4">dropout<span class="_ _7"> </span></span>的<span class="_ _2"></span>方<span class="_ _6"></span>式<span class="_ _2"></span>是<span class="_ _6"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>取<span class="_ _6"></span>每<span class="_ _2"></span>个<span class="_ _6"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>层<span class="_ _6"></span>的<span class="_ _2"></span>输</div><div class="t m0 x0 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">出</div><div class="t m0 x13 h15 y36d ffe fs3 fc0 sc0 ls0 ws0">ℎ</div><div class="t m0 xc0 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>并<span class="_ _2"></span>保<span class="_ _6"></span>持<span class="_ _2"></span>概<span class="_ _6"></span>率</div><div class="t m0 x8e h15 y36d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>是<span class="_ _6"></span>激<span class="_ _2"></span>活<span class="_ _2"></span>的<span class="_ _6"></span>，<span class="_ _2"></span>否<span class="_ _2"></span>则<span class="_ _6"></span>将<span class="_ _2"></span>神<span class="_ _6"></span>经<span class="_ _2"></span>元<span class="_ _2"></span>设<span class="_ _6"></span>置<span class="_ _2"></span>为</div><div class="t m0 x0 h5 y324 ff4 fs3 fc0 sc0 ls0 ws0">0<span class="_ _4"> </span><span class="ff5">。然后，<span class="_ _2"></span>在反<span class="_ _2"></span>向传播<span class="_ _2"></span>中我们<span class="_ _2"></span>仅对<span class="_ _2"></span>在前向<span class="_ _2"></span>传播<span class="_ _2"></span>中激<span class="_ _2"></span>活的神经<span class="_ _2"></span>元回</span></div><div class="t m0 x0 h6 y5 ff5 fs3 fc0 sc0 ls0 ws0">传梯度。最后<span class="_ _2"></span>，在测试过程<span class="_ _2"></span>，我们使<span class="_ _2"></span>用神经网络中<span class="_ _2"></span>全部的神经元</div><div class="t m0 x0 h6 y327 ff5 fs3 fc0 sc0 ls0 ws0">进<span class="_ _12"></span>行<span class="_ _12"></span>前<span class="_ _12"></span>向<span class="_ _17"></span>传<span class="_ _6"></span>播<span class="_ _17"></span>计<span class="_ _6"></span>算<span class="_ _12"></span>。<span class="_ _12"></span>然<span class="_ _17"></span>而<span class="_ _6"></span>，<span class="_ _17"></span>有<span class="_ _6"></span>一<span class="_ _17"></span>个<span class="_ _6"></span>关<span class="_ _12"></span>键<span class="_ _17"></span>的<span class="_ _6"></span>微<span class="_ _12"></span>妙<span class="_ _17"></span>之<span class="_ _6"></span>处<span class="_ _17"></span>，<span class="_ _6"></span>为<span class="_ _17"></span>了<span class="_ _6"></span>使</div><div class="t m0 x0 h5 y328 ff4 fs3 fc0 sc0 ls0 ws0">dropout<span class="_ _7"> </span><span class="ff5">有<span class="_ _2"></span>效<span class="_ _12"></span>地<span class="_ _2"></span>工<span class="_ _6"></span>作<span class="_ _6"></span>，<span class="_ _6"></span>测<span class="_ _6"></span>试<span class="_ _6"></span>阶<span class="_ _6"></span>段<span class="_ _6"></span>的<span class="_ _6"></span>神<span class="_ _6"></span>经<span class="_ _6"></span>元<span class="_ _2"></span>的<span class="_ _12"></span>预<span class="_ _2"></span>期<span class="_ _6"></span>输<span class="_ _6"></span>出<span class="_ _6"></span>应<span class="_ _6"></span>与<span class="_ _6"></span>训<span class="_ _6"></span>练</span></div><div class="t m0 x0 h5 y329 ff5 fs3 fc0 sc0 ls0 ws0">阶段大致相同<span class="_ _2"></span><span class="ff4">——</span>否则输出<span class="_ _2"></span>的大小可<span class="_ _2"></span>能会有很大的<span class="_ _2"></span>不同，网<span class="_ _2"></span>络的</div><div class="t m0 x0 h6 y32a ff5 fs3 fc0 sc0 ls0 ws0">表现已经不再<span class="_ _2"></span>明确了。因此<span class="_ _2"></span>，我们通<span class="_ _2"></span>常必须在测试<span class="_ _2"></span>阶段将每个神</div><div class="t m0 x0 h5 y32b ff5 fs3 fc0 sc0 ls0 ws0">经元的输出除<span class="_ _2"></span>以某个值<span class="ff4">——<span class="_ _2"></span></span>这留给读<span class="_ _2"></span>者作为练习来<span class="_ _2"></span>确定这个<span class="_ _2"></span>值应</div><div class="t m0 x0 h6 y209 ff5 fs3 fc0 sc0 ls0 ws0">该<span class="_ _17"> </span>是<span class="_ _17"> </span>多<span class="_ _17"> </span>少<span class="_ _11"> </span>，<span class="_ _17"></span>以<span class="_ _17"> </span>便<span class="_ _17"> </span>在<span class="_ _17"> </span>训<span class="_ _17"> </span>练<span class="_ _11"> </span>和<span class="_ _17"> </span>测<span class="_ _17"> </span>试<span class="_ _17"> </span>期<span class="_ _17"> </span>间<span class="_ _11"> </span>的<span class="_ _17"></span>预<span class="_ _17"></span>期<span class="_ _17"> </span>输<span class="_ _17"> </span>出<span class="_ _11"> </span>相<span class="_ _17"></span>等<span class="_ _17"> </span>（<span class="_ _17"> </span>该<span class="_ _17"> </span>值</div><div class="t m0 x0 h15 y32c ff5 fs3 fc0 sc0 ls0 ws0">为<span class="_ _3"> </span><span class="ffe"><span class="_ _4"></span></span>）<span class="_ _4"> </span>。</div><div class="t m0 x0 h5 y36e ff5 fs3 fc0 sc0 ls0 ws0">以<span class="_ _17"> </span>下<span class="_ _17"> </span>源<span class="_ _17"> </span>于 《<span class="_ _17"> </span>神<span class="_ _11"> </span>经<span class="_ _17"> </span>网<span class="_ _17"> </span>络<span class="_ _17"> </span>与<span class="_ _17"> </span>深<span class="_ _17"> </span>度<span class="_ _11"> </span>学<span class="_ _17"></span>习<span class="_ _17"></span>》<span class="_ _17"> </span><span class="ff4">[https<span class="_ _2"></span>://nndl.github.io/<span class="_ _2"></span>]</span></div><div class="t m0 x0 h5 y36f ff4 fs3 fc0 sc0 ls0 ws0">P190</div><div class="t m0 x0 h6 y370 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">目的：缓解过<span class="_ _2"></span>拟合问题，一<span class="_ _2"></span>定程度上<span class="_ _2"></span>达到正则化的<span class="_ _2"></span>效果</span></div><div class="t m0 x0 h6 y371 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">效果：减少下<span class="_ _2"></span>层节点对其的<span class="_ _2"></span>依赖，迫<span class="_ _2"></span>使网络去学习<span class="_ _2"></span>更加鲁棒</span></div><div class="t m0 x2 h6 y372 ff5 fs3 fc0 sc0 ls0 ws0">的特征</div><div class="t m0 x0 h2d y373 ffd fs3 fc0 sc0 ls0 ws0">集成学习的解<span class="_ _2"></span>释</div><div class="t m0 x0 h23 y374 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h6 y375 ff5 fs3 fc0 sc0 ls0 ws0">每<span class="_ _2"></span>做<span class="_ _6"></span>一<span class="_ _6"></span>次<span class="_ _6"></span>丢<span class="_ _6"></span>弃<span class="_ _6"></span>，<span class="_ _2"></span>相<span class="_ _6"></span>当<span class="_ _6"></span>于<span class="_ _6"></span>从<span class="_ _6"></span>原<span class="_ _6"></span>始<span class="_ _6"></span>的<span class="_ _2"></span>网<span class="_ _6"></span>络<span class="_ _6"></span>中<span class="_ _6"></span>采<span class="_ _6"></span>样<span class="_ _6"></span>得<span class="_ _6"></span>到<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>子<span class="_ _6"></span>网</div><div class="t m0 x2 h6 y376 ff5 fs3 fc0 sc0 ls0 ws0">络。<span class="_ _4"> </span>如<span class="_ _2"></span>果<span class="_ _2"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>神经<span class="_ _2"></span>网<span class="_ _2"></span>络<span class="_ _2"></span>有</div><div class="t m0 x3d h15 y377 ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 x39 h6 y376 ff5 fs3 fc0 sc0 ls0 ws0">个神<span class="_ _2"></span>经<span class="_ _2"></span>元<span class="_ _2"></span>，<span class="_ _2"></span>那<span class="_ _2"></span>么<span class="_ _2"></span>总<span class="_ _2"></span>共可<span class="_ _2"></span>以<span class="_ _2"></span>采<span class="_ _2"></span>样</div><div class="t m0 x2 h6 y378 ff5 fs3 fc0 sc0 ls0 ws0">出</div><div class="t m0 x79 h15 y379 ffe fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x97 h16 y37a ffe fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x50 h6 y378 ff5 fs3 fc0 sc0 ls0 ws0">个子网络。<span class="_ _2"></span>每次迭代都相<span class="_ _2"></span>当于训<span class="_ _2"></span>练一个不同的<span class="_ _2"></span>子网络<span class="_ _2"></span>，</div><div class="t m0 x2 h6 y37b ff5 fs3 fc0 sc0 ls0 ws0">这些子网络都<span class="_ _2"></span>共享原始网络<span class="_ _2"></span>的参数。<span class="_ _2"></span>那么，最终的<span class="_ _2"></span>网络可以</div><div class="t m0 x2 h6 yd8 ff5 fs3 fc0 sc0 ls0 ws0">近似看作是集<span class="_ _2"></span>成了指数级个<span class="_ _2"></span>不同网络<span class="_ _2"></span>的组合模型。</div><div class="t m0 x0 h2d y37c ffd fs3 fc0 sc0 ls0 ws0">贝叶斯学习的<span class="_ _2"></span>解释</div><div class="t m0 x0 h6 y298 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">丢弃法<span class="_ _2"></span>也<span class="_ _2"></span>可以<span class="_ _2"></span>解释为<span class="_ _2"></span>一<span class="_ _2"></span>种贝叶<span class="_ _2"></span>斯学<span class="_ _2"></span>习的<span class="_ _2"></span>近似<span class="_ _2"></span>。用</span></div><div class="t m0 x7b h15 y297 ffe fs3 fc0 sc0 ls0 ws0">y<span class="_ _4"></span>=<span class="_ _15"></span>f(<span class="_ _2"></span>x,<span class="_ _11"></span>θ)</div><div class="t m0 x2 h6 y29a ff5 fs3 fc0 sc0 ls0 ws0">来表<span class="_ _2"></span>示<span class="_ _2"></span>要<span class="_ _2"></span>学<span class="_ _2"></span>习<span class="_ _2"></span>的<span class="_ _2"></span>神<span class="_ _2"></span>经<span class="_ _2"></span>网<span class="_ _2"></span>络<span class="_ _2"></span>，<span class="_ _2"></span>贝叶<span class="_ _2"></span>斯<span class="_ _2"></span>学<span class="_ _6"></span>习是<span class="_ _2"></span>假<span class="_ _2"></span>设<span class="_ _2"></span>参<span class="_ _2"></span>数</div><div class="t m0 xc1 h15 y299 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x63 h6 y29a ff5 fs3 fc0 sc0 ls0 ws0">为随<span class="_ _2"></span>机</div><div class="t m0 x2 h6 y29b ff5 fs3 fc0 sc0 ls0 ws0">向量，并且先<span class="_ _2"></span>验分布为</div><div class="t m0 x88 h15 y37d ffe fs3 fc0 sc0 ls0 ws0">q(θ)</div><div class="t m0 xa7 h6 y29b ff5 fs3 fc0 sc0 ls0 ws0">，贝叶斯方法<span class="_ _2"></span>的预测为</div><div class="t m0 x1e h15 y5d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x37 h16 y37e ffe fs7 fc0 sc0 ls0 ws0">()</div><div class="t m0 x4d h15 y5d ffe fs3 fc0 sc0 ls0 ws0">[]<span class="_ _f"> </span>=</div><div class="t m0 x4a h16 y2c5 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m1 x94 h17 ye4 ffe fs8 fc0 sc0 ls0 ws0"></div><div class="t m0 x90 h15 y5d ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x9f h24 y37f ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h15 y5d ffe fs3 fc0 sc0 ls0 ws0">(,<span class="_ _11"></span>)<span class="_ _2"></span>()</div><div class="t m0 x99 h15 y380 ffe fs3 fc0 sc0 ls0 ws0">≈</div><div class="t m0 x4b h15 y381 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9f h15 y1d7 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3f h16 y382 ffe fs7 fc0 sc0 ls0 ws0">=1</div><div class="t m0 x59 h16 y383 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h15 y380 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x3f h24 y384 ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x5d h15 y380 ffe fs3 fc0 sc0 ls0 ws0">,<span class="_ _11"></span></div><div class="t m0 x11 h16 y385 ffe fs7 fc0 sc0 ls0 ws0"></div><div class="t m0 x0 h15 y386 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">其<span class="_ _2"></span>中<span class="_ _5"> </span><span class="ffe">f(x,</span></span></div><div class="t m0 x73 h15 y387 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x83 h16 y388 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x1e h15 y386 ffe fs3 fc0 sc0 ls0 ws0">)<span class="_ _2"></span><span class="ff5">为<span class="_ _2"></span>第<span class="_ _5"> </span></span>m<span class="_ _8"></span><span class="ff5">次<span class="_ _2"></span>应<span class="_ _2"></span>用<span class="_ _2"></span>丢<span class="_ _6"></span>弃<span class="_ _2"></span>方<span class="_ _2"></span>法<span class="_ _2"></span>后<span class="_ _6"></span>的<span class="_ _2"></span>网<span class="_ _2"></span>络<span class="_ _2"></span>，<span class="_ _2"></span>其<span class="_ _6"></span>参<span class="_ _2"></span>数</span></div><div class="t m0 xc2 h15 y387 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x15 h16 y388 ffe fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x2 h6 y389 ff5 fs3 fc0 sc0 ls0 ws0">为对全部参数</div><div class="t m0 x37 h15 y38a ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x8e h6 y389 ff5 fs3 fc0 sc0 ls0 ws0">的一次采样。</div></div><a class="l" href="https://nndl.github.io/"><div class="d m2" style="border-style:none;position:absolute;left:93.600000px;bottom:562.400000px;width:129.800000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfe" class="pf w0 h0" data-page-no="e"><div class="pc pce w0 h0"><img class="bi x0 y0 w1 hd" alt="" src="bge.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h2d yba ffd fs3 fc0 sc0 ls0 ws0">RNN 中的变分<span class="_ _19"> </span>Drop<span class="_ _2"></span>out<span class="_ _4"> </span>Variational<span class="_ _4"> </span>Drop<span class="_ _2"></span>out</div><div class="t m0 x0 h15 y38b ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ffe">Dropout<span class="_ _8"></span><span class="ff5">一般是针<span class="_ _2"></span>对神<span class="_ _2"></span>经元<span class="_ _2"></span>进行随<span class="_ _2"></span>机丢<span class="_ _2"></span>弃，<span class="_ _2"></span>但是<span class="_ _2"></span>也可<span class="_ _2"></span>以扩展</span></span></div><div class="t m0 x2 h6 y38c ff5 fs3 fc0 sc0 ls0 ws0">到<span class="_ _2"></span>对<span class="_ _2"></span>神<span class="_ _6"></span>经<span class="_ _2"></span>元<span class="_ _6"></span>之<span class="_ _2"></span>间<span class="_ _15"> </span>的<span class="_ _2"></span>连<span class="_ _6"></span>接<span class="_ _6"></span>进<span class="_ _2"></span>行<span class="_ _2"></span>随<span class="_ _6"></span>机<span class="_ _2"></span>丢<span class="_ _6"></span>弃<span class="_ _2"></span>，<span class="_ _2"></span>或<span class="_ _6"></span>每<span class="_ _2"></span>一<span class="_ _6"></span>层<span class="_ _2"></span>进<span class="_ _2"></span>行<span class="_ _6"></span>随<span class="_ _6"></span>机</div><div class="t m0 x2 h6 y38d ff5 fs3 fc0 sc0 ls0 ws0">丢弃。</div><div class="t m0 x0 h23 y38e ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h15 y38f ff5 fs3 fc0 sc0 ls0 ws0">在<span class="_ _16"> </span><span class="ffe">RNN<span class="_ _13"> </span></span>中<span class="_ _17"></span>，<span class="_ _12"></span>不<span class="_ _12"></span>能<span class="_ _17"></span>直<span class="_ _12"></span>接<span class="_ _17"></span>对<span class="_ _12"></span>每<span class="_ _17"></span>个<span class="_ _6"></span>时<span class="_ _17"></span>刻<span class="_ _12"></span>的<span class="_ _17"></span>隐<span class="_ _12"></span>状<span class="_ _17"></span>态<span class="_ _6"></span>进<span class="_ _17"> </span>行<span class="_ _12"></span>随<span class="_ _17"></span>机<span class="_ _0"> </span>丢</div><div class="t m0 x2 h6 y172 ff5 fs3 fc0 sc0 ls0 ws0">弃，这样会损<span class="_ _2"></span>害循环网络在<span class="_ _2"></span>时间维度<span class="_ _2"></span>上记忆能力。</div><div class="t m0 x0 h6 y390 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">一种简单的方<span class="_ _2"></span>法是对非时间<span class="_ _2"></span>维度的连<span class="_ _2"></span>接（即非循环<span class="_ _2"></span>连接）进</span></div><div class="t m0 x2 h6 y34e ff5 fs3 fc0 sc0 ls0 ws0">行随机丢失。<span class="_ _2"></span>如图所示，虚<span class="_ _2"></span>线边表示<span class="_ _2"></span>进行随机丢弃<span class="_ _2"></span>，不同的</div><div class="t m0 x2 h6 y34f ff5 fs3 fc0 sc0 ls0 ws0">颜色表示不同<span class="_ _2"></span>的丢弃掩码。</div><div class="t m0 x0 h6 y391 ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff5">然<span class="_ _6"></span>而<span class="_ _12"></span>根<span class="_ _6"></span>据<span class="_ _12"></span>贝<span class="_ _6"></span>叶<span class="_ _12"></span>斯<span class="_ _12"></span>学<span class="_ _6"></span>习<span class="_ _6"></span>的<span class="_ _12"></span>解<span class="_ _12"></span>释<span class="_ _6"></span>，<span class="_ _12"></span>丢<span class="_ _6"></span>弃<span class="_ _12"></span>法<span class="_ _12"></span>是<span class="_ _6"></span>一<span class="_ _12"></span>种<span class="_ _6"></span>对<span class="_ _12"></span>参<span class="_ _6"></span>数</span></div><div class="t m0 xc3 h15 y392 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 xb4 h6 y391 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _6"></span>采</div><div class="t m0 x2 h6 y393 ff5 fs3 fc0 sc0 ls0 ws0">样。每次采样<span class="_ _2"></span>的参数需要在<span class="_ _2"></span>每个时刻<span class="_ _2"></span>保持不变。因<span class="_ _2"></span>此，在对</div><div class="t m0 x2 h6 y394 ff5 fs3 fc0 sc0 ls0 ws0">循环神经网络<span class="_ _2"></span>上使用丢弃法<span class="_ _2"></span>时，需要<span class="_ _2"></span>对参数矩阵的<span class="_ _2"></span>每个元素</div><div class="t m0 x2 h6 y395 ff5 fs3 fc0 sc0 ls0 ws0">进行随机丢弃<span class="_ _2"></span>，并在所有时<span class="_ _2"></span>刻都使用<span class="_ _2"></span>相同的丢弃掩<span class="_ _2"></span>码。这种</div><div class="t m0 x2 h15 y396 ff5 fs3 fc0 sc0 ls0 ws0">方<span class="_ _2"></span>法<span class="_ _6"></span>称<span class="_ _2"></span>为<span class="_ _6"></span>变<span class="_ _6"></span>分<span class="_ _2"></span>丢<span class="_ _6"></span>弃<span class="_ _6"></span>法<span class="_ _2"></span>（<span class="_ _6"></span><span class="ffe">Variatio<span class="_ _2"></span>nal<span class="_ _4"></span>Dropout<span class="_ _6"></span></span>）<span class="_ _6"></span>。<span class="_ _7"> </span>图<span class="_ _5"> </span><span class="ffe">7.12<span class="_ _8"></span></span>给</div><div class="t m0 x2 h6 y397 ff5 fs3 fc0 sc0 ls0 ws0">出<span class="_ _2"></span>了<span class="_ _6"></span>变<span class="_ _6"></span>分<span class="_ _6"></span>丢<span class="_ _6"></span>弃<span class="_ _6"></span>法<span class="_ _2"></span>的<span class="_ _6"></span>示<span class="_ _6"></span>例<span class="_ _6"></span>，<span class="_ _6"></span>相<span class="_ _6"></span>同<span class="_ _6"></span>颜<span class="_ _2"></span>色<span class="_ _6"></span>表<span class="_ _6"></span>示<span class="_ _6"></span>使<span class="_ _6"></span>用<span class="_ _6"></span>相<span class="_ _6"></span>同<span class="_ _2"></span>的<span class="_ _6"></span>丢<span class="_ _6"></span>弃<span class="_ _6"></span>掩</div><div class="t m0 x2 h6 y398 ff5 fs3 fc0 sc0 ls0 ws0">码。</div><div class="t m0 x0 h14 y399 ffd fs0 fc0 sc0 ls0 ws0">2.4<span class="_ _4"> </span>N<span class="_ _2"></span>euron<span class="_ _15"> </span>Units</div><div class="t m0 x0 h15 y39a ff5 fs3 fc0 sc0 ls0 ws0">到<span class="_ _2"></span>目<span class="_ _6"></span>前<span class="_ _2"></span>为<span class="_ _6"></span>止<span class="_ _2"></span>，<span class="_ _2"></span>我<span class="_ _6"></span>们<span class="_ _6"></span>讨<span class="_ _2"></span>论<span class="_ _6"></span>了<span class="_ _2"></span>含<span class="_ _6"></span>有<span class="_ _15"> </span><span class="ffe">sigmoid<span class="_ _2"></span>al<span class="_ _4"></span>neurons<span class="_ _4"></span></span>的<span class="_ _2"></span>非<span class="_ _6"></span>线<span class="_ _6"></span>性<span class="_ _2"></span>分<span class="_ _6"></span>类</div><div class="t m0 x0 h6 y39b ff5 fs3 fc0 sc0 ls0 ws0">的神经网络。<span class="_ _2"></span>但是在很多应<span class="_ _2"></span>用中，使<span class="_ _2"></span>用其他激活函<span class="_ _2"></span>数可以设计更</div><div class="t m0 x0 h6 y39c ff5 fs3 fc0 sc0 ls0 ws0">好的神经网络<span class="_ _2"></span>。下面列出一<span class="_ _2"></span>些常见的<span class="_ _2"></span>激活函数和激<span class="_ _2"></span>活函数的梯度</div><div class="t m0 x0 h15 y39d ff5 fs3 fc0 sc0 ls0 ws0">定义，它们可<span class="_ _2"></span>以和前面讨论<span class="_ _2"></span>过的<span class="_ _3"> </span><span class="ffe">sigmoid<span class="_ _2"></span>al<span class="_ _3"></span></span>函数互相替换<span class="_ _2"></span>。</div></div><div class="c x23 y97 w6 h18"><div class="t m0 x7 h19 y50 ff7 fs0 fc0 sc0 ls0 ws0">2.4 Notes<span class="_ _4"> </span>i<span class="_ _2"></span>nfo.</div></div><div class="c x23 y39e w7 h1a"><div class="t m0 x7 hb y52 ffb fs5 fc0 sc0 ls0 ws0">课件<span class="ff7">/Slides</span></div></div><div class="c x24 y39e w8 h1a"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>P53</div></div><div class="c x23 y39f w7 h1a"><div class="t m0 x7 hb y54 ffb fs5 fc0 sc0 ls0 ws0">视频<span class="ff7">/Video</span></div></div><div class="c x24 y39f w8 h1a"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>4,<span class="_ _3"> </span>68:00</div></div><div class="c x23 y3a0 w7 h1b"><div class="t m0 x7 hb y52 ff7 fs5 fc0 sc0 ls0 ws0">GitHub<span class="ffb">·代码</span></div></div><div class="c x24 y3a0 w8 h1b"><div class="t m0 x7 h1c y52 ffb fs5 fc0 sc0 ls0 ws0">实时在线查阅文档</div></div><div class="c x23 y3a1 w7 h1a"><div class="t m0 x7 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">Bilibili<span class="ffb">·视频</span></div></div><div class="c x24 y3a1 w8 h1a"><div class="t m0 x7 h1c y57 ffb fs5 fc0 sc0 ls0 ws0">中英字幕课程视频</div></div><div class="c x23 y3a2 w6 h1d"><div class="t m0 x25 h1e y59 ff7 fs9 fc0 sc0 ls0 ws0">Stanford<span class="_ _11"> </span>University<span class="_ _8"> </span>X ShowMeA</div><div class="t m0 x26 hb y54 ff7 fs5 fc0 sc0 ls0 ws0">I</div></div><a class="l" href="https://arxiv.org/abs/1512.05287"><div class="d m2" style="border-style:none;position:absolute;left:165.200000px;bottom:786.950000px;width:105.400000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pff" class="pf w0 h0" data-page-no="f"><div class="pc pcf w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bgf.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h15 y111 ffd fs3 fc0 sc0 ls0 ws0">Sigmoid<span class="ff5">：这<span class="_ _2"></span>是我们讨论过<span class="_ _2"></span>的常用选择，<span class="_ _2"></span>激活函数<span class="_ _4"> </span><span class="ffe">σ<span class="_ _4"></span></span>为：</span></div><div class="t m0 x3 h15 y3a3 ffe fs3 fc0 sc0 ls0 ws0">σ(z)<span class="_ _4"></span>=</div><div class="t m0 x32 h15 y3a4 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9f h15 y3a5 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>e<span class="_ _2"></span>xp(<span class="_ _3"></span>−<span class="_ _3"></span>z<span class="_ _2"></span>)</div><div class="t m0 x7c h6 y3a6 ff5 fs3 fc0 sc0 ls0 ws0">其中</div><div class="t m0 x88 h15 y3a7 ffe fs3 fc0 sc0 ls0 ws0">σ(z)<span class="_ _4"></span>∈<span class="_ _7"></span>(0,1)</div><div class="t m0 x0 h15 y3a8 ffe fs3 fc0 sc0 ls0 ws0">σ(z)<span class="_ _4"></span><span class="ff5">的梯度为</span></div><div class="t m0 x81 h15 y3a9 ffe fs3 fc0 sc0 ls0 ws0">σ</div><div class="t m0 x1e h16 y3aa ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x17 h15 y3a8 ffe fs3 fc0 sc0 ls0 ws0">(z)<span class="_ _4"></span>=</div><div class="t m0 xb8 h16 y3ab ffe fs7 fc0 sc0 ls0 ws0">−exp(−z)</div><div class="t m0 x9 h16 y171 ffe fs7 fc0 sc0 ls0 ws0">1+exp(−z)</div><div class="t m0 x3f h15 y3a8 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _15"></span>σ(z)</div><div class="t m0 x78 h15 y3a9 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _3"></span>−<span class="_ _3"></span>σ(z)</div><div class="t m0 x0 h2d y3ac ffd fs3 fc0 sc0 ls0 ws0">Tanh<span class="_ _2"></span><span class="ff5">：</span></div><div class="t m0 x97 h15 y3ad ffe fs3 fc0 sc0 ls0 ws0">tanℎ</div><div class="t m0 xb9 h6 y3ac ff5 fs3 fc0 sc0 ls0 ws0">函数<span class="_ _2"></span>是</div><div class="t m0 x1f h15 y3ad ffe fs3 fc0 sc0 ls0 ws0">sigmoid</div><div class="t m0 x4b h6 y3ac ff5 fs3 fc0 sc0 ls0 ws0">函数<span class="_ _2"></span>之<span class="_ _2"></span>外<span class="_ _2"></span>的另<span class="_ _2"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>选<span class="_ _2"></span>择，<span class="_ _2"></span>在<span class="_ _2"></span>实<span class="_ _2"></span>际中</div><div class="t m0 x0 h6 y3ae ff5 fs3 fc0 sc0 ls0 ws0">它能<span class="_ _2"></span>更快<span class="_ _2"></span>地收<span class="_ _2"></span>敛。</div><div class="t m0 x18 h15 y3af ffe fs3 fc0 sc0 ls0 ws0">tanℎ</div><div class="t m0 x8f h6 y3ae ff5 fs3 fc0 sc0 ls0 ws0">和</div><div class="t m0 x74 h15 y3af ffe fs3 fc0 sc0 ls0 ws0">sigmoid</div><div class="t m0 x43 h6 y3ae ff5 fs3 fc0 sc0 ls0 ws0">的主<span class="_ _2"></span>要不<span class="_ _2"></span>同在<span class="_ _2"></span>于</div><div class="t m0 x85 h15 y3af ffe fs3 fc0 sc0 ls0 ws0">tanℎ</div><div class="t m0 x63 h6 y3ae ff5 fs3 fc0 sc0 ls0 ws0">的输<span class="_ _2"></span>出</div><div class="t m0 x0 h5 y3b0 ff5 fs3 fc0 sc0 ls0 ws0">范围在<span class="_ _4"> </span><span class="ff4">-1<span class="_ _4"> </span></span>到<span class="_ _3"> </span><span class="ff4">1<span class="_ _15"> </span></span>，而</div><div class="t m0 x4e h15 y3b1 ffe fs3 fc0 sc0 ls0 ws0">sigmoid</div><div class="t m0 x9f h5 y3b0 ff5 fs3 fc0 sc0 ls0 ws0">的输出范围在<span class="_ _4"> </span><span class="ff4">0<span class="_ _4"> </span></span>到<span class="_ _4"> </span><span class="ff4">1<span class="_ _4"> </span></span>。</div><div class="t m0 x0 h15 y3b2 ffe fs3 fc0 sc0 ls0 ws0">ℎ()</div><div class="t m0 x97 h15 y20a ffe fs3 fc0 sc0 ls0 ws0">()<span class="_ _3"></span>−<span class="_ _3"></span><span class="_ _2"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>)</div><div class="t m0 x97 h15 y3b3 ffe fs3 fc0 sc0 ls0 ws0">()<span class="_ _3"></span>+<span class="_ _3"></span><span class="_ _2"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>)</div><div class="t m0 xa2 h15 y3b2 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>2<span class="_ _2"></span>(2)</div><div class="t m0 x0 h15 y3b4 ff5 fs3 fc0 sc0 ls0 ws0">其中<span class="_ _4"> </span><span class="ffe">ℎ()<span class="_ _15"></span>∈<span class="_ _15"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>1,1)<span class="_ _4"></span></span>。</div><div class="t m0 x0 h15 y3b5 ffe fs3 fc0 sc0 ls0 ws0">ℎ()</div><div class="t m0 x97 h6 y3b6 ff5 fs3 fc0 sc0 ls0 ws0">的梯度为：</div><div class="t m0 x0 h15 y3b7 ffe fs3 fc0 sc0 ls0 ws0"></div><div class="t m0 x8 h15 y3b8 ffe fs3 fc0 sc0 ls0 ws0">ℎ</div><div class="t m0 x2 h16 y3b9 ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 xc0 h15 y3b7 ffe fs3 fc0 sc0 ls0 ws0">()<span class="_ _4"></span>=</div><div class="t m0 xb7 h15 y3ba ffe fs3 fc0 sc0 ls0 ws0">()<span class="_ _3"></span>−<span class="_ _3"></span><span class="_ _2"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>)</div><div class="t m0 xb7 h15 y28e ffe fs3 fc0 sc0 ls0 ws0">()<span class="_ _3"></span>+<span class="_ _3"></span><span class="_ _2"></span>(<span class="_ _3"></span>−<span class="_ _3"></span>)</div><div class="t m0 x59 h16 y3bb ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x39 h15 y3b7 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>1<span class="_ _3"></span>−<span class="_ _4"></span></div><div class="t m0 x55 h15 y3b8 ffe fs3 fc0 sc0 ls0 ws0">ℎ</div><div class="t m0 x34 h16 y3bc ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb h15 y3b7 ffe fs3 fc0 sc0 ls0 ws0">()</div><div class="t m0 x0 h15 y3bd ffd fs3 fc0 sc0 ls0 ws0">Hard<span class="_ _15"> </span>tanh<span class="_ _6"></span><span class="ff5">：<span class="_ _6"></span>有<span class="_ _2"></span>时<span class="_ _6"></span>候<span class="_ _15"> </span><span class="ffe">ℎ<span class="_ _2"></span>ard tan<span class="_ _2"></span>ℎ<span class="_ _15"></span></span>函<span class="_ _2"></span>数<span class="_ _6"></span>有<span class="_ _6"></span>时<span class="_ _2"></span>比</span></div><div class="t m0 x34 h15 y3be ffe fs3 fc0 sc0 ls0 ws0">tanℎ</div><div class="t m0 xd h6 y3bd ff5 fs3 fc0 sc0 ls0 ws0">函<span class="_ _2"></span>数<span class="_ _6"></span>的<span class="_ _2"></span>选<span class="_ _6"></span>择<span class="_ _6"></span>更</div><div class="t m0 x0 h6 y3bf ff5 fs3 fc0 sc0 ls0 ws0">为优先<span class="_ _2"></span>，因为<span class="_ _2"></span>它的计<span class="_ _2"></span>算量更<span class="_ _2"></span>小。然<span class="_ _2"></span>而当</div><div class="t m0 x3c h15 y3c0 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x4c h6 y3bf ff5 fs3 fc0 sc0 ls0 ws0">的值大<span class="_ _2"></span>于</div><div class="t m0 xa9 h15 y3c0 ffe fs3 fc0 sc0 ls0 ws0">1</div><div class="t m0 x60 h6 y3bf ff5 fs3 fc0 sc0 ls0 ws0">时，函<span class="_ _2"></span>数的</div><div class="t m0 x0 h15 y3c1 ff5 fs3 fc0 sc0 ls0 ws0">数<span class="_ _12"></span>值<span class="_ _12"></span>会<span class="_ _6"></span>饱<span class="_ _12"></span>和<span class="_ _12"></span>（<span class="_ _17"></span>如<span class="_ _2"></span>右<span class="_ _12"></span>图<span class="_ _17"></span>所<span class="_ _6"></span>示<span class="_ _12"></span>会<span class="_ _12"></span>恒<span class="_ _12"></span>等<span class="_ _12"></span>于<span class="_ _0"> </span><span class="ffe">1<span class="_ _6"></span></span>）<span class="_ _12"></span>。<span class="_ _12"></span><span class="ffe">ℎard<span class="_ _2"></span> tanℎ<span class="_ _0"> </span></span>激<span class="_ _12"></span>活<span class="_ _12"></span>函<span class="_ _6"></span>数</div><div class="t m0 x0 h6 y3c2 ff5 fs3 fc0 sc0 ls0 ws0">为：</div><div class="t m0 xa5 h15 y3c3 ffe fs3 fc0 sc0 ls0 ws0">ℎardtanℎ(z)<span class="_ _15"></span>=</div><div class="t m0 x88 h15 y12c ffe fs3 fc0 sc0 ls0 ws0">−1<span class="_ _1d"> </span>:<span class="_ _11"></span>z<span class="_ _4"></span>&lt;<span class="_ _15"></span>1</div><div class="t m0 x49 h15 y3c4 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x1d h15 y3c5 ffe fs3 fc0 sc0 ls0 ws0">:<span class="_ _1"></span>−<span class="_ _3"></span>1<span class="_ _15"></span>≤<span class="_ _15"></span>z<span class="_ _7"></span>≤<span class="_ _15"></span>1</div><div class="t m0 x4b h15 y3c6 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1e"> </span>:<span class="_ _11"></span>z<span class="_ _15"></span>&gt;<span class="_ _15"></span>1</div><div class="t m0 x0 h15 y3c7 ffe fs3 fc0 sc0 ls0 ws0">ℎard tanℎ</div><div class="t m0 x53 h6 y3c8 ff5 fs3 fc0 sc0 ls0 ws0">这个函数的微<span class="_ _2"></span>分也可以用分<span class="_ _2"></span>段函数的<span class="_ _2"></span>形式表示：</div><div class="t m0 x73 h15 y3c9 ffe fs3 fc0 sc0 ls0 ws0">ℎardtanℎ(z)<span class="_ _f"> </span>=</div><div class="t m0 x90 h15 y3ca ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _f"> </span>:<span class="_ _1"></span>−<span class="_ _4"></span>1<span class="_ _4"></span>≤<span class="_ _15"></span>z<span class="_ _15"></span>≤<span class="_ _15"></span>1</div><div class="t m0 x90 h15 y3cb ffe fs3 fc0 sc0 ls0 ws0">0<span class="_ _f"> </span>:<span class="_ _11"></span>otℎerwis<span class="_ _2"></span>e</div><div class="t m0 x0 h15 y3cc ffd fs3 fc0 sc0 ls0 ws0">Soft<span class="_ _4"> </span>sign<span class="_ _2"></span><span class="ff5">：<span class="_ _4"> </span><span class="ffe">soft sign<span class="_ _4"></span></span>函<span class="_ _2"></span>数是<span class="_ _2"></span>另外<span class="_ _2"></span>一<span class="_ _2"></span>种非<span class="_ _2"></span>线<span class="_ _2"></span>性<span class="_ _2"></span>激活<span class="_ _2"></span>函数<span class="_ _2"></span>，<span class="_ _2"></span>它<span class="_ _2"></span>可以</span></div><div class="t m0 x0 h6 y3cd ff5 fs3 fc0 sc0 ls0 ws0">是</div><div class="t m0 x13 h15 y3ce ffe fs3 fc0 sc0 ls0 ws0">tanℎ</div><div class="t m0 x66 h15 y3cd ff5 fs3 fc0 sc0 ls0 ws0">的另<span class="_ _2"></span>外<span class="_ _2"></span>一<span class="_ _6"></span>种选<span class="_ _2"></span>择<span class="_ _2"></span>，<span class="_ _2"></span>因<span class="_ _2"></span>为<span class="_ _2"></span>它<span class="_ _2"></span>和<span class="_ _4"> </span><span class="ffe">ℎard <span class="_ _2"></span>clipped func<span class="_ _2"></span>tions<span class="_ _4"></span></span>一<span class="_ _2"></span>样</div><div class="t m0 x0 h6 y383 ff5 fs3 fc0 sc0 ls0 ws0">不会过早地饱<span class="_ _2"></span>和：</div><div class="t m0 x3 h15 y3cf ffe fs3 fc0 sc0 ls0 ws0">softsign(z)<span class="_ _15"></span>=</div><div class="t m0 x1d h15 y3d0 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x21 h15 y3d1 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>|<span class="_ _2"></span>z|</div><div class="t m0 x0 h15 y3d2 ffe fs3 fc0 sc0 ls0 ws0">soft sign</div><div class="t m0 x50 h6 y3d3 ff5 fs3 fc0 sc0 ls0 ws0">函数的微分表<span class="_ _2"></span>达式为：</div><div class="t m0 x4e h15 y3d4 ffe fs3 fc0 sc0 ls0 ws0">soft sign</div><div class="t m0 x9f h16 y3d5 ffe fs7 fc0 sc0 ls0 ws0">&apos;</div><div class="t m0 x94 h15 y3d4 ffe fs3 fc0 sc0 ls0 ws0">z<span class="_ _d"> </span>=</div><div class="t m0 x3b h15 y3d6 ffe fs3 fc0 sc0 ls0 ws0">sgn(z)</div><div class="t m0 x3b h15 y3d7 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _1"></span>+<span class="_ _3"></span>z</div><div class="t m0 xb3 h16 y3d8 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x0 h6 y3d9 ff5 fs3 fc0 sc0 ls0 ws0">其中</div><div class="t m0 xc0 h15 y3da ffe fs3 fc0 sc0 ls0 ws0">sgn</div><div class="t m0 x50 h6 y3d9 ff5 fs3 fc0 sc0 ls0 ws0">是符号函数，<span class="_ _2"></span>根据</div><div class="t m0 x70 h15 y3da ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x4b h15 y3d9 ff5 fs3 fc0 sc0 ls0 ws0">的符号返回<span class="_ _3"> </span><span class="ffe">1<span class="_ _3"></span></span>或者<span class="_ _3"> </span><span class="ffe">-1<span class="_ _3"></span></span>。</div><div class="t m0 xb1 h15 y3db ffe fs3 fc0 sc0 ls0 ws0">rect&apos;(z)<span class="_ _f"> </span>=</div><div class="t m0 x59 h15 y3dc ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _f"> </span>:<span class="_ _11"></span>z<span class="_ _4"></span>&gt;<span class="_ _7"></span>1</div><div class="t m0 x59 h15 y3dd ffe fs3 fc0 sc0 ls0 ws0">0<span class="_ _f"> </span>:otℎerwis<span class="_ _2"></span>e</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y3de ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _5"> </span><span class="ff10 fs1">↑<span class="_ _1"> </span><span class="ffc">Figur<span class="_ _2"></span>e<span class="_ _13"> </span>9:<span class="_ _0"> </span>T<span class="_ _2"></span>he<span class="_ _0"> </span>re<span class="_ _2"></span>sponse<span class="_ _13"> </span>of<span class="_ _13"> </span>a</span></span></div><div class="t m0 x28 h12 y3df ffc fs1 fc0 sc0 ls0 ws0">sigmoid<span class="_ _10"> </span>nonlinearity<span class="_ _4"> </span><span class="ffb">【<span class="_ _4"> </span>图<span class="_ _1f"> </span></span>9:sigmoid</div><div class="t m0 x28 h13 y3e0 ffb fs1 fc0 sc0 ls0 ws0">非线性的响<span class="_ _2"></span>应】</div><div class="t m0 x28 h11 y3e1 ffa fs6 fc0 sc0 ls0 ws0">❐</div><div class="t m0 x29 h1f y2b4 ff10 fs1 fc0 sc0 ls0 ws0">↑</div><div class="t m0 x13 h12 y3e1 ffc fs1 fc0 sc0 ls0 ws0">Figure<span class="_ _8"> </span>10:<span class="_ _7"> </span>T<span class="_ _2"></span>he<span class="_ _7"> </span>re<span class="_ _2"></span>sponse<span class="_ _8"> </span>of<span class="_ _7"> </span>a</div><div class="t m0 x28 h12 y3e2 ffc fs1 fc0 sc0 ls0 ws0">tanh<span class="_ _7"> </span>nonlinearity<span class="_ _7"> </span><span class="ffb">【<span class="_ _17"> </span>图<span class="_ _16"> </span></span>10<span class="_ _2"></span>:tanh<span class="_ _15"> </span><span class="ffb">非<span class="_ _17"> </span>线</span></div><div class="t m0 x28 h13 y3e3 ffb fs1 fc0 sc0 ls0 ws0">性的响应】</div><div class="t m0 x28 h11 y3e4 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _10"> </span><span class="ff10 fs1">↑<span class="_ _17"></span><span class="ffc">Figure<span class="_ _7"> </span>11:<span class="_ _8"> </span>The<span class="_ _8"> </span>response<span class="_ _8"> </span>of<span class="_ _7"> </span>a</span></span></div><div class="t m0 x28 h12 y3e5 ffc fs1 fc0 sc0 ls0 ws0">hard<span class="_ _3"> </span>tanh<span class="_ _3"> </span>nonlinearity<span class="_ _2"></span><span class="ffb">【<span class="_ _2"></span>图<span class="_ _10"> </span></span>1<span class="_ _2"></span>1<span class="ffb">：<span class="_ _2"></span></span>hard</div><div class="t m0 x28 h12 y3e6 ffc fs1 fc0 sc0 ls0 ws0">tanh <span class="ffb">非线性的响<span class="_ _2"></span>应】</span></div><div class="t m0 x28 h11 y3e7 ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _10"> </span><span class="ff10 fs1">↑<span class="_ _17"></span><span class="ffc">Figure<span class="_ _7"> </span>12:<span class="_ _8"> </span>The<span class="_ _8"> </span>response<span class="_ _8"> </span>of<span class="_ _7"> </span>a</span></span></div><div class="t m0 x28 h12 y3e8 ffc fs1 fc0 sc0 ls0 ws0">soft<span class="_ _4"> </span>sign<span class="_ _4"> </span>nonlinearity<span class="_ _12"></span><span class="ffb">【<span class="_ _6"></span>图<span class="_ _19"> </span></span>12<span class="_ _6"></span><span class="ffb">：<span class="_ _12"></span>软<span class="_ _6"></span>符</span></div><div class="t m0 x28 h13 y310 ffb fs1 fc0 sc0 ls0 ws0">号非线性的<span class="_ _2"></span>响应】</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf10" class="pf w0 h0" data-page-no="10"><div class="pc pc10 w0 h0"><img class="bi x0 y0 w1 hd" alt="" src="bg10.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h2d yba ffd fs3 fc0 sc0 ls0 ws0">ReLU<span class="_ _6"></span><span class="ff5">：</span></div><div class="t m0 x6d h15 ybb ffe fs3 fc0 sc0 ls0 ws0">ReLU</div><div class="t m0 x98 h15 yba ff5 fs3 fc0 sc0 ls0 ws0">（<span class="_ _8"> </span><span class="ffe">Rectiﬁed Linea<span class="_ _2"></span>r Unit<span class="_ _8"></span></span>）<span class="_ _12"></span>函<span class="_ _6"></span>数<span class="_ _6"></span>是<span class="_ _12"></span>激<span class="_ _6"></span>活<span class="_ _6"></span>函<span class="_ _12"></span>数<span class="_ _6"></span>中<span class="_ _12"></span>的</div><div class="t m0 x0 h15 ybc ff5 fs3 fc0 sc0 ls0 ws0">一个常<span class="_ _2"></span>见的选<span class="_ _2"></span>择，当<span class="_ _3"> </span><span class="ffe">z<span class="_ _3"></span></span>的<span class="_ _2"></span>值特<span class="_ _2"></span>别大的时<span class="_ _2"></span>候它<span class="_ _2"></span>也不会饱<span class="_ _2"></span>和。<span class="_ _2"></span>在计算</div><div class="t m0 x0 h6 ybd ff5 fs3 fc0 sc0 ls0 ws0">机视觉应用中<span class="_ _2"></span>取得了很大的<span class="_ _2"></span>成功：</div><div class="t m0 xb2 h15 y3e9 ffe fs3 fc0 sc0 ls0 ws0">rect(z)<span class="_ _4"></span>=<span class="_ _15"></span>ma<span class="_ _2"></span>x(z,<span class="_ _11"></span>0<span class="_ _2"></span>)</div><div class="t m0 x0 h15 y3ea ffe fs3 fc0 sc0 ls0 ws0">ReLU</div><div class="t m0 x71 h6 y3eb ff5 fs3 fc0 sc0 ls0 ws0">函数的微分是<span class="_ _2"></span>一个分段函数<span class="_ _2"></span>：</div><div class="t m0 xb1 h15 yc4 ffe fs3 fc0 sc0 ls0 ws0">rect&apos;(z)<span class="_ _f"> </span>=</div><div class="t m0 x59 h15 y3ec ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _f"> </span>:<span class="_ _11"></span>z<span class="_ _4"></span>&gt;<span class="_ _7"></span>1</div><div class="t m0 x59 h15 y3ed ffe fs3 fc0 sc0 ls0 ws0">0<span class="_ _f"> </span>:otℎerwis<span class="_ _2"></span>e</div><div class="t m0 x0 h2d y3ee ffd fs3 fc0 sc0 ls0 ws0">Leaky<span class="_ _4"> </span>ReLU<span class="_ _2"></span><span class="ff5">：<span class="_ _2"></span>传<span class="_ _2"></span>统<span class="_ _2"></span>的</span></div><div class="t m0 xa0 h15 y3ef ffe fs3 fc0 sc0 ls0 ws0">ReLU</div><div class="t m0 x49 h15 y3ee ff5 fs3 fc0 sc0 ls0 ws0">单元<span class="_ _2"></span>当<span class="_ _4"> </span><span class="ffe">z<span class="_ _3"></span></span>的<span class="_ _2"></span>值小<span class="_ _2"></span>于<span class="_ _4"> </span><span class="ffe">0<span class="_ _3"></span></span>时<span class="_ _2"></span>，是<span class="_ _2"></span>不<span class="_ _2"></span>会<span class="_ _2"></span>反</div><div class="t m0 x0 h6 y3f0 ff5 fs3 fc0 sc0 ls0 ws0">向<span class="_ _2"></span>传<span class="_ _2"></span>播<span class="_ _6"></span>误<span class="_ _2"></span>差</div><div class="t m0 xb7 h15 y3f1 ffe fs3 fc0 sc0 ls0 ws0">leaky ReLU</div><div class="t m0 x8f h6 y3f0 ff5 fs3 fc0 sc0 ls0 ws0">改<span class="_ _2"></span>善<span class="_ _2"></span>了<span class="_ _6"></span>这<span class="_ _2"></span>一<span class="_ _2"></span>点<span class="_ _6"></span>，<span class="_ _2"></span>当</div><div class="t m0 x33 h15 y3f1 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x4 h15 y3f0 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>值<span class="_ _2"></span>小<span class="_ _6"></span>于<span class="_ _15"> </span><span class="ffe">0<span class="_ _4"></span></span>时<span class="_ _2"></span>，<span class="_ _2"></span>仍</div><div class="t m0 x0 h6 y3f2 ff5 fs3 fc0 sc0 ls0 ws0">然会有一个很<span class="_ _2"></span>小的误差反向<span class="_ _2"></span>传播回去<span class="_ _2"></span>。</div><div class="t m0 x4e h15 y3f3 ffe fs3 fc0 sc0 ls0 ws0">leaky</div><div class="t m0 xbe h15 y3f4 ffe fs3 fc0 sc0 ls0 ws0">z</div><div class="t m0 x4b h15 y3f3 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>max<span class="_ _14"> </span>z,<span class="_ _11"></span>k<span class="_ _3"></span>∙<span class="_ _3"></span>z</div><div class="t m0 x52 h6 y3f5 ff5 fs3 fc0 sc0 ls0 ws0">其中</div><div class="t m0 x49 h15 y3f6 ffe fs3 fc0 sc0 ls0 ws0">0<span class="_ _4"></span>&lt;<span class="_ _15"></span>k<span class="_ _15"></span>&lt;<span class="_ _15"></span>1</div><div class="t m0 x0 h15 y3f7 ffe fs3 fc0 sc0 ls0 ws0">leaky ReLU<span class="_ _4"></span><span class="ff5">函数<span class="_ _2"></span>的微分是<span class="_ _2"></span>一个分段函数<span class="_ _2"></span>：</span></div><div class="t m0 x17 h15 y218 ffe fs3 fc0 sc0 ls0 ws0">leaky&apos;(z)<span class="_ _f"> </span>=</div><div class="t m0 x57 h15 y3f8 ffe fs3 fc0 sc0 ls0 ws0">1<span class="_ _f"> </span>:<span class="_ _11"></span>z<span class="_ _4"></span>&gt;<span class="_ _15"></span>0</div><div class="t m0 x57 h15 yc ffe fs3 fc0 sc0 ls0 ws0">k<span class="_ _20"> </span>:<span class="_ _11"></span>otℎerwise</div><div class="t m0 x0 h14 y3f9 ffd fs0 fc0 sc0 ls0 ws0">2.5<span class="_ _4"> </span>Da<span class="_ _2"></span>ta<span class="_ _15"> </span>Preprocessing</div><div class="t m0 x0 h6 y3fa ff5 fs3 fc0 sc0 ls0 ws0">与机器学习模<span class="_ _2"></span>型的一般情况<span class="_ _2"></span>一样，确<span class="_ _2"></span>保模型在当前<span class="_ _2"></span>任务上获得合</div><div class="t m0 x0 h6 y3fb ff5 fs3 fc0 sc0 ls0 ws0">理性能的一个<span class="_ _2"></span>关键步骤是对<span class="_ _2"></span>数据执行<span class="_ _2"></span>基本的预处理<span class="_ _2"></span>。下面概述了</div><div class="t m0 x0 h6 y3fc ff5 fs3 fc0 sc0 ls0 ws0">一些常见的技<span class="_ _2"></span>术。</div><div class="t m0 x0 h2d y3fd ffd fs3 fc0 sc0 ls0 ws0">Mean<span class="_ _4"> </span>Subtract<span class="_ _2"></span>ion</div><div class="t m0 x0 h6 y3fe ff5 fs3 fc0 sc0 ls0 ws0">给<span class="_ _2"></span>定<span class="_ _2"></span>一<span class="_ _2"></span>组<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _2"></span>数<span class="_ _2"></span>据</div><div class="t m0 x69 h15 y3ff ffe fs3 fc0 sc0 ls0 ws0">X</div><div class="t m0 x4d h6 y3fe ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>一<span class="_ _2"></span>般<span class="_ _2"></span>把</div><div class="t m0 x3f h15 y3ff ffe fs3 fc0 sc0 ls0 ws0">X</div><div class="t m0 x90 h6 y3fe ff5 fs3 fc0 sc0 ls0 ws0">中<span class="_ _2"></span>的<span class="_ _2"></span>值<span class="_ _2"></span>减<span class="_ _2"></span>去</div><div class="t m0 xaa h15 y3ff ffe fs3 fc0 sc0 ls0 ws0">X</div><div class="t m0 x67 h6 y3fe ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>平<span class="_ _2"></span>均<span class="_ _2"></span>特<span class="_ _2"></span>征<span class="_ _6"></span>向<span class="_ _2"></span>量</div><div class="t m0 x0 h6 y400 ff5 fs3 fc0 sc0 ls0 ws0">来使数据零中<span class="_ _2"></span>心化。在实践<span class="_ _2"></span>中很重要<span class="_ _2"></span>的一点是，只<span class="_ _2"></span>计算训练集的</div><div class="t m0 x0 h6 y401 ff5 fs3 fc0 sc0 ls0 ws0">平均值，而且<span class="_ _2"></span>在训练集，验<span class="_ _2"></span>证集和测<span class="_ _2"></span>试集都是减去<span class="_ _2"></span>同一平均值。</div><div class="t m0 x0 h2d y402 ffd fs3 fc0 sc0 ls0 ws0">Normalizatio<span class="_ _2"></span>n</div><div class="t m0 x0 h6 y403 ff5 fs3 fc0 sc0 ls0 ws0">另<span class="_ _2"></span>外<span class="_ _6"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>常<span class="_ _2"></span>见<span class="_ _6"></span>的<span class="_ _6"></span>技<span class="_ _2"></span>术<span class="_ _6"></span>（<span class="_ _6"></span>虽<span class="_ _6"></span>然<span class="_ _2"></span>没<span class="_ _6"></span>有</div><div class="t m0 x39 h15 y404 ffe fs3 fc0 sc0 ls0 ws0">mean Subtra<span class="_ _2"></span>ction</div><div class="t m0 x85 h6 y403 ff5 fs3 fc0 sc0 ls0 ws0">常<span class="_ _2"></span>用<span class="_ _6"></span>）<span class="_ _6"></span>是<span class="_ _6"></span>将</div><div class="t m0 x0 h6 y405 ff5 fs3 fc0 sc0 ls0 ws0">每个输入特征<span class="_ _2"></span>维度缩小，让<span class="_ _2"></span>每个输入<span class="_ _2"></span>特征维度具有<span class="_ _2"></span>相似的幅度范</div><div class="t m0 x0 h5 y406 ff5 fs3 fc0 sc0 ls0 ws0">围<span class="_ _6"></span>。<span class="_ _12"></span>这<span class="_ _12"></span>是<span class="_ _12"></span>很<span class="_ _6"></span>有<span class="_ _12"></span>用<span class="_ _12"></span>的<span class="_ _12"></span>，<span class="_ _6"></span>因<span class="_ _12"></span>此<span class="_ _6"></span>不<span class="_ _12"></span>同<span class="_ _12"></span>的<span class="_ _12"></span>输<span class="_ _6"></span>入<span class="_ _12"></span>特<span class="_ _12"></span>征<span class="_ _12"></span>是<span class="_ _6"></span>用<span class="_ _12"></span>不<span class="_ _12"></span>同<span class="_ _12"></span><span class="ff4">“<span class="_ _6"></span></span>单<span class="_ _12"></span>位<span class="_ _12"></span><span class="ff4">”<span class="_ _6"></span></span>度</div><div class="t m0 x0 h6 y147 ff5 fs3 fc0 sc0 ls0 ws0">量，但是最初<span class="_ _2"></span>的时候我们经<span class="_ _2"></span>常认为所<span class="_ _2"></span>有的特征同样<span class="_ _2"></span>重要。实现方</div><div class="t m0 x0 h6 y149 ff5 fs3 fc0 sc0 ls0 ws0">法是将特征除<span class="_ _2"></span>以它们各自在<span class="_ _2"></span>训练集中<span class="_ _2"></span>计算的标准差<span class="_ _2"></span>。</div><div class="t m0 x0 h2d y1e1 ffd fs3 fc0 sc0 ls0 ws0">Whitening</div><div class="t m0 x0 h5 y407 ff5 fs3 fc0 sc0 ls0 ws0">相比上述<span class="_ _2"></span>的两<span class="_ _2"></span>个方法，<span class="_ _15"> </span><span class="ff4">whitening<span class="_ _4"> </span></span>没<span class="_ _2"></span>有那么<span class="_ _2"></span>常用，<span class="_ _2"></span>它本质<span class="_ _2"></span>上是<span class="_ _2"></span>数</div><div class="t m0 x0 h6 y408 ff5 fs3 fc0 sc0 ls0 ws0">据经过转换后<span class="_ _2"></span>，特征之间相<span class="_ _2"></span>关性较低<span class="_ _2"></span>，所有特征具<span class="_ _2"></span>有相同的方差</div><div class="t m0 x0 h5 y409 ff5 fs3 fc0 sc0 ls0 ws0">（协方差阵为<span class="_ _4"> </span><span class="ff4">1<span class="_ _4"> </span></span>）。首先<span class="_ _2"></span>对数据进<span class="_ _2"></span>行<span class="_ _4"> </span><span class="ff4">Mean<span class="_ _4"> </span>Subtraction<span class="_ _4"> </span></span>处</div></div><div class="c x27 y3 w9 hf"><div class="t m0 x28 h11 y40a ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _10"> </span><span class="ff10 fs1">↑<span class="_ _17"></span><span class="ffc">Figure<span class="_ _7"> </span>13:<span class="_ _8"> </span>The<span class="_ _8"> </span>response<span class="_ _8"> </span>of<span class="_ _7"> </span>a</span></span></div><div class="t m0 x28 h12 y40b ffc fs1 fc0 sc0 ls0 ws0">ReLU<span class="_ _0"> </span>nonlinearity<span class="_ _11"> </span><span class="ffb">【<span class="_ _11"> </span>图<span class="_ _21"> </span></span>13:ReL<span class="_ _2"></span>U</div><div class="t m0 x28 h13 y40c ffb fs1 fc0 sc0 ls0 ws0">非线性的响<span class="_ _2"></span>应】</div><div class="t m0 x28 h11 y40d ffa fs6 fc0 sc0 ls0 ws0">❐<span class="_ _10"> </span><span class="ff10 fs1">↑<span class="_ _17"></span><span class="ffc">Figure<span class="_ _7"> </span>14:<span class="_ _8"> </span>The<span class="_ _8"> </span>response<span class="_ _8"> </span>of<span class="_ _7"> </span>a</span></span></div><div class="t m0 x28 h12 y40e ffc fs1 fc0 sc0 ls0 ws0">leaky<span class="_ _15"> </span>ReL<span class="_ _2"></span>U<span class="_ _15"> </span>nonlinea<span class="_ _2"></span>rity<span class="_ _12"></span><span class="ffb">【<span class="_ _17"> </span>图<span class="_ _5"> </span></span>14<span class="_ _12"></span><span class="ffb">：</span></div><div class="t m0 x28 h12 y40f ffb fs1 fc0 sc0 ls0 ws0">泄漏<span class="_ _10"> </span><span class="ffc">ReLU </span>非线性的响<span class="_ _2"></span>应】</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf11" class="pf w0 h0" data-page-no="11"><div class="pc pc11 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg11.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">理<span class="_ _6"></span>，<span class="_ _6"></span>得<span class="_ _6"></span>到</div><div class="t m0 x53 h15 y112 ffe fs3 fc0 sc0 ls0 ws0">X&apos;</div><div class="t m0 x7d h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">。<span class="_ _6"></span>然<span class="_ _6"></span>后<span class="_ _6"></span>我<span class="_ _6"></span>们<span class="_ _12"></span>对</div><div class="t m0 x75 h15 y112 ffe fs3 fc0 sc0 ls0 ws0">X&apos;</div><div class="t m0 x46 h6 y111 ff5 fs3 fc0 sc0 ls0 ws0">进<span class="_ _6"></span>行<span class="_ _6"></span>奇<span class="_ _6"></span>异<span class="_ _6"></span>值<span class="_ _12"></span>分<span class="_ _6"></span>解<span class="_ _12"></span>得<span class="_ _6"></span>到<span class="_ _6"></span>矩<span class="_ _6"></span>阵</div><div class="t m0 xbb h15 y112 ffe fs3 fc0 sc0 ls0 ws0">U</div><div class="t m0 x77 h5 y111 ff4 fs3 fc0 sc0 ls0 ws0">,</div><div class="t m0 xc2 h15 y112 ffe fs3 fc0 sc0 ls0 ws0">S</div><div class="t m0 xc4 h5 y111 ff4 fs3 fc0 sc0 ls0 ws0">,</div><div class="t m0 x0 h15 y36d ffe fs3 fc0 sc0 ls0 ws0">V</div><div class="t m0 x2e h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">，<span class="_ _2"></span>计<span class="_ _2"></span>算</div><div class="t m0 x6d h15 y36d ffe fs3 fc0 sc0 ls0 ws0">UX&apos;</div><div class="t m0 xab h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">将</div><div class="t m0 x1e h15 y36d ffe fs3 fc0 sc0 ls0 ws0">X&apos;</div><div class="t m0 x69 h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">投<span class="_ _2"></span>影<span class="_ _2"></span>到<span class="_ _2"></span>由</div><div class="t m0 x9f h15 y36d ffe fs3 fc0 sc0 ls0 ws0">U</div><div class="t m0 x3f h6 y113 ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>列<span class="_ _2"></span>定<span class="_ _2"></span>义<span class="_ _2"></span>的<span class="_ _2"></span>基<span class="_ _2"></span>上<span class="_ _6"></span>。<span class="_ _2"></span>我<span class="_ _2"></span>们<span class="_ _2"></span>最<span class="_ _2"></span>后<span class="_ _2"></span>将<span class="_ _6"></span>结</div><div class="t m0 x0 h6 y324 ff5 fs3 fc0 sc0 ls0 ws0">果的每个维<span class="_ _2"></span>度除以</div><div class="t m0 x18 h15 y325 ffe fs3 fc0 sc0 ls0 ws0">S</div><div class="t m0 x4e h6 y324 ff5 fs3 fc0 sc0 ls0 ws0">中的相应奇<span class="_ _2"></span>异值，从而适<span class="_ _2"></span>当地缩放<span class="_ _2"></span>我们的数</div><div class="t m0 x0 h5 y5 ff5 fs3 fc0 sc0 ls0 ws0">据<span class="_ _17"> </span>（<span class="_ _17"></span>如<span class="_ _17"></span>果<span class="_ _17"></span>其<span class="_ _17"></span>中<span class="_ _17"></span>有<span class="_ _12"></span>奇<span class="_ _17"> </span>异<span class="_ _17"> </span>值<span class="_ _17"> </span>为 <span class="ff4">0<span class="_ _0"> </span></span>，<span class="_ _17"></span>我<span class="_ _17"></span>们<span class="_ _17"></span>就<span class="_ _12"></span>除<span class="_ _11"> </span>以<span class="_ _17"></span>一<span class="_ _17"></span>个<span class="_ _17"></span>很<span class="_ _12"></span>小<span class="_ _17"> </span>的<span class="_ _17"> </span>值<span class="_ _17"> </span>代</div><div class="t m0 x0 h6 y327 ff5 fs3 fc0 sc0 ls0 ws0">替）。</div><div class="t m0 x0 h14 y410 ffd fs0 fc0 sc0 ls0 ws0">2.6<span class="_ _15"> </span>Parameter<span class="_ _15"> </span>Initialization</div><div class="t m0 x0 h6 y411 ff5 fs3 fc0 sc0 ls0 ws0">让<span class="_ _2"></span>神<span class="_ _6"></span>经<span class="_ _6"></span>网<span class="_ _2"></span>络<span class="_ _6"></span>实<span class="_ _6"></span>现<span class="_ _6"></span>最<span class="_ _2"></span>佳<span class="_ _6"></span>性<span class="_ _6"></span>能<span class="_ _6"></span>的<span class="_ _2"></span>关<span class="_ _6"></span>键<span class="_ _6"></span>一<span class="_ _2"></span>步<span class="_ _6"></span>是<span class="_ _6"></span>以<span class="_ _6"></span>合<span class="_ _2"></span>理<span class="_ _6"></span>的<span class="_ _6"></span>方<span class="_ _2"></span>式<span class="_ _6"></span>初<span class="_ _6"></span>始<span class="_ _6"></span>化<span class="_ _2"></span>参</div><div class="t m0 x0 h5 y2a6 ff5 fs3 fc0 sc0 ls0 ws0">数<span class="_ _2"></span>。<span class="_ _6"></span>一<span class="_ _2"></span>个<span class="_ _2"></span>好<span class="_ _6"></span>的<span class="_ _2"></span>起<span class="_ _6"></span>始<span class="_ _6"></span>方<span class="_ _2"></span>法<span class="_ _6"></span>是<span class="_ _2"></span>将<span class="_ _2"></span>权<span class="_ _6"></span>值<span class="_ _2"></span>初<span class="_ _6"></span>始<span class="_ _6"></span>化<span class="_ _2"></span>为<span class="_ _6"></span>通<span class="_ _2"></span>常<span class="_ _2"></span>分<span class="_ _6"></span>布<span class="_ _2"></span>在<span class="_ _8"> </span><span class="ff4">0<span class="_ _15"> </span></span>附<span class="_ _2"></span>近<span class="_ _6"></span>的</div><div class="t m0 x0 h5 yc8 ff5 fs3 fc0 sc0 ls0 ws0">很<span class="_ _6"></span>小<span class="_ _6"></span>的<span class="_ _6"></span>随<span class="_ _6"></span>机<span class="_ _6"></span>数<span class="_ _6"></span><span class="ff4">-<span class="_ _12"></span></span>在<span class="_ _6"></span>实<span class="_ _6"></span>践<span class="_ _6"></span>中<span class="_ _6"></span>效<span class="_ _6"></span>果<span class="_ _6"></span>还<span class="_ _12"></span>不<span class="_ _2"></span>错<span class="_ _12"></span>。<span class="_ _6"></span>在<span class="_ _6"></span>论<span class="_ _6"></span>文<span class="_ _16"> </span><span class="ff4">Understanding</span></div><div class="t m0 x0 h5 y412 ff4 fs3 fc0 sc0 ls0 ws0">the<span class="_ _8"> </span>difficu<span class="_ _2"></span>lty<span class="_ _0"> </span>of<span class="_ _8"> </span>train<span class="_ _2"></span>ing<span class="_ _0"> </span>deep<span class="_ _8"> </span>feed<span class="_ _2"></span>forward<span class="_ _0"> </span>neural<span class="_ _0"> </span>networks</div><div class="t m0 x0 h5 y413 ff4 fs3 fc0 sc0 ls0 ws0">(2010),<span class="_ _0"> </span>Xavier<span class="_ _0"> </span><span class="ff5">研<span class="_ _17"></span>究<span class="_ _12"></span>不<span class="_ _17"> </span>同<span class="_ _17"></span>权<span class="_ _12"></span>值<span class="_ _17"> </span>和<span class="_ _17"> </span>偏<span class="_ _17"></span>置<span class="_ _17"></span>初<span class="_ _12"></span>始<span class="_ _17"> </span>化<span class="_ _17"></span>方<span class="_ _12"></span>案<span class="_ _17"> </span>对<span class="_ _17"> </span>训<span class="_ _17"></span>练<span class="_ _17"></span>动<span class="_ _12"></span>力</span></div><div class="t m0 x0 h5 y414 ff5 fs3 fc0 sc0 ls0 ws0">（<span class="_ _15"> </span><span class="ff4">tra<span class="_ _2"></span>ining<span class="_ _15"> </span>dynamics<span class="_ _15"> </span></span>）<span class="_ _2"></span>的<span class="_ _6"></span>影<span class="_ _2"></span>响<span class="_ _2"></span>。<span class="_ _2"></span>实<span class="_ _6"></span>验结<span class="_ _6"></span>果<span class="_ _2"></span>表<span class="_ _2"></span>明<span class="_ _2"></span>，<span class="_ _6"></span>对<span class="_ _2"></span>于<span class="_ _7"> </span><span class="ff4">sigmoid</span></div><div class="t m0 x0 h5 y415 ff5 fs3 fc0 sc0 ls0 ws0">和<span class="_ _15"> </span><span class="ff4">ta<span class="_ _2"></span>nh<span class="_ _15"> </span></span>激<span class="_ _2"></span>活<span class="_ _6"></span>单<span class="_ _2"></span>元<span class="_ _2"></span>，<span class="_ _6"></span>当<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _2"></span>权<span class="_ _6"></span>值<span class="_ _2"></span>矩<span class="_ _2"></span>阵</div><div class="t m0 x5d h15 y416 ffe fs3 fc0 sc0 ls0 ws0">W<span class="_ _4"></span>∈<span class="_ _15"></span>ℝ</div><div class="t m0 x2d h16 y417 ffe fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x34 h22 y418 ffe fsb fc0 sc0 ls0 ws0">(l+1)</div><div class="t m0 x2b h16 y419 ffe fs7 fc0 sc0 ls0 ws0">×</div><div class="t m0 x68 h16 y417 ffe fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x5 h22 y418 ffe fsb fc0 sc0 ls0 ws0">(l)</div><div class="t m0 x85 h6 y415 ff5 fs3 fc0 sc0 ls0 ws0">以<span class="_ _2"></span>如<span class="_ _2"></span>下<span class="_ _6"></span>的<span class="_ _2"></span>均</div><div class="t m0 x0 h6 y41a ff5 fs3 fc0 sc0 ls0 ws0">匀分布的方式<span class="_ _2"></span>随机初始化，<span class="_ _2"></span>能够实现<span class="_ _2"></span>更快的收敛和<span class="_ _2"></span>得到更低的误</div><div class="t m0 x0 h6 y41b ff5 fs3 fc0 sc0 ls0 ws0">差：</div><div class="t m0 x7d h15 y164 ffe fs3 fc0 sc0 ls0 ws0">W<span class="_ _4"></span>∼<span class="_ _7"></span>U<span class="_ _16"> </span>−</div><div class="t m0 x41 h15 y28c ffe fs3 fc0 sc0 ls0 ws0">6</div><div class="t m0 x45 h15 y41c ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 x48 h16 y41d ffe fs7 fc0 sc0 ls0 ws0">(l)</div><div class="t m0 x88 h15 y41e ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span>n</div><div class="t m0 x59 h16 y41d ffe fs7 fc0 sc0 ls0 ws0">(l+1)</div><div class="t m0 xa8 h15 y164 ffe fs3 fc0 sc0 ls0 ws0">,</div><div class="t m0 x55 h15 y28c ffe fs3 fc0 sc0 ls0 ws0">6</div><div class="t m0 xac h15 y41c ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 x40 h16 y41d ffe fs7 fc0 sc0 ls0 ws0">(l)</div><div class="t m0 xb3 h15 y41e ffe fs3 fc0 sc0 ls0 ws0">+<span class="_ _3"></span>n</div><div class="t m0 xb h16 y41d ffe fs7 fc0 sc0 ls0 ws0">(l+1)</div><div class="t m0 x0 h6 y41f ff5 fs3 fc0 sc0 ls0 ws0">其<span class="_ _2"></span>中</div><div class="t m0 x58 h15 y420 ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 xaf h16 y421 ffe fs7 fc0 sc0 ls0 ws0">(l)</div><div class="t m0 xc5 h6 y41f ff5 fs3 fc0 sc0 ls0 ws0">是</div><div class="t m0 xb7 h15 y420 ffe fs3 fc0 sc0 ls0 ws0">W(fan<span class="_ _3"></span>−<span class="_ _3"></span>in)</div><div class="t m0 x45 h6 y41f ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _2"></span>输<span class="_ _6"></span>入<span class="_ _2"></span>单<span class="_ _6"></span>元<span class="_ _6"></span>数<span class="_ _2"></span>，</div><div class="t m0 x95 h15 y420 ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 x51 h16 y421 ffe fs7 fc0 sc0 ls0 ws0">(l+1)</div><div class="t m0 x2b h6 y41f ff5 fs3 fc0 sc0 ls0 ws0">是</div><div class="t m0 xa9 h15 y420 ffe fs3 fc0 sc0 ls0 ws0">W(fan<span class="_ _3"></span>−<span class="_ _3"></span>out)</div><div class="t m0 x0 h6 y128 ff5 fs3 fc0 sc0 ls0 ws0">的输出单元数<span class="_ _2"></span>。在这个参数<span class="_ _2"></span>初始化方<span class="_ _2"></span>案中，偏置单<span class="_ _2"></span>元是初始化为</div><div class="t m0 x0 h5 y422 ff4 fs3 fc0 sc0 ls0 ws0">0<span class="_ _4"> </span><span class="ff5">。这种方<span class="_ _2"></span>法是<span class="_ _2"></span>尝试保<span class="_ _2"></span>持跨层<span class="_ _2"></span>之间<span class="_ _2"></span>的激活<span class="_ _2"></span>方差<span class="_ _2"></span>以及<span class="_ _2"></span>反向传播<span class="_ _2"></span>梯度</span></div><div class="t m0 x0 h6 y423 ff5 fs3 fc0 sc0 ls0 ws0">方差。如果没<span class="_ _2"></span>有这样的初始<span class="_ _2"></span>化，梯度<span class="_ _2"></span>方差（当中含<span class="_ _2"></span>有纠正信息）</div><div class="t m0 x0 h6 y424 ff5 fs3 fc0 sc0 ls0 ws0">通常随着跨层<span class="_ _2"></span>的反向传播而<span class="_ _2"></span>衰减。</div><div class="t m0 x0 h14 y1c5 ffd fs0 fc0 sc0 ls0 ws0">2.7<span class="_ _15"> </span>Learning<span class="_ _15"> </span>Strategies</div><div class="t m0 x0 h5 y425 ff5 fs3 fc0 sc0 ls0 ws0">训练<span class="_ _6"></span>期<span class="_ _2"></span>间<span class="_ _2"></span>模<span class="_ _2"></span>型<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _2"></span>更<span class="_ _2"></span>新<span class="_ _2"></span>的<span class="_ _6"></span>速率<span class="_ _2"></span><span class="ff4">/<span class="_ _2"></span></span>幅<span class="_ _2"></span>度<span class="_ _2"></span>可<span class="_ _2"></span>以<span class="_ _6"></span>使<span class="_ _2"></span>用学<span class="_ _6"></span>习<span class="_ _2"></span>率<span class="_ _2"></span>进<span class="_ _2"></span>行<span class="_ _2"></span>控<span class="_ _2"></span>制<span class="_ _2"></span>。</div><div class="t m0 x0 h6 y426 ff5 fs3 fc0 sc0 ls0 ws0">在最简单的梯<span class="_ _2"></span>度下降公式中<span class="_ _2"></span>，</div><div class="t m0 x4a h15 y427 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x59 h6 y426 ff5 fs3 fc0 sc0 ls0 ws0">是学习率：</div><div class="t m0 x92 h15 y428 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x3a h16 y429 ffe fs7 fc0 sc0 ls0 ws0">new</div><div class="t m0 x48 h15 y428 ffe fs3 fc0 sc0 ls0 ws0">=<span class="_ _4"></span>θ</div><div class="t m0 x49 h16 y429 ffe fs7 fc0 sc0 ls0 ws0">old</div><div class="t m0 x57 h15 y428 ffe fs3 fc0 sc0 ls0 ws0">−<span class="_ _3"></span>α∇</div><div class="t m0 x5d h16 y42a ffe fs7 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x42 h15 y428 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x78 h16 y42a ffe fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x11 h15 y428 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x0 h6 y42b ff5 fs3 fc0 sc0 ls0 ws0">你<span class="_ _2"></span>可<span class="_ _6"></span>能<span class="_ _2"></span>会<span class="_ _6"></span>认<span class="_ _2"></span>为<span class="_ _2"></span>如<span class="_ _6"></span>果<span class="_ _6"></span>要<span class="_ _2"></span>更<span class="_ _6"></span>快<span class="_ _2"></span>地<span class="_ _6"></span>收<span class="_ _2"></span>敛<span class="_ _6"></span>，<span class="_ _2"></span>我<span class="_ _6"></span>们<span class="_ _2"></span>应<span class="_ _6"></span>该<span class="_ _2"></span>对</div><div class="t m0 x2b h15 y42c ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 xd h6 y42b ff5 fs3 fc0 sc0 ls0 ws0">取<span class="_ _2"></span>一<span class="_ _6"></span>个<span class="_ _2"></span>较<span class="_ _6"></span>大<span class="_ _2"></span>的</div><div class="t m0 x0 h5 y42d ff5 fs3 fc0 sc0 ls0 ws0">值<span class="ff4">——</span>然而<span class="_ _2"></span>，在更快的收<span class="_ _2"></span>敛速度下<span class="_ _2"></span>并不能保证更<span class="_ _2"></span>快的收敛<span class="_ _2"></span>。实际</div><div class="t m0 x0 h6 y42e ff5 fs3 fc0 sc0 ls0 ws0">上，如果学习<span class="_ _2"></span>率非常高，我<span class="_ _2"></span>们可能会<span class="_ _2"></span>遇到损失函数<span class="_ _2"></span>难以收敛的情</div><div class="t m0 x0 h6 y42f ff5 fs3 fc0 sc0 ls0 ws0">况<span class="_ _2"></span>，<span class="_ _6"></span>因<span class="_ _6"></span>为<span class="_ _2"></span>参<span class="_ _6"></span>数<span class="_ _6"></span>更<span class="_ _6"></span>新<span class="_ _2"></span>幅<span class="_ _6"></span>度<span class="_ _6"></span>过<span class="_ _6"></span>大<span class="_ _2"></span>，<span class="_ _6"></span>会<span class="_ _6"></span>导<span class="_ _2"></span>致<span class="_ _6"></span>模<span class="_ _6"></span>型<span class="_ _6"></span>越<span class="_ _2"></span>过<span class="_ _6"></span>凸<span class="_ _6"></span>优<span class="_ _2"></span>化<span class="_ _6"></span>的<span class="_ _6"></span>极<span class="_ _6"></span>小<span class="_ _2"></span>值</div><div class="t m0 x0 h6 y430 ff5 fs3 fc0 sc0 ls0 ws0">点，如右图<span class="_ _2"></span>所示。在非凸<span class="_ _2"></span>模型中（<span class="_ _2"></span>我们很多时候<span class="_ _2"></span>遇到的模<span class="_ _2"></span>型都是</div><div class="t m0 x0 h6 y431 ff5 fs3 fc0 sc0 ls0 ws0">非凸），高学<span class="_ _2"></span>习率的结果是<span class="_ _2"></span>难以预测<span class="_ _2"></span>的，但是损失<span class="_ _2"></span>函数难以收敛</div><div class="t m0 x0 h6 y432 ff5 fs3 fc0 sc0 ls0 ws0">的可能性是非<span class="_ _2"></span>常高的。</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h11 y433 ffa fs6 fc0 sc0 ls0 ws0">❐</div><div class="t m0 x91 h1f y434 ff10 fs1 fc0 sc0 ls0 ws0">↑</div><div class="t m0 x8 h12 y433 ffc fs1 fc0 sc0 ls0 ws0">Figure<span class="_ _13"> </span>15:<span class="_ _13"> </span>Here<span class="_ _13"> </span>we<span class="_ _13"> </span>s<span class="_ _2"></span>ee<span class="_ _13"> </span>that</div><div class="t m0 x28 h12 y435 ffc fs1 fc0 sc0 ls0 ws0">updating<span class="_ _10"> </span>parameter<span class="_ _14"> </span>w2<span class="_ _10"> </span>with<span class="_ _14"> </span>a<span class="_ _10"> </span>large</div><div class="t m0 x28 h12 y436 ffc fs1 fc0 sc0 ls0 ws0">learning<span class="_ _13"> </span>rate<span class="_ _13"> </span>can<span class="_ _0"> </span>l<span class="_ _2"></span>ead<span class="_ _0"> </span>to<span class="_ _13"> </span>divergence</div><div class="t m0 x28 h12 y437 ffc fs1 fc0 sc0 ls0 ws0">of the<span class="_ _3"> </span>error.<span class="_ _2"></span><span class="ffb">【图<span class="_ _19"> </span></span>15<span class="ffb">：<span class="_ _2"></span>在<span class="_ _2"></span>这里<span class="_ _2"></span>，我<span class="_ _2"></span>们</span></div><div class="t m0 x28 h12 y438 ffb fs1 fc0 sc0 ls0 ws0">看<span class="_ _6"></span>到<span class="_ _12"></span>用<span class="_ _12"></span>大<span class="_ _6"></span>的<span class="_ _12"></span>学<span class="_ _6"></span>习<span class="_ _12"></span>率<span class="_ _12"></span>更<span class="_ _12"></span>新<span class="_ _6"></span>参<span class="_ _12"></span>数<span class="_ _5"> </span><span class="ffc">w2<span class="_ _4"> </span></span>会</div><div class="t m0 x28 h13 y439 ffb fs1 fc0 sc0 ls0 ws0">导致错误的<span class="_ _2"></span>发散。】</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf12" class="pf w0 h0" data-page-no="12"><div class="pc pc12 w0 h0"><img class="bi xa y0 wa hd" alt="" src="bg12.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 hf"><div class="t m0 x0 h6 yba ff5 fs3 fc0 sc0 ls0 ws0">避免损失函数<span class="_ _2"></span>难以收敛的一<span class="_ _2"></span>个简答的<span class="_ _2"></span>解决方法是使<span class="_ _2"></span>用一个很小的</div><div class="t m0 x0 h5 ybc ff5 fs3 fc0 sc0 ls0 ws0">学习率，让模<span class="_ _2"></span>型谨慎地在参<span class="_ _2"></span>数空间中<span class="_ _2"></span>迭代<span class="ff4">——</span>当然<span class="_ _2"></span>，如果我<span class="_ _2"></span>们使</div><div class="t m0 x0 h6 ybd ff5 fs3 fc0 sc0 ls0 ws0">用<span class="_ _2"></span>了<span class="_ _6"></span>一<span class="_ _6"></span>个<span class="_ _2"></span>太<span class="_ _6"></span>小<span class="_ _6"></span>的<span class="_ _6"></span>学<span class="_ _2"></span>习<span class="_ _6"></span>率<span class="_ _6"></span>，<span class="_ _6"></span>损<span class="_ _2"></span>失<span class="_ _6"></span>函<span class="_ _6"></span>数<span class="_ _2"></span>可<span class="_ _6"></span>能<span class="_ _6"></span>不<span class="_ _6"></span>会<span class="_ _2"></span>在<span class="_ _6"></span>合<span class="_ _6"></span>理<span class="_ _2"></span>的<span class="_ _6"></span>时<span class="_ _6"></span>间<span class="_ _6"></span>内<span class="_ _2"></span>收</div><div class="t m0 x0 h6 ybf ff5 fs3 fc0 sc0 ls0 ws0">敛，或者会困<span class="_ _2"></span>在局部最优点<span class="_ _2"></span>。因此，<span class="_ _2"></span>与任何其他超<span class="_ _2"></span>参数一样，学</div><div class="t m0 x0 h6 yc0 ff5 fs3 fc0 sc0 ls0 ws0">习率必须有效<span class="_ _2"></span>地调整。</div><div class="t m0 x0 h6 y43a ff5 fs3 fc0 sc0 ls0 ws0">深度学习系统<span class="_ _2"></span>中最消耗计算<span class="_ _2"></span>资源的是<span class="_ _2"></span>训练阶段，一<span class="_ _2"></span>些研究已在尝</div><div class="t m0 x0 h5 y390 ff5 fs3 fc0 sc0 ls0 ws0">试<span class="_ _2"></span>提<span class="_ _6"></span>升<span class="_ _6"></span>设<span class="_ _6"></span>置<span class="_ _6"></span>学<span class="_ _6"></span>习<span class="_ _2"></span>率<span class="_ _12"></span>的<span class="_ _2"></span>新<span class="_ _6"></span>方<span class="_ _6"></span>法<span class="_ _6"></span>。<span class="_ _6"></span>例<span class="_ _6"></span>如<span class="_ _6"></span>，<span class="_ _8"> </span><span class="ff4">Ronan<span class="_ _15"> </span>Collobert<span class="_ _7"> </span></span>通<span class="_ _6"></span>过<span class="_ _6"></span>取</div><div class="t m0 x0 h15 y26 ffe fs3 fc0 sc0 ls0 ws0">fan<span class="_ _3"></span>−<span class="_ _3"></span>in</div><div class="t m0 x72 h6 y34e ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _6"></span>神<span class="_ _6"></span>经<span class="_ _12"></span>元</div><div class="t m0 x18 h15 y26 ffe fs3 fc0 sc0 ls0 ws0">(n</div><div class="t m0 x92 h16 y43b ffe fs7 fc0 sc0 ls0 ws0">(l)</div><div class="t m0 x9 h15 y26 ffe fs3 fc0 sc0 ls0 ws0">)</div><div class="t m0 x45 h6 y34e ff5 fs3 fc0 sc0 ls0 ws0">的<span class="_ _6"></span>平<span class="_ _6"></span>方<span class="_ _12"></span>根<span class="_ _6"></span>的<span class="_ _12"></span>倒<span class="_ _6"></span>数<span class="_ _6"></span>来<span class="_ _12"></span>缩<span class="_ _6"></span>放<span class="_ _6"></span>权<span class="_ _12"></span>值</div><div class="t m0 xc6 h15 y26 ffe fs3 fc0 sc0 ls0 ws0">W</div><div class="t m0 x89 h16 y43c ffe fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xb5 h5 y34e ff4 fs3 fc0 sc0 ls0 ws0">(</div><div class="t m0 x77 h15 y26 ffe fs3 fc0 sc0 ls0 ws0">W<span class="_ _4"></span>∈</div><div class="t m0 x0 h15 y34f ffe fs3 fc0 sc0 ls0 ws0">ℝ</div><div class="t m0 x91 h16 y43d ffe fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x2a h22 y43e ffe fsb fc0 sc0 ls0 ws0">(l+1)</div><div class="t m0 x71 h16 y43d ffe fs7 fc0 sc0 ls0 ws0">×n</div><div class="t m0 x66 h22 y43e ffe fsb fc0 sc0 ls0 ws0">(l)</div><div class="t m0 xc5 h5 y34f ff4 fs3 fc0 sc0 ls0 ws0">)<span class="_ _4"> </span><span class="ff5">的学习率。</span></div><div class="t m0 x0 h5 y43f ff5 fs3 fc0 sc0 ls0 ws0">还有<span class="_ _2"></span>其<span class="_ _6"></span>他已<span class="_ _2"></span>经<span class="_ _2"></span>被<span class="_ _6"></span>证明<span class="_ _2"></span>有<span class="_ _2"></span>效<span class="_ _6"></span>的技<span class="_ _2"></span>术<span class="_ _2"></span><span class="ff4">-<span class="_ _2"></span></span>这<span class="_ _2"></span>个<span class="_ _2"></span>方<span class="_ _6"></span>法叫<span class="_ _15"> </span><span class="ff4">ann<span class="_ _2"></span>ealing<span class="_ _15"> </span></span>退<span class="_ _2"></span>火<span class="_ _2"></span>，</div><div class="t m0 x0 h6 y440 ff5 fs3 fc0 sc0 ls0 ws0">在多次迭代之<span class="_ _2"></span>后，学习率以<span class="_ _2"></span>以下方式<span class="_ _2"></span>降低：保证以<span class="_ _2"></span>一个高的的学</div><div class="t m0 x0 h6 y441 ff5 fs3 fc0 sc0 ls0 ws0">习率开始训练<span class="_ _2"></span>和快速逼近最<span class="_ _2"></span>小值；当<span class="_ _2"></span>越来越接近最<span class="_ _2"></span>小值时，开始</div><div class="t m0 x0 h6 y442 ff5 fs3 fc0 sc0 ls0 ws0">降低学习率，<span class="_ _2"></span>让我们可以在<span class="_ _2"></span>更细微的<span class="_ _2"></span>范围内找到最<span class="_ _2"></span>优值。一个常</div><div class="t m0 x0 h5 y443 ff5 fs3 fc0 sc0 ls0 ws0">见<span class="_ _2"></span>的<span class="_ _6"></span>实<span class="_ _6"></span>现<span class="_ _8"> </span><span class="ff4">annealing<span class="_ _15"> </span></span>的<span class="_ _6"></span>方<span class="_ _6"></span>法<span class="_ _6"></span>是<span class="_ _6"></span>在<span class="_ _2"></span>每</div><div class="t m0 xa8 h15 y444 ffe fs3 fc0 sc0 ls0 ws0">n</div><div class="t m0 x47 h6 y443 ff5 fs3 fc0 sc0 ls0 ws0">次<span class="_ _2"></span>的<span class="_ _6"></span>迭<span class="_ _6"></span>代<span class="_ _6"></span>学<span class="_ _2"></span>习<span class="_ _6"></span>后<span class="_ _6"></span>，<span class="_ _6"></span>通<span class="_ _6"></span>过<span class="_ _2"></span>一</div><div class="t m0 x0 h15 y445 ff5 fs3 fc0 sc0 ls0 ws0">个因子<span class="_ _4"> </span><span class="ffe">x<span class="_ _4"></span></span>来降低学习率</div><div class="t m0 x7c h15 y446 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x9e h6 y445 ff5 fs3 fc0 sc0 ls0 ws0">。</div><div class="t m0 x0 h15 y447 ff5 fs3 fc0 sc0 ls0 ws0">指<span class="_ _2"></span>数<span class="_ _6"></span>衰<span class="_ _6"></span>减<span class="_ _6"></span>也<span class="_ _6"></span>是<span class="_ _6"></span>很<span class="_ _6"></span>常<span class="_ _6"></span>见<span class="_ _2"></span>的<span class="_ _6"></span>方<span class="_ _6"></span>法<span class="_ _6"></span>，<span class="_ _6"></span>在<span class="_ _8"> </span><span class="ffe">t<span class="_ _8"></span></span>次<span class="_ _6"></span>迭<span class="_ _2"></span>代<span class="_ _12"></span>后<span class="_ _2"></span>学<span class="_ _6"></span>习<span class="_ _6"></span>率<span class="_ _6"></span>变<span class="_ _6"></span>为<span class="_ _8"> </span><span class="ffe">α(t)<span class="_ _4"></span>=</span></div><div class="t m0 x0 h15 y83 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x29 h16 y448 ffe fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x2e h15 y449 ffe fs3 fc0 sc0 ls0 ws0">e</div><div class="t m0 x8 h16 y44a ffe fs7 fc0 sc0 ls0 ws0">−kt</div><div class="t m0 xaf h6 y83 ff5 fs3 fc0 sc0 ls0 ws0">，其中</div><div class="t m0 x73 h15 y449 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x98 h16 y448 ffe fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x17 h6 y83 ff5 fs3 fc0 sc0 ls0 ws0">是初始的学习<span class="_ _2"></span>率和</div><div class="t m0 x21 h15 y449 ffe fs3 fc0 sc0 ls0 ws0">k</div><div class="t m0 x5d h6 y83 ff5 fs3 fc0 sc0 ls0 ws0">是超参数。</div><div class="t m0 x0 h6 y44b ff5 fs3 fc0 sc0 ls0 ws0">还有另外一种<span class="_ _2"></span>方法是允许学<span class="_ _2"></span>习率随着<span class="_ _2"></span>时间减少：</div><div class="t m0 x8f h15 y44c ffe fs3 fc0 sc0 ls0 ws0">α(t)<span class="_ _4"></span>=</div><div class="t m0 x39 h15 y44d ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x32 h16 y44e ffe fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa8 h15 y44d ffe fs3 fc0 sc0 ls0 ws0">τ</div><div class="t m0 x3f h15 y44f ffe fs3 fc0 sc0 ls0 ws0">max(t,<span class="_ _1"></span>τ)</div><div class="t m0 x0 h6 y450 ff5 fs3 fc0 sc0 ls0 ws0">在上<span class="_ _2"></span>述<span class="_ _2"></span>的<span class="_ _2"></span>方<span class="_ _2"></span>案<span class="_ _2"></span>中<span class="_ _2"></span>，</div><div class="t m0 x69 h15 y451 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x4e h16 y424 ffe fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x26 h6 y450 ff5 fs3 fc0 sc0 ls0 ws0">是一<span class="_ _2"></span>个<span class="_ _2"></span>可<span class="_ _2"></span>调<span class="_ _2"></span>的<span class="_ _2"></span>参<span class="_ _2"></span>数<span class="_ _2"></span>，<span class="_ _2"></span>代<span class="_ _2"></span>表<span class="_ _2"></span>起<span class="_ _2"></span>始的<span class="_ _2"></span>学<span class="_ _2"></span>习<span class="_ _2"></span>率<span class="_ _2"></span>。</div><div class="t m0 x0 h15 y452 ffe fs3 fc0 sc0 ls0 ws0">τ<span class="_ _4"></span><span class="ff5">也是<span class="_ _2"></span>一<span class="_ _2"></span>个可<span class="_ _2"></span>调参<span class="_ _2"></span>数<span class="_ _2"></span>，表<span class="_ _2"></span>示学<span class="_ _2"></span>习<span class="_ _2"></span>率应该<span class="_ _2"></span>在<span class="_ _2"></span>该<span class="_ _2"></span>时间点<span class="_ _2"></span>开<span class="_ _2"></span>始减<span class="_ _2"></span>少。<span class="_ _2"></span>在</span></div><div class="t m0 x0 h6 y453 ff5 fs3 fc0 sc0 ls0 ws0">实际中，这个<span class="_ _2"></span>方法是很有效<span class="_ _2"></span>的。在下<span class="_ _2"></span>一部分我们讨<span class="_ _2"></span>论另外一种不</div><div class="t m0 x0 h6 y454 ff5 fs3 fc0 sc0 ls0 ws0">需要手动设定<span class="_ _2"></span>学习率的自适<span class="_ _2"></span>应梯度下<span class="_ _2"></span>降的方法。</div><div class="t m0 x0 h14 y138 ffd fs0 fc0 sc0 ls0 ws0">2.8<span class="_ _4"> </span>Momentum<span class="_ _7"> </span>Updates</div><div class="t m0 x0 h6 y455 ff5 fs3 fc0 sc0 ls0 ws0">动量方法，灵<span class="_ _2"></span>感来自于物理<span class="_ _2"></span>学中的对<span class="_ _2"></span>动力学的研究<span class="_ _2"></span>，是梯度下降</div><div class="t m0 x0 h5 y456 ff5 fs3 fc0 sc0 ls0 ws0">方<span class="_ _2"></span>法<span class="_ _2"></span>的<span class="_ _2"></span>一<span class="_ _2"></span>种<span class="_ _6"></span>变<span class="_ _2"></span>体<span class="_ _2"></span>，<span class="_ _2"></span>尝<span class="_ _6"></span>试<span class="_ _2"></span>使<span class="_ _2"></span>用<span class="_ _2"></span>更<span class="_ _6"></span>新<span class="_ _2"></span>的<span class="_ _2"></span><span class="ff4">“<span class="_ _2"></span></span>速<span class="_ _6"></span>度<span class="_ _2"></span><span class="ff4">”<span class="_ _2"></span></span>的<span class="_ _2"></span>一<span class="_ _6"></span>种更<span class="_ _6"></span>有<span class="_ _2"></span>效<span class="_ _2"></span>的<span class="_ _2"></span>更<span class="_ _6"></span>新</div><div class="t m0 x0 h6 y457 ff5 fs3 fc0 sc0 ls0 ws0">方案。动量更<span class="_ _2"></span>新的伪代码如<span class="_ _2"></span>下所示：</div></div><div class="c x0 y458 wb h2e"><div class="t m0 x7 h2f y459 ff15 fs4 fc0 sc0 ls0 ws0"># Computes a<span class="_ _5"> </span>s<span class="_ _2"></span>tandard momen<span class="_ _a"></span>tum update</div><div class="t m0 x7 h2f y45a ff15 fs4 fc0 sc0 ls0 ws0"># on parame<span class="_ _a"></span>ters x</div><div class="t m0 x7 h30 y45b ff16 fs4 fc0 sc0 ls0 ws0">v = mu * v -<span class="_ _5"> </span>a<span class="_ _2"></span>lpha * grad_<span class="_ _a"></span>x</div><div class="t m0 x7 h30 y45c ff16 fs4 fc0 sc0 ls0 ws0">x += v</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf13" class="pf w0 h0" data-page-no="13"><div class="pc pc13 w0 h0"><img class="bi xa y0 wa h1" alt="" src="bg13.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h14 y5e ffd fs0 fc0 sc0 ls0 ws0">2.9<span class="_ _15"> </span>Adaptive<span class="_ _15"> </span>Optimization<span class="_ _15"> </span>Methods</div><div class="t m0 x0 h5 y5f ff4 fs3 fc0 sc0 ls0 ws0">AdaGrad<span class="_ _7"> </span><span class="ff5">是<span class="_ _6"></span>标<span class="_ _2"></span>准<span class="_ _6"></span>的<span class="_ _6"></span>随<span class="_ _6"></span>机<span class="_ _6"></span>梯<span class="_ _6"></span>度<span class="_ _6"></span>下<span class="_ _2"></span>降<span class="_ _6"></span></span>(<span class="_ _7"> </span>SGD<span class="_ _15"> </span>)<span class="_ _6"></span><span class="ff5">的<span class="_ _6"></span>一<span class="_ _6"></span>种<span class="_ _2"></span>实<span class="_ _6"></span>现<span class="_ _6"></span>，<span class="_ _6"></span>但<span class="_ _6"></span>是<span class="_ _6"></span>有</span></div><div class="t m0 x0 h6 y61 ff5 fs3 fc0 sc0 ls0 ws0">一点关键的不<span class="_ _2"></span>同：对每个参<span class="_ _2"></span>数学习率<span class="_ _2"></span>是不同的。每<span class="_ _2"></span>个参数的学习</div><div class="t m0 x0 h6 y45d ff5 fs3 fc0 sc0 ls0 ws0">率取决于每个<span class="_ _2"></span>参数梯度更新<span class="_ _2"></span>的历史<span class="_ _2"></span>，参数的历史更<span class="_ _2"></span>新越小，<span class="_ _2"></span>就使</div><div class="t m0 x0 h6 y45e ff5 fs3 fc0 sc0 ls0 ws0">用更大的学习<span class="_ _2"></span>率加快更新。<span class="_ _2"></span>即，过<span class="_ _2"></span>去没有更新太<span class="_ _2"></span>大的参数<span class="_ _2"></span>，现在</div><div class="t m0 x0 h6 y45f ff5 fs3 fc0 sc0 ls0 ws0">更有可能有更<span class="_ _2"></span>高的学习率。</div><div class="t m0 x2f h15 y460 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x30 h16 y461 ffe fs7 fc0 sc0 ls0 ws0">t,i</div><div class="t m0 x14 h15 y181 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x6f h15 y460 ffe fs3 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x98 h16 y462 ffe fs7 fc0 sc0 ls0 ws0">t−1,i</div><div class="t m0 x8e h15 y460 ffe fs3 fc0 sc0 ls0 ws0">−</div><div class="t m0 xa1 h15 y278 ffe fs3 fc0 sc0 ls0 ws0">α</div><div class="t m0 x9e h16 y43d ffe fs7 fc0 sc0 ls0 ws0">τ=1</div><div class="t m0 x9e h16 y2a5 ffe fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x88 h15 y463 ffe fs3 fc0 sc0 ls0 ws0">g</div><div class="t m0 x49 h16 y464 ffe fs7 fc0 sc0 ls0 ws0">τ,i</div><div class="t m0 x49 h16 y465 ffe fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xa0 h24 y463 ffe fsc fc0 sc0 ls0 ws0"></div><div class="t m0 x3d h15 y460 ffe fs3 fc0 sc0 ls0 ws0">g</div><div class="t m0 xa7 h16 y461 ffe fs7 fc0 sc0 ls0 ws0">t,i</div><div class="t m0 x9a h15 y460 ffe fs3 fc0 sc0 ls0 ws0"> wℎere g</div><div class="t m0 x5f h16 y461 ffe fs7 fc0 sc0 ls0 ws0">t,i</div><div class="t m0 x34 h15 y181 ffe fs3 fc0 sc0 ls0 ws0">=</div><div class="t m0 x2b h15 y278 ffe fs3 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x5a h15 y3f0 ffe fs3 fc0 sc0 ls0 ws0">∂θ</div><div class="t m0 x76 h16 y466 ffe fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x76 h16 yc7 ffe fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x61 h15 y460 ffe fs3 fc0 sc0 ls0 ws0">J</div><div class="t m0 x5e h16 y462 ffe fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x96 h15 y460 ffe fs3 fc0 sc0 ls0 ws0">(θ)</div><div class="t m0 x0 h5 y467 ff5 fs3 fc0 sc0 ls0 ws0">在这个<span class="_ _2"></span>技<span class="_ _2"></span>术中<span class="_ _2"></span>，我<span class="_ _2"></span>们看<span class="_ _2"></span>到如果<span class="_ _2"></span>梯<span class="_ _2"></span>度的<span class="_ _2"></span>历史<span class="_ _15"> </span><span class="ff4">RMS<span class="_ _4"> </span></span>很<span class="_ _2"></span>低，<span class="_ _2"></span>那么<span class="_ _2"></span>学习</div><div class="t m0 x0 h6 y468 ff5 fs3 fc0 sc0 ls0 ws0">率会非常高。<span class="_ _2"></span>这个技术的一<span class="_ _2"></span>个简单的<span class="_ _2"></span>实现如下所示<span class="_ _2"></span>：</div></div><div class="c x0 y469 wb h31"><div class="t m0 x7 h2f y46a ff15 fs4 fc0 sc0 ls0 ws0"># Assume th<span class="_ _a"></span>e gradient dx<span class="_ _5"> </span>and parameter vector x</div><div class="t m0 x7 h30 y46b ff16 fs4 fc0 sc0 ls0 ws0">cache += dx<span class="_ _5"> </span>** 2</div><div class="t m0 x7 h30 y46c ff16 fs4 fc0 sc0 ls0 ws0">x += -learn<span class="_ _a"></span>ing_rate * dx<span class="_ _5"> </span>/ np.sqrt(cache + 1e-8)</div></div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h5 y46d ff5 fs3 fc0 sc0 ls0 ws0">其<span class="_ _2"></span>他<span class="_ _2"></span>常<span class="_ _6"></span>见<span class="_ _2"></span>的<span class="_ _2"></span>自<span class="_ _6"></span>适应<span class="_ _6"></span>方<span class="_ _2"></span>法<span class="_ _2"></span>有<span class="_ _7"> </span><span class="ff4">RM<span class="_ _2"></span>SProp<span class="_ _15"> </span></span>和<span class="_ _7"> </span><span class="ff4">A<span class="_ _2"></span>dam<span class="_ _15"> </span></span>，<span class="_ _2"></span>其<span class="_ _2"></span>更<span class="_ _6"></span>新<span class="_ _2"></span>规<span class="_ _2"></span>则<span class="_ _6"></span>如</div><div class="t m0 x0 h6 y46e ff5 fs3 fc0 sc0 ls0 ws0">下：</div></div><div class="c x0 y46f wb h32"><div class="t m0 x7 h2f y470 ff15 fs4 fc0 sc0 ls0 ws0"># Update ru<span class="_ _a"></span>le for RMS prop</div><div class="t m0 x7 h30 y471 ff16 fs4 fc0 sc0 ls0 ws0">cache =<span class="_ _22"> </span>decay<span class="_ _2"></span>_rate *<span class="_ _22"> </span>cache +<span class="_ _22"> </span>(1 -<span class="_ _22"> </span>decay_<span class="_ _2"></span>rate) *<span class="_ _22"> </span>dx *</div><div class="t m0 x7 h30 y472 ff16 fs4 fc0 sc0 ls0 ws0">* 2</div><div class="t m0 x7 h30 y473 ff16 fs4 fc0 sc0 ls0 ws0">x += -learn<span class="_ _a"></span>ing_rate * dx<span class="_ _5"> </span>/ (np.sqrt(cache) + eps)</div><div class="t m0 x7 h2f y474 ff15 fs4 fc0 sc0 ls0 ws0"># Update ru<span class="_ _a"></span>le for Adam</div><div class="t m0 x7 h30 y475 ff16 fs4 fc0 sc0 ls0 ws0">m = beta * m<span class="_ _5"> </span>+ (1 - beta1) * dx</div><div class="t m0 x7 h30 y476 ff16 fs4 fc0 sc0 ls0 ws0">v = beta * v<span class="_ _5"> </span>+ (1 - beta2) * (dx ** 2<span class="_ _a"></span>)</div><div class="t m0 x7 h30 y477 ff16 fs4 fc0 sc0 ls0 ws0">x += -learn<span class="_ _a"></span>ing_rate * m / (np.<span class="_ _a"></span>sqrt(v) + eps)</div></div><div class="c x1 y3 w2 h3"><div class="t m0 x0 h23 y478 ff3 fs3 fc0 sc0 ls0 ws0">•</div><div class="t m0 x2 h5 y479 ff4 fs3 fc0 sc0 ls0 ws0">RMSProp<span class="_ _15"> </span><span class="ff5">是<span class="_ _2"></span>利用<span class="_ _2"></span>平<span class="_ _2"></span>方<span class="_ _2"></span>梯<span class="_ _2"></span>度<span class="_ _2"></span>的<span class="_ _2"></span>移<span class="_ _2"></span>动平<span class="_ _2"></span>局<span class="_ _2"></span>值<span class="_ _2"></span>，<span class="_ _2"></span>是<span class="_ _7"> </span></span>AdaGrad<span class="_ _4"> </span><span class="ff5">的</span></div><div class="t m0 x2 h5 y47a ff5 fs3 fc0 sc0 ls0 ws0">一个变<span class="_ _2"></span>体<span class="ff4">——<span class="_ _2"></span></span>实际<span class="_ _2"></span>上，<span class="_ _2"></span>和<span class="_ _4"> </span><span class="ff4">AdaGrad<span class="_ _15"> </span></span>不一<span class="_ _2"></span>样，它<span class="_ _2"></span>的更<span class="_ _2"></span>新不<span class="_ _2"></span>会</div><div class="t m0 x2 h6 y47b ff5 fs3 fc0 sc0 ls0 ws0">单调变小。</div><div class="t m0 x0 h5 y47c ff3 fs3 fc0 sc0 ls0 ws0">•<span class="_ _18"> </span><span class="ff4">Adam<span class="_ _7"> </span><span class="ff5">更<span class="_ _2"></span>新<span class="_ _12"></span>规<span class="_ _2"></span>则<span class="_ _12"></span>又<span class="_ _2"></span>是<span class="_ _8"> </span></span>RM<span class="_ _2"></span>SProp<span class="_ _7"> </span><span class="ff5">的<span class="_ _6"></span>一<span class="_ _6"></span>个<span class="_ _6"></span>变<span class="_ _6"></span>体<span class="_ _6"></span>，<span class="_ _6"></span>但<span class="_ _6"></span>是<span class="_ _6"></span>加<span class="_ _6"></span>上<span class="_ _2"></span>了</span></span></div><div class="t m0 x2 h6 y47d ff5 fs3 fc0 sc0 ls0 ws0">动量更新。</div></div><div class="c x27 y3 w9 h3"><div class="t m0 x28 h14 y5e ffd fs0 fc0 sc0 ls0 ws0">2.10<span class="_ _4"> </span>More<span class="_ _7"> </span>reference</div><div class="t m0 x28 h6 y5f ff5 fs3 fc0 sc0 ls0 ws0">如果希望了解<span class="_ _2"></span>以上的梯度优<span class="_ _2"></span>化算法</div><div class="t m0 x28 h6 y61 ff5 fs3 fc0 sc0 ls0 ws0">的具体细节，<span class="_ _2"></span>可以阅读这篇<span class="_ _2"></span>文章：</div><div class="t m0 x28 h5 y45d ff4 fs3 fc0 sc0 ls0 ws0">An<span class="_ _23"> </span>overview<span class="_ _23"> </span>of<span class="_ _23"> </span>gradient</div><div class="t m0 x28 h5 y45e ff4 fs3 fc0 sc0 ls0 ws0">descent<span class="_ _24"> </span>optimization</div><div class="t m0 x28 h5 y45f ff4 fs3 fc0 sc0 ls0 ws0">algorithms<span class="_ _2"></span>)<span class="_ _3"> </span><span class="ff5">。</span></div></div><a class="l" href="http://ruder.io/optimizing-gradient-descent/"><div class="d m2" style="border-style:none;position:absolute;left:395.300000px;bottom:722.250000px;width:160.650000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="http://ruder.io/optimizing-gradient-descent/"><div class="d m2" style="border-style:none;position:absolute;left:395.300000px;bottom:722.250000px;width:160.650000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="http://ruder.io/optimizing-gradient-descent/"><div class="d m2" style="border-style:none;position:absolute;left:395.300000px;bottom:722.250000px;width:160.650000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf14" class="pf w0 h0" data-page-no="14"><div class="pc pc14 w0 h0"><img class="bi xa y0 wc hd" alt="" src="bg14.png"/><div class="t m0 xd he y1e ff8 fs1 fc0 sc0 ls0 ws0">系列内容</div><div class="t m0 xe h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">Awesome<span class="_ _1"> </span>AI<span class="_ _1"> </span>Cour<span class="_ _2"></span>ses<span class="_ _1"> </span>Notes<span class="_ _1"> </span>Che<span class="_ _2"></span>at<span class="_ _1"> </span>Sheets</div><div class="t m0 xf he y1e ff8 fs1 fc0 sc0 ls0 ws0">@</div><div class="t m0 x10 h2 y1f ff2 fs1 fc0 sc0 ls0 ws0">ShowMeAI</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls0 ws0">Lecture<span class="_ _1"> </span>Notes:<span class="_ _3"> </span>Part<span class="_ _1"> </span><span class="ff1">III<span class="_ _1"> </span></span>-<span class="_ _1"> </span>Neural<span class="_ _1"> </span>Net<span class="_ _2"></span>works,<span class="_ _1"> </span>Backpropagatio<span class="_ _2"></span>n</div><div class="c xa y47e wd h33"><div class="t m0 x7 h34 y47f ff7 fs1 fc0 sc0 ls0 ws0">机器学习</div></div><div class="c x8e y47e we h33"><div class="t m0 x7 h34 y480 ff7 fs1 fc0 sc0 ls0 ws0">深度学习</div></div><div class="c x1d y47e wf h33"><div class="t m0 x7 h34 y47f ff7 fs1 fc0 sc0 ls0 ws0">自然语言处<span class="_ _2"></span>理</div></div><div class="c xc7 y47e w10 h33"><div class="t m0 x7 h34 y480 ff7 fs1 fc0 sc0 ls0 ws0">计算机视觉</div></div><div class="c xc8 y47e w4 h33"><div class="t m0 x7 h34 y47f ff7 fs1 fc0 sc0 ls0 ws0">知识图谱</div></div><div class="c xa y481 wd h33"><div class="t m0 x7 hc y482 ff4 fs5 fc0 sc0 ls0 ws0">Machine<span class="_ _1"> </span>Le<span class="_ _2"></span>arning</div></div><div class="c x8e y481 we h33"><div class="t m0 x7 hc y483 ff4 fs5 fc0 sc0 ls0 ws0">Deep<span class="_ _1"> </span>Le<span class="_ _2"></span>arning</div></div><div class="c x1d y481 wf h33"><div class="t m0 x7 hc y482 ff4 fs5 fc0 sc0 ls0 ws0">Natural<span class="_ _1"> </span>Language<span class="_ _3"> </span>Processing</div></div><div class="c xc7 y481 w10 h33"><div class="t m0 x7 hc y483 ff4 fs5 fc0 sc0 ls0 ws0">Computer<span class="_ _1"> </span>Vision</div></div><div class="c xc8 y481 w4 h33"><div class="t m0 x7 hc y482 ff4 fs5 fc0 sc0 ls0 ws0">Knowledge<span class="_ _1"> </span>Graph<span class="_ _2"></span>s</div></div><div class="c xa y484 wd h33"><div class="t m0 x7 hc y485 ff4 fs5 fc0 sc0 ls0 ws0">Stanford<span class="_ _1"> </span>·<span class="_ _3"> </span>CS229</div></div><div class="c x8e y484 we h33"><div class="t m0 x7 hc y486 ff4 fs5 fc0 sc0 ls0 ws0">Stanford<span class="_ _1"> </span>·<span class="_ _3"> </span>CS230</div></div><div class="c x1d y484 wf h33"><div class="t m0 x7 hc y485 ff4 fs5 fc0 sc0 ls0 ws0">Stanford ·<span class="_ _1"> </span>CS224n</div></div><div class="c xc7 y484 w10 h33"><div class="t m0 x7 hc y486 ff4 fs5 fc0 sc0 ls0 ws0">Stanford<span class="_ _1"> </span>·<span class="_ _3"> </span>CS231n</div></div><div class="c xc8 y484 w4 h33"><div class="t m0 x7 hc y485 ff4 fs5 fc0 sc0 ls0 ws0">Stanford<span class="_ _1"> </span>·<span class="_ _3"> </span>CS520</div></div><div class="c xa y487 w11 h35"><div class="t m0 x73 h19 y488 ff7 fs0 fc0 sc0 ls0 ws0">#<span class="_ _4"> </span>系列内容<span class="_ _15"> </span>A<span class="_ _2"></span>wesome<span class="_ _15"> </span>AI<span class="_ _15"> </span>Courses<span class="_ _15"> </span>Notes<span class="_ _15"> </span>Cheatsheets</div></div><div class="c xa y489 w12 h33"><div class="t m0 x7 h34 y47f ff7 fs1 fc0 sc0 ls0 ws0">图机器学习</div></div><div class="c x1d y489 wf h33"><div class="t m0 x7 h34 y480 ff7 fs1 fc0 sc0 ls0 ws0">深度强化学<span class="_ _2"></span>习</div></div><div class="c xc7 y489 w13 h33"><div class="t m0 x7 h34 y480 ff7 fs1 fc0 sc0 ls0 ws0">自动驾驶</div></div><div class="c xa y48a w12 h33"><div class="t m0 x7 hc y482 ff4 fs5 fc0 sc0 ls0 ws0">Machine<span class="_ _1"> </span>Le<span class="_ _2"></span>arning<span class="_ _1"> </span>with<span class="_ _1"> </span>Grap<span class="_ _2"></span>hs</div></div><div class="c x1d y48a wf h33"><div class="t m0 x7 hc y483 ff4 fs5 fc0 sc0 ls0 ws0">Deep<span class="_ _1"> </span>Rei<span class="_ _2"></span>nforcement<span class="_ _1"> </span>Learning</div></div><div class="c xc7 y48a w13 h33"><div class="t m0 x7 hc y483 ff4 fs5 fc0 sc0 ls0 ws0">Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span>for<span class="_ _1"> </span>Se<span class="_ _2"></span>lf-Driving<span class="_ _1"> </span>Cars</div></div><div class="c xa y48b w12 h33"><div class="t m0 x7 hc y485 ff4 fs5 fc0 sc0 ls0 ws0">Stanford<span class="_ _1"> </span>·<span class="_ _3"> </span>CS224W</div></div><div class="c x1d y48b wf h33"><div class="t m0 x7 hc y486 ff4 fs5 fc0 sc0 ls0 ws0">UCBerkeley<span class="_ _1"> </span>·<span class="_ _3"> </span>CS285</div></div><div class="c xc7 y48b w13 h33"><div class="t m0 x7 hc y486 ff4 fs5 fc0 sc0 ls0 ws0">MIT<span class="_ _1"> </span>·<span class="_ _3"> </span>6.S094</div></div><div class="c xa y48c w12 h36"><div class="t m0 x7 h37 y48d ff4 fs1 fc0 sc0 ls0 ws0">...</div></div><div class="c x1d y48c wf h36"><div class="t m0 x7 h37 y48d ff4 fs1 fc0 sc0 ls0 ws0">...</div></div><div class="c xc7 y48c w13 h36"><div class="t m0 x7 h37 y48d ff4 fs1 fc0 sc0 ls0 ws0">...</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf15" class="pf w0 h0" data-page-no="15"><div class="pc pc15 w0 h0"><img class="bi xc9 y48e w14 h38" alt="" src="bg15.png"/><div class="t m0 x0 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">CS224n<span class="_ _0"> </span><span class="ff2 fs1">|<span class="_ _1"> </span>Natural<span class="_ _1"> </span>Langua<span class="_ _2"></span>ge<span class="_ _1"> </span>Processing<span class="_ _1"> </span>wit<span class="_ _2"></span>h<span class="_ _1"> </span>Deep<span class="_ _1"> </span>Learning<span class="_ _3"> </span><span class="ff3">•<span class="_ _1"> </span></span>Stanford<span class="_ _1"> </span>U<span class="_ _2"></span>niversity</span></div><div class="t m0 xca hc y48f ff4 fs5 fc0 sc0 ls0 ws0">21</div><div class="t m0 x0 h5 y490 ff5 fs3 fc0 sc0 ls0 ws0">是<span class="_ _15"> </span><span class="ff4">ShowMeAI<span class="_ _15"> </span></span>资<span class="_ _2"></span>料<span class="_ _2"></span>库<span class="_ _2"></span>的分<span class="_ _2"></span>支<span class="_ _2"></span>系<span class="_ _2"></span>列<span class="_ _2"></span>，<span class="_ _2"></span>覆盖<span class="_ _2"></span>最<span class="_ _2"></span>具<span class="_ _2"></span>知名<span class="_ _2"></span>度<span class="_ _2"></span>的 <span class="ff4">TOP2<span class="_ _2"></span>0+<span class="_ _2"></span></span>门<span class="_ _19"> </span><span class="ff4">A<span class="_ _2"></span>I </span>课<span class="_ _2"></span>程<span class="_ _2"></span>，<span class="_ _2"></span>旨在<span class="_ _2"></span>为<span class="_ _2"></span>读<span class="_ _2"></span>者<span class="_ _2"></span>和<span class="_ _2"></span>学习<span class="_ _2"></span>者<span class="_ _2"></span>提<span class="_ _2"></span>供<span class="_ _2"></span>一整<span class="_ _2"></span>套</div><div class="t m0 x0 h6 y491 ff5 fs3 fc0 sc0 ls0 ws0">高品质中文学<span class="_ _2"></span>习笔记和速查<span class="_ _2"></span>表。</div><div class="t m0 x0 h5 y492 ff5 fs3 fc0 sc0 ls0 ws0">斯坦<span class="_ _2"></span>福<span class="_ _2"></span>大<span class="_ _2"></span>学<span class="_ _2"></span><span class="ff4">(Stanfor<span class="_ _2"></span>d<span class="_ _4"> </span>Univer<span class="_ _2"></span>sity)<span class="_ _4"> </span>Natu<span class="_ _2"></span>ral<span class="_ _4"> </span>L<span class="_ _2"></span>anguage<span class="_ _15"> </span>Proces<span class="_ _2"></span>sing<span class="_ _4"> </span>with<span class="_ _15"> </span>Deep<span class="_ _15"> </span>Learning<span class="_ _15"> </span>(CS224n<span class="_ _2"></span>)<span class="_ _4"> </span></span>课<span class="_ _2"></span>程<span class="_ _2"></span>，<span class="_ _2"></span>是<span class="_ _2"></span>本</div><div class="t m0 x0 h6 y493 ff5 fs3 fc0 sc0 ls0 ws0">系列的第三门<span class="_ _2"></span>产出。</div><div class="t m0 x0 h5 y494 ff5 fs3 fc0 sc0 ls0 ws0">课程<span class="_ _2"></span>版本<span class="_ _2"></span>为<span class="_ _19"> </span><span class="ff4">2019<span class="_ _15"> </span>Winter<span class="_ _2"></span></span>，核<span class="_ _2"></span>心<span class="_ _2"></span>深度<span class="_ _2"></span>内<span class="_ _2"></span>容<span class="ff4">(trans<span class="_ _2"></span>former<span class="_ _2"></span></span>、<span class="ff4">bert<span class="_ _2"></span></span>、<span class="_ _2"></span>问<span class="_ _2"></span>答、<span class="_ _2"></span>摘要<span class="_ _2"></span>、<span class="_ _2"></span>文本<span class="_ _2"></span>生成<span class="_ _2"></span>等<span class="_ _2"></span><span class="ff4">)</span>在<span class="_ _2"></span>当前<span class="_ _2"></span><span class="ff4">(2021<span class="_ _5"> </span></span>年<span class="ff4">)<span class="_ _2"></span></span>工</div><div class="t m0 x0 h6 y495 ff5 fs3 fc0 sc0 ls0 ws0">业界和研究界<span class="_ _2"></span>依旧是前沿的<span class="_ _2"></span>方法。最<span class="_ _2"></span>新版课程的笔<span class="_ _2"></span>记生产已在规<span class="_ _2"></span>划中，也<span class="_ _2"></span>敬请期待。</div><div class="t m0 x0 h19 y496 ff5 fs3 fc0 sc0 ls0 ws0">笔记内<span class="_ _2"></span>容经<span class="_ _2"></span>由深度<span class="_ _2"></span>加工<span class="_ _2"></span>整合<span class="_ _2"></span>，以 <span class="ff7 fs0">5 </span>个部<span class="_ _2"></span>分构<span class="_ _2"></span>建起完<span class="_ _2"></span>整的<span class="_ _2"></span>“<span class="ff4">CS224<span class="_ _2"></span>n </span>内<span class="_ _2"></span>容世界<span class="_ _2"></span>”，<span class="_ _2"></span>并依托<span class="_ _5"> </span><span class="ff4">GitHub </span>创<span class="_ _2"></span>建了<span class="_ _2"></span>汇总</div><div class="t m0 x0 h5 y497 ff5 fs3 fc0 sc0 ls0 ws0">页。快扫描二<span class="_ _2"></span>维码，跳转进<span class="_ _2"></span>入吧！有<span class="_ _2"></span>任何建议和反<span class="_ _2"></span>馈，也欢迎通<span class="_ _2"></span>过下方渠<span class="_ _2"></span>道和我们联络<span class="_ _4"> </span><span class="ff4">(*</span>￣<span class="_ _2"></span><span class="ff4">3</span>￣<span class="ff4">)~</span></div><a class="l" href="http://show-me-ai.com/"><div class="d m2" style="border-style:none;position:absolute;left:55.950000px;bottom:787.350000px;width:53.900000px;height:18.800000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png"/>
</div>
</body>
</html>
